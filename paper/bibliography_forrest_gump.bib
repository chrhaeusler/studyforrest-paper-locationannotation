@comment{x-kbibtex-encoding=iso-8859-15}

@comment{x-kbibtex-personnameformatting=<%f ><%l>}

@book{kandorfer_1994_DuMonts_Filmgestaltung,
	address = "Köln",
	author = "Pierre Kandorfer",
	crossref = https://ubfind.ovgu.de/Record/043587984,
	edition = "5. Aufl.",
	pages = "488 S.",
	publisher = "DuMont",
	title = "{DuMont's Lehrbuch der Filmgestaltung theoretisch-technische Grundlagen der Filmkunde}",
	x-color = "#ffff00",
	year = "1994"
}

@book{katz_2000_richtige_Einstellung,
	address = "Frankfurt am Main",
	author = "Steven D Katz",
	crossref = https://ubfind.ovgu.de/Record/317477722,
	edition = "Dt. Erstausg., 3. Aufl.",
	keywords = "cinematography",
	note = "Literaturverz. S 495 - 497",
	pages = "520 S.",
	publisher = "Zweitausendeins",
	title = "{Die richtige Einstellung: Zur Bildsprache des Films}",
	year = "2000"
}

@inproceedings{kauppi_2011_face_prediction,
	added-at = "2011-06-16T00:00:00.000+0200",
	author = "Jukka-Pekka Kauppi and Heikki Huttunen and Heikki Korkala and Iiro P. Jï¿œï¿œskelï¿œinen and Mikko Sams and Jussi Tohka",
	booktitle = "{ICANN (2)}",
	crossref = "conf/icann/2011-2",
	editor = "Timo Honkela and Wlodzislaw Duch and Mark A. Girolami and Samuel Kaski",
	interhash = "5c26e6248e1effb744b021a77de14a33",
	intrahash = "1c8f3f5e2af2f011cc4c328f05f035c5",
	isbn = "978-3-642-21737-1",
	keywords = "Natural stimulation; brain imaging; regression; faces; movie; Crash; MVPA",
	localfile = "/home/chris/studium/masterarbeit/paper/Kauppi (2011). Face prediction from fMRI data during movie stimulus.pdf",
	pages = "189--196",
	publisher = "Springer",
	series = "{Lecture Notes in Computer Science}",
	title = "{Face Prediction from fMRI Data during Movie Stimulus: Strategies for Feature Selection.}",
	url = "http://dx.doi.org/10.1007/978-3-642-21738-8_25",
	volume = "6792",
	x-fetchedfrom = "Bibsonomy",
	year = "2011"
}

@article{abelson_2013_zombies_brains_tweets,
	abstract = "no abstract given :-(",
	author = "Brian Abelson",
	localfile = "/home/chris/studium/masterarbeit/paper/Abelson (2013). Zombies, Brains, and Tweets. The Neural and Emotional Correlates of Social Media.pdf",
	title = "{Zombies, Brains, and Tweets: The Neural and Emotional Correlates of Social Media}",
	x-color = "#ffffa5",
	year = "2013"
}

@incollection{aspell_2009_understanding-obe,
	address = "Hauppauge",
	author = "Jane E Aspell and Olaf Blanke",
	booktitle = "{Psychological and Scientific Perspectives on Out-of-Body and Near-Death Experiences}",
	editor = "Craig M. Murray",
	keywords = "review",
	localfile = "/home/chris/studium/masterarbeit/paper/Aspell, Blanke (2009). Understanding the OBE from a neuroscientific perspective (review).pdf",
	pages = "73--88",
	publisher = "Nova Science",
	title = "{Understanding the out-of-body experience from a neuroscientific perspective}",
	year = "2009"
}

@article{partels_2005_natural_viewing_new_guide,
	abstract = "We describe here a new way of obtaining maps of connectivity in the human brain based on interregional correlations of blood oxygen level-dependent (BOLD) signal during natural viewing conditions. We propose that anatomical connections are reflected in BOLD signal correlations during natural brain dynamics. This may provide a powerful approach to chart connectivity, more so than that based on the 'resting state' of the human brain, and it may complement diffusion tensor imaging. Our approach relies on natural brain dynamics and is therefore experimentally unbiased and independent of hypothesis-driven, specialized stimuli. It has the advantage that natural viewing leads to considerably stronger cortical activity than rest, thus facilitating detection of weaker connections. To validate our technique, we used functional magnetic resonance imaging (fMRI) to record BOLD signal while volunteers freely viewed a movie that was interrupted by resting periods. We used independent component analysis (ICA) to segregate cortical areas before characterizing the dynamics of their BOLD signal during free viewing and rest. Natural viewing and rest each revealed highly specific correlation maps, which reflected known anatomical connections. Examples are homologous regions in visual and auditory cortices in the two hemispheres and the language network consisting of Wernicke's area, Broca's area, and a premotor region. Correlations between regions known to be directly connected were always substantially higher than between nonconnected regions. Furthermore, compared to rest, natural viewing specifically increased correlations between anatomically connected regions while it decreased correlations between nonconnected regions. Our findings therefore demonstrate that natural viewing conditions lead to particularly specific interregional correlations and thus provide a powerful environment to reveal anatomical connectivity in vivo.",
	author = "Andreas Bartels and Semir Zeki",
	journal = "Neuroimage",
	keywords = "fMRI; Correlation; Functional connectivity; Anatomical con- nectivity; Effective connectivity; Natural vision; Resting state; Independent component analysis; ICA; Visual cortex; Language; Broca; Wernicke; Diffusion tensor imaging; James Bond; Tomorrow Never Dies",
	localfile = "/home/chris/studium/masterarbeit/paper/Bartels (2005). Brain dynamics during natural viewing conditions. A new guide for mapping connectivity in vivo.pdf",
	month = jan,
	nlmuniqueid = "9215515",
	note = {stimulus: "Tomorrow Never Dies" (James Bond Movie)},
	number = "2",
	pages = "339--349",
	pii = "S1053-8119(04)00507-5",
	pubmed = "15627577",
	title = "{Brain dynamics during natural viewing conditions--a new guide for mapping connectivity in vivo}",
	volume = "24",
	x-fetchedfrom = "PubMed",
	year = "2005"
}

@article{bartels_2004_chronoarchitecture,
	abstract = {A dominant tendency in cerebral studies has been the attempt to locate architecturally distinct parts of the cortex and assign special functions to each, through histological, clinical or hypothesis-based imaging experiments. Here we show that the cerebral cortex can also be subdivided into different components temporally, without any a priori hypotheses, based on the principle of functional independence. This states that distinct functional subdivisions have activity time courses (ATCs) that are, if not independent, at least characteristic to each when the brain is exposed to natural conditions. To approach a time-based anatomy experimentally, we recorded whole-brain activity using functional magnetic resonance imaging (fMRI) and analyzed the data with independent component analysis (ICA). Our results show that a multitude of cortical areas can be identified based purely on their characteristic ATCs during natural conditions. We demonstrate that a more "rich" stimulation (free viewing of a movie) leads to more areas being activated in a specific way than conventional stimuli, allowing for a more detailed dissection of the cortex into its subdivisions. We show that stimulus-driven functionally specialized areas can be identified by intersubject correlation even if their function is unknown. Chronoarchitectonic mapping thus opens the prospect of identifying previously unknown cortical subdivisions based on natural viewing conditions by exploiting the characteristic temporal "fingerprint" that is unique to each.},
	author = "Andreas Bartels and Semir Zeki",
	journal = "Neuroimage",
	keywords = "Chronoarchitecture; fMRI; Time-based anatomy; Independent component analysis; ICA; Movie; Visual cortex; Auditory cortex; Connectivity",
	localfile = "/home/chris/studium/masterarbeit/paper/Bartels (2004). Chronoarchitecture of the human brain.pdf",
	month = may,
	nlmuniqueid = "9215515",
	note = {stimulus: "Tomorrow Never Dies" (James Bond Movie)},
	number = "1",
	pages = "419--433",
	pii = "S1053811904000333",
	pubmed = "15110035",
	title = "{The chronoarchitecture of the human brain--natural viewing conditions reveal a time-based anatomy of the brain}",
	volume = "22",
	x-fetchedfrom = "PubMed",
	year = "2004"
}

@article{bartels_2004_mapping_during_free_viewing,
	abstract = "Previous imaging studies have used mostly perceptually abstracted, idealized, or static stimuli to show segregation of function in the cerebral cortex. We wanted to learn whether functional segregation is maintained during more natural, complex, and dynamic conditions when many features have to be processed simultaneously, and identify regions whose activity correlates with the perception of specific features. To achieve this, we used functional magnetic resonance imaging (fMRI) to measure brain activity when human observers viewed freely dynamic natural scenes (a James Bond movie). The intensity with which they perceived different features (color, faces, language, and human bodies) was assessed psychometrically in separate sessions. In all subjects different features were perceived with a high degree of independence over time. We found that the perception of each feature correlated with activity in separate, specialized areas whose activity also varied independently. We conclude that even in natural conditions, when many features have to be processed simultaneously, functional specialization is preserved. Our method thus opens a new way of brain mapping, which allows the localization of a multitude of brain areas based on a single experiment using uncontrolled, natural stimuli. Furthermore, our results show that the intensity of activity in a specialized area is linearly correlated with the intensity of its perceptual experience. This leads us to suggest that each specialized area is directly responsible for the creation of a feature-specific conscious percept (a microconsciousness).",
	author = "Andreas Bartels and Semir Zeki",
	journal = "Human Brain Mapping",
	keywords = "fMRI; free viewing; natural scenes; color; faces; human body; language; movie; James Bond; Tomorrow Never Dies",
	localfile = "/home/chris/studium/masterarbeit/paper/Bartels (2004). Functional Brain Mapping During Free Viewing of Natural Scenes.pdf",
	month = feb,
	nlmuniqueid = "9419065",
	note = {stimulus: "Tomorrow Never Dies" (James Bond Movie)},
	number = "2",
	pages = "75--85",
	pubmed = "14755595",
	title = "{Functional brain mapping during free viewing of natural scenes}",
	volume = "21",
	x-color = "#ffff00",
	x-fetchedfrom = "PubMed",
	year = "2004"
}

@article{berg_2009_free_viewing,
	abstract = "Due to extensive homologies, monkeys provide a sophisticated animal model of human visual attention. However, for electrophysiological recording in behaving animals simplified stimuli and controlled eye position are traditionally used. To validate monkeys as a model for human attention during realistic free viewing, we contrasted human (n = 5) and monkey (n = 5) gaze behavior using 115 natural and artificial video clips. Monkeys exhibited broader ranges of saccadic endpoints and amplitudes and showed differences in fixation and intersaccadic intervals. We compared tendencies of both species to gaze toward scene elements with similar low-level visual attributes using two computational models--luminance contrast and saliency. Saliency was more predictive of both human and monkey gaze, predicting human saccades better than monkey saccades overall. Quantifying interobserver gaze consistency revealed that while humans were highly consistent, monkeys were more heterogeneous and were best predicted by the saliency model. To address these discrepancies, we further analyzed high-interest gaze targets--those locations simultaneously chosen by at least two monkeys. These were on average very similar to human gaze targets, both in terms of specific locations and saliency values. Although substantial quantitative differences were revealed, strong similarities existed between both species, especially when focusing analysis onto high-interest targets.",
	author = "David J Berg and Susan E Boehnke and Robert A Marino and Douglas P Munoz and Laurent Itti",
	journal = "Journal of Vision",
	keywords = "visual attention; computational model; salience; free viewing; saccades; monkeys",
	localfile = "/home/chris/studium/masterarbeit/paper/Berg (2009). Free viewing of dynamic stimuli by humans and monkeys.pdf",
	nlmuniqueid = "101147197",
	number = "5",
	pages = "1--15",
	pii = "9/5/19",
	pubmed = "19757897",
	title = "{Free viewing of dynamic stimuli by humans and monkeys}",
	volume = "9",
	x-color = "#ffffa5",
	x-fetchedfrom = "PubMed",
	year = "2009"
}

@article{blanke_2012_multisensory-mechanisms,
	author = "Olaf Blanke",
	journal = "Nature Reviews Neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Blanke (2012). Multisensory brain mechanisms (Review).pdf",
	number = "8",
	pages = "556--571",
	publisher = "Nature Publishing Group",
	title = "{Multisensory brain mechanisms of bodily self-consciousness}",
	volume = "13",
	year = "2012"
}

@article{blanke_2005_linking_obe_to_tpj,
	author = "Olaf Blanke and Christine Mohr and Christoph M Michel and Alvaro Pascual-Leone and Peter Brugger and Margitta Seeck and Theodor Landis and Gregor Thut",
	journal = "The Journal of Neuroscience",
	keywords = "self processing; temporoparietal junction; neurology; transcranial magnetic stimulation; event-related potentials; human; TMS",
	localfile = "/home/chris/studium/masterarbeit/paper/Blanke (2005). Linking out of body at at the Temporoparietal Junction.pdf",
	number = "3",
	pages = "550--557",
	publisher = "Soc Neuroscience",
	title = "{Linking out-of-body experience and self processing to mental own-body imagery at the temporoparietal junction}",
	volume = "25",
	year = "2005"
}

@article{boksem_2014_trailer_eeg_responses,
	author = "Maarten AS Boksem and Ale Smidts",
	journal = "Journal of Marketing Research",
	keywords = "Neuromarketing; consumer neuroscience; advertising; EEG; beta; gamma; trailers",
	localfile = "/home/chris/studium/masterarbeit/paper/Boksem & Smidts (2015). Brain responses to movie-trailers predict individual preferences for movies and their population-wide commercial success.pdf",
	publisher = "American Marketing Association",
	title = "{Brain responses to movie-trailers predict individual preferences for movies and their population-wide commercial success.}",
	url = "http://journals.ama.org/doi/abs/10.1509/jmr.13.0572",
	year = "2014"
}

@article{bonda_1995_mental_transformations_body-in-space,
	author = "Eva Bonda and Michael Petrides and Stephen Frey and ALAN EvANs",
	journal = "Proceedings of the National Academy of Sciences",
	keywords = "PET; mental rotation; superior parietal cortex; intraparietal sulcus; inferior parietal lobule; body",
	localfile = "/home/chris/studium/masterarbeit/paper/Bonda (1995). Neural correlates of mental transformations of the body-in-space.pdf",
	number = "24",
	pages = "11180--11184",
	publisher = "National Acad Sciences",
	title = "{Neural correlates of mental transformations of the body-in-space}",
	volume = "92",
	year = "1995"
}

@article{bordier_2013_sensory_processing_during_cinematographic_material,
	author = "Cecile Bordier and Francesco Puja and Emiliano Macaluso",
	journal = "Neuroimage",
	keywords = "Data-driven; Saliency Multi-sensory; Cinematographic material; Biologically-inspired vision and audition; general linear model; GLM; independent component analysis; ICA; TV series; 24",
	localfile = "/home/chris/studium/masterarbeit/paper/Bordier (2013). Sensory processing during viewing of cinematographic material.pdf",
	note = {stimulus: "24" TV series},
	pages = "213--226",
	publisher = "Elsevier",
	title = "{Sensory processing during viewing of cinematographic material: Computational modeling and functional neuroimaging}",
	volume = "67",
	x-color = "#ffffa5",
	year = "2013"
}

@book{bordwell_2002_film_history,
	abstract = "Written by two of the leading film scholars, Film History: An Introduction, is the long-awaited, comprehensive survey that not only acknowledges the contributions of Hollywood and films from other U.S. sources, but broadens its scope to examine filmmaking internationally. As with the authors' bestselling Film Art, Fifth Edition, concepts and events are illustrated with actual frame enlargements, giving students more realistic points of reference than competing books that use publicity stills. Any serious film scholar -- professor, undergraduate, or graduate student -- will want to see and keep Film History.",
	added-at = "2008-09-12T06:26:01.000+0200",
	author = "David Bordwell and Kristin Thompson",
	citeulike-article-id = "2468086",
	description = "CiteULike",
	howpublished = "Paperback",
	interhash = "78d14bf7153261ab41509128179499cb",
	intrahash = "53a405f0902e84dee1f651314ae035d9",
	isbn = "0071151419",
	keywords = "film",
	localfile = "path=ASIN/0071151419",
	month = "September",
	posted-at = "2008-03-04 22:52:21",
	priority = "2",
	publisher = "McGraw Hill Higher Education",
	title = "{Film History: An Introduction}",
	url = "http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp; http://www.bibsonomy.org/bibtex/253a405f0902e84dee1f651314ae035d9/nathan.piazza",
	x-fetchedfrom = "Bibsonomy",
	year = "2002"
}

@article{bremmer_2001_space_in_primate_posterior_parietal,
	abstract = "Neuropsychological studies of patients with lesions of right frontal (premotor) or posterior parietal cortex often show severe impairments of attentive sensori- motor behavior. Such patients frequently manifest symptoms like hemispatial neglect or extinction. In- terestingly, these behavioral deficits occur across dif- ferent sensory modalities and are often organized in head- or body-centered coordinates. These neuropsy- chological data provide evidence for the existence of a network of polymodal areas in (primate) premotor and inferior parietal cortex representing visual spatial in- formation in a nonretinocentric frame of reference. In the monkey, a highly modular structural and func- tional specialization has been demonstrated espe- cially within posterior parietal cortex. One such func- tionally specialized area is the ventral intraparietal area (VIP). This area is located in the fundus of the intraparietal sulcus and contains many neurons that show polymodal directionally selective discharges, i.e., these neurons respond to moving visual, tactile, vestibular, or auditory stimuli. Many of these neurons also encode sensory information from different modal- ities in a common, probably head-centered, frame of reference. Functional imaging data on humans reveal a network of cortical areas that respond to polymodal stimuli conveying motion information. One of these regions of activation is located in the depth of human intraparietal sulcus. Accordingly, it is suggested that this area constitutes the human equivalent of monkey area VIP. The functional role of area VIP for poly- modal spatial perception in normals as well as the functional implications of lesions of area VIP in pari- etal patients needs to be established in further experiments.",
	author = "Frank Bremmer and Anja Schlack and Jean-Rene\'{ } Duhamel and Werner Graf and Gereon R. Fink",
	journal = "Neuroimage",
	keywords = "inferior parietal cortex; premotor cortex; ventral intraparietal area (VIP); PPC; neurophysiology; fMRI; macaque; human; area VIP; intraparietal.",
	localfile = "/home/chris/studium/masterarbeit/paper/Bremmer, Schlack (2001) Space coding in primate posterior parietal cortex.pdf",
	number = "1",
	pages = "S46--S51",
	publisher = "Elsevier",
	title = "{Space coding in primate posterior parietal cortex}",
	volume = "14",
	year = "2001"
}

@book{brown_2012_cinematography,
	author = "Blain Brown",
	edition = "2",
	isbn = "9780240812090",
	keywords = "cinematography",
	localfile = "/home/chris/studium/masterarbeit/cinematography /Brown - Cinematography - Theory and Practice (2012, 2nd Ed.).pdf",
	month = "7",
	publisher = "Focal Press",
	timestamp = "2015.09.18",
	title = "{Cinematography. Theory and Practice. Image Making for Cinematographers and Directors}",
	totalpages = "384",
	year = "2012"
}

@article{burgess_2001_retrieving_spatial_context_lifelike_events,
	abstract = "Virtual reality (VR) and event-related functional mag- netic resonance imaging were used to study memory for the spatial context of controlled but lifelike events. Sub- jects received a set of objects from two different people in two different places within a VR environment. Mem- ory for the objects, and for where and from whom they were received was tested by putting the subject back into a place in the company of a person and giving a paired forced choice of objects. In four conditions ob- jects had to be chosen according to different criteria: which was received in that place, which was received from that person, which object was recognized, and which object was widest. Event-related functional mag- netic resonance imaging was performed during testing to identify areas involved in retrieval of the spatial con- text of an event. A network of areas was identified con- sisting of a temporoparietal pathway running between the precuneus and parahippocampi via retrosplenial cortex and the parieto-occipital sulcus, left hippocam- pus, bilateral posterior parietal, dorsolateral, ventrolat- eral and anterior prefrontal cortices, and the anterior cingulate. Of these areas the parahippocampal, right posterior parietal, and posteriodorsal medial parietal areas were specifically involved in retrieval of spatial context compared to retrieval of nonspatial context. The posterior activations are consistent with a model of long-term storage of allocentric representations in me- dial temporal regions with translation to body-centered and head-centered representations computed in right posterior parietal cortex and buffered in the temporopa- rietal pathway so as to provide an imageable represen- tation in the precuneus. Prefrontal activations are con- sistent with strategic retrieval processes, including those required to overcome the interference between the highly similar events.",
	author = "Neil Burgess and Eleanor A Maguire and Hugo J Spiers and John O'Keefe",
	keywords = "virtual reality (VR); fMRI; memory; retrieval; spatial contex; parahippocampal; tempoarietal; allocentric representations; head-centered; body-centered; right posterior parietal cortex",
	localfile = "/home/chris/studium/masterarbeit/paper/Burgess (2001). A temporoparietal and prefrontal network for retrieving the spatial context of lifelike events.pdf",
	title = "{A Temporoparietal and Prefrontal Network for Retrieving the Spatial Context of Lifelike Events}",
	x-color = "#ffff00",
	year = "2001"
}

@article{calhoun_2012_review_simulated_driving,
	author = "V.D. Calhoun and G.D. Pearlson",
	keywords = "fMRI; Functional; Visual perception; Alcohol; simulated driving; navigation; independent component analysis; ICA; general linear model; GLM",
	localfile = "/home/chris/studium/masterarbeit/paper/Calhoun (2012). A selective review of simulated driving studies. Combining naturalistic and hybrid paradigms, analysis approaches, and future directions.pdf",
	title = "{A selective review of simulated driving studies: Combining naturalistic and hybrid paradigms, analysis approaches, and future directions}",
	x-color = "#ffff00",
	year = "2012"
}

@article{calhoun_2002_different_dynamics_simuated_driving,
	author = "Vince D Calhoun and James J Pekar and Vince B McGinty and Tulay Adali and Todd D Watson and Godfrey D Pearlson",
	journal = "Human Brain Mapping",
	keywords = "simulated driving; fMRI; driving; brain; independent component analysis; ICA",
	localfile = "/home/chris/studium/masterarbeit/paper/Calhoun (2002). Different activation dynamics in multiple neural systems during simulated driving.pdf",
	number = "3",
	pages = "158--167",
	publisher = "Wiley Online Library",
	title = "{Different activation dynamics in multiple neural systems during simulated driving}",
	volume = "16",
	x-color = "#ffffa5",
	year = "2002"
}

@article{codispoti_2008_emotional_movies,
	abstract = "Previous studies have found that unpleasant film clips depicting mutilated bodies or injuries evoke a sustained heart rate deceleration which has been interpreted as reflecting a stimulus-specific aversive response or as increased orienting and attentional processing that varies with stimulus significance. Few studies, however, have examined cardiac changes during the viewing of high arousal pleasant films. To clarify this issue, the present study assessed evaluative, facial and autonomic reactions in both men and women during the viewing of highly arousing pleasant, as well as unpleasant, films. Results indicated a similar skin conductance increase and heart rate deceleration which were greater than those observed during the viewing of a neutral film. Compared to men, women rated both films as less pleasant and rated the unpleasant film as more arousing. The present findings suggest that sustained exposure to pleasant and unpleasant stimuli elicit similar cardiac orienting when stimuli are equated for subjective report of emotional arousal.",
	author = "Maurizio Codispoti and Paola Surcinelli and Bruno Baldaro",
	doi = "10.1016/j.ijpsycho.2008.03.004",
	journal = "Intrnational Journal of Psychphysioloy",
	keywords = "Emotion; Orienting; Heart rate; Respiratory sinus arrhythmia; Gender; clips",
	localfile = "/home/chris/studium/masterarbeit/paper/Codispoti (2008). Watching emotional movies. Affective reactions and gender differences.pdf",
	month = aug,
	nlmuniqueid = "8406214",
	number = "2",
	pages = "90--95",
	pii = "S0167-8760(08)00076-7",
	pubmed = "18433903",
	title = "{Watching emotional movies: Affective reactions and gender differences}",
	volume = "69",
	x-fetchedfrom = "PubMed",
	year = "2008"
}

@article{corradi_2008_shifting_perspective_of_self,
	abstract = "When looking to our reflection, or moving a video-game character, we see our own movement preformed by an agent which is physically separated from our body. Yet, we consider the agent to be ourself. Using fMRI, we sought to explore the neural underpinnings of disembodiment, the cognitive mechanism under which the properties of the self are projected away from the boundaries of one{\rq}s own body towards an external entity. Seventeen participants watched a video-game in which three players threw each other a ball. Subjects{\rq} key-press could either be synchronous or asynchronous with one of the players{\rq} action (TASK: Agency vs. Control). The game was shown from one of four viewpoints which could either be fixed or change every trial (VIEWS: Fixed vs. Changeable). Consistent with previous studies, the left insula was activated when the agent{\rq}s movements were synchronous with those of the participants (main effect of TASK, p b 0.05, SVC). The analysis of the interaction TASK â VIEWS revealed activation ( p b 0.05, corrected) of the right parieto-temporal-occipital (PTO) junction when the agent whose movements were synchronous to the participants was processed in a spatial position each time different with respect to the preceding trials. Our findings implicate the right PTO junction in assigning one{\rq}s own movements to an agent which is physically independent of oneself. They also suggest that the ability to disembody, and thereby objectify, bodily or mental states concerning the self is common to all experimental para- digms which led to an activation of the PTO junction.",
	author = "Corrado Corradi-Dell{\rq}Acqua and Kenichi Ueno and Akitoshi Ogawa and Kang Cheng and Raffaella I Rumiati and Atsushi Iriki",
	keywords = "Agency; Disembodiment; Self-objectification; Temporo-parietal junction; Theory of mind; left insula; right parieto-temporal-occipital junction (PTO)",
	localfile = "/home/chris/studium/masterarbeit/paper/Corradi-Dell{\rq}acqua (2008). Effects of shifting perspective of the self.pdf",
	title = "{Effects of shifting perspective of the self: an fMRI study}",
	x-color = "#009966",
	year = "2008"
}

@article{creem_2001_imagined_self-rotation,
	abstract = "In the present study, functional magnetic resonance imaging was used to examine the neural mech- anisms involved in the imagined spatial transformation of one{\rq}s body. The task required subjects to up- date the position of one of four external objects from memory after they had performed an imagined self-rotation to a new position. Activation in the rotation condition was compared with that in a con- trol condition in which subjects located the positions of objects without imagining a change in self- position. The results indicated similar networks of activation to other egocentric transformation tasks involving decisions about body parts. The most significant area of activation was in the left posterior parietal cortex. Other regions of activation common among several of the subjects were secondary vi- sual, premotor, and frontal lobe regions. These results are discussed relative to motor and visual im- agery processes as well as to the distinctions between the present task and other imagined egocentric transformation tasks.",
	author = "Sarah H Creem and Traci Hirsch Downs and Maryjane Wraga and Gregory S Harrington and Dennis R Proffitt and J Hunter Downs",
	journal = "Cognitive, Affective, \& Behavioral Neuroscience",
	keywords = "fMRI; mental transformation; body; imagined; left posterior parietal cortex; self-rotation; egocentric transformation task",
	localfile = "/home/chris/studium/masterarbeit/paper/Creem (2001). fMRI study of imagined self-rotation.pdf",
	number = "3",
	pages = "239--249",
	publisher = "Springer",
	title = "{An fMRI study of imagined self-rotation}",
	volume = "1",
	x-color = "#ffff00",
	year = "2001"
}

@article{cutting_2014_representation_of_space_in_movies,
	abstract = "Popular movies present chunk-like events (scenes and subscenes) that promote episodic, serial updating of viewers{\rq} representations of the ongoing narrative. Event-indexing theory would suggest that the beginnings of new scenes trigger these updates, which in turn require more cognitive pro- cessing. Typically, a new movie event is signaled by an establishing shot, one providing more background information and a longer look than the average shot. Our analysis of 24 films recon- firms this. More important, we show that, when returning to a previously shown location, the re-establishing shot reduces both context and duration while remaining greater than the average shot. In general, location shifts dominate character and time shifts in event segmentation of movies. In addition, over the last 70 years re-establishing shots have become more like the noninitial shots of a scene. Establishing shots have also approached noninitial shot scales, but not their durations. Such results suggest that film form is evolving, perhaps to suit more rapid encoding of narrative events.",
	author = "James Cutting and Catalina Iricinschi",
	journal = "Cognitive Science",
	keywords = "Discourse; Segmentation Events; Given/new information; Movies; Narrative; Perception; Segmentation; establishing shot",
	localfile = "/home/chris/studium/masterarbeit/paper/Cutting (2014). Re-Presentations of Space in Hollywood Movies. An Event-Indexing Analysis.pdf",
	title = "{Re-Presentations of Space in Hollywood Movies: An Event-Indexing Analysis}",
	x-color = "#ffff00",
	year = "2014"
}

@article{cutting_2014_event_segmentation_7_types_of_discontinuity_in_movies,
	abstract = "Using a sample of 24 movies I investigate narrative shifts in location, characters, and time frame that do and do not align with viewer segmentations of events (scenes and subscenes) in popular movies. Taken independently these dimensions create eight categories, seven of change and one of nonchange. Data show that the more dimensions that are changed the more viewers agree on their segmentations, although the nonadditive variations across the seven change types are large and systematic. Dissolves aid segmentation but over the last 70 years they have been used less and less by filmmakers, except for two infrequent shift types. Locations and characters are strongly yoked, jointly accounting for most narrative shifts. There are also interactions of shift types over the 70-year span and across genres, as well as differences that affect the scale of the establishing shot in a new scene. In addition, several aspects of the narratives of individual movies affect the distributions of shift types. Together these results suggest that there are at least four different signatures of narrative shifts to be found in popular movies --- general patterns across time, patterns of historical change, genre-specific patterns, and film-specific patterns.",
	author = "James E. Cutting",
	journal = "Acta Psychologica",
	keywords = "Events; Film style; Movies; Narrative Scenes; Segmentation",
	localfile = "/home/chris/studium/masterarbeit/paper/Cutting (2014). Event segmentation and seven types of narrative discontinuity in popular movies.pdf",
	number = "149",
	pages = "69--77",
	title = "{Event segmentation and seven types of narrative discontinuity in popular movies}",
	x-color = "#ffff00",
	year = "2014"
}

@article{cutting_2013_movies_evolution_mind,
	author = "James E Cutting and Ayse Candan",
	journal = "The Evolutionary Review",
	keywords = "continuity editing",
	localfile = "/home/chris/studium/masterarbeit/paper/Cutting (2013). Movies, Evolution, and Mind. From Fragmentation to Continuity.pdf",
	number = "1",
	pages = "25--36",
	publisher = "State University of New York Press",
	title = "{Movies, evolution, and mind: From fragmentation to continuity}",
	volume = "4",
	year = "2013"
}

@article{daloia_2012_upside_down_cinema,
	author = "Adriano D{\rq}Aloia",
	journal = "Cinema: Journal of Philosophy of the Moving Image",
	localfile = "/home/chris/studium/masterarbeit/paper/D'Aloia (2012). Upside-Down Cinema. (Dis)Simulation of the body in the film experience.pdf",
	number = "3",
	title = "{Upside-Down Cinema: (Dis)Simulation of the Body in the Film Experience}",
	year = "2012"
}

@article{david_2006_perspective_taking_ball_tossing_game,
	abstract = "Human self-consciousness relies on the ability to distinguish between oneself and others. We sought to explore the neural correlates involved in self--other representations by investigating two critical processes: perspective taking and agency. Although recent research has shed light on the neural processes underly- ing these phenomena, little is known about how they overlap or interact at the neural level. In a two-factorial functional mag- netic resonance imaging (fMRI) experiment, participants played a ball-tossing game with two virtual characters ({\lq}{\lq}avatars{\rq}{\rq}). During an active/agency (ACT) task, subjects threw a ball to one of the avatars by pressing a button. During a passive/ nonagency (PAS) task, they indicated which of the other avatars threw the ball. Both tasks were performed from a first-person perspective (1PP), in which subjects interacted from their own perspective, and a third-person perspective (3PP), in which sub- jects interacted from the perspective of an avatar with another location in space. fMRI analyses revealed overlapping activity in medial prefrontal regions associated with representations of one{\rq}s own perspective and actions (1PP and ACT), and overlap- ping activity in temporal--occipital, premotor, and inferior frontal, as well as posterior parietal regions associated with representa- tion of others{\rq} perspectives and actions (3PP and PAS). These findings provide evidence for distinct neural substrates under- lying representations of the self and others and provide support for the idea that the medial prefrontal cortex crucially contrib- utes to a neural basis of the self. The lack of a statistically sig- nificant interaction suggests that perspective taking and agency represent independent constituents of self-consciousness.",
	author = "Nicole David and Bettina H Bewernick and Mark S Cohen and Albert Newen and Silke Lux and Gereon R Fink and N Jon Shah and Kai Vogeley",
	journal = "Cognitive Neuroscience, Journal of",
	keywords = "virtual; ball-tossing game",
	localfile = "/home/chris/studium/masterarbeit/paper/David (2006). Neural representations of self versus other visual-spatial perspective taking and agency in a virtial ball-tossing game.pdf",
	number = "6",
	pages = "898--910",
	publisher = "MIT Press",
	title = "{Neural representations of self versus other: visual-spatial perspective taking and agency in a virtual ball-tossing game}",
	volume = "18",
	x-color = "#ffffa5",
	year = "2006"
}

@article{decety_2007_tpj_review,
	abstract = "Accumulating evidence from cognitive neuroscience indicates that the right inferior parietal cortex, at the junc- tion with the posterior temporal cortex, plays a critical role in various aspects of social cognition such as theory of mind and empathy. With a quantitative meta-analysis of 70 functional neuroimaging studies, the authors demonstrate that this area is also engaged in lower-level (bottom-up) computational processes associated with the sense of agency and reorienting attention to salient stimuli. It is argued that this domain-general computational mechanism is crucial for higher level social cognitive processing.",
	author = "Jean Decety and Claus Lamm",
	keywords = "Temporoparietal junction; Self/other distinction; Agency; Social cognition; Theory of mind; Empathy; Attention; meta-analysis",
	localfile = "/home/chris/studium/masterarbeit/paper/Decety & Lamm (2007). The Role of the parietal temporoparietal junction (review).pdf",
	title = "{The role of the right temporoparietal junction in social interaction: How low-level computational processes contribute to meta-cognition}",
	year = "2007"
}

@article{dmochowski_2014_walking_dead_tweets,
	author = "Jacek P Dmochowski and Matthew A Bezdek and Brian P Abelson and John S Johnson and Eric H Schumacher and Lucas C Parra",
	journal = "Nature communications",
	keywords = "TV; fMRI; social media; EEG; intersubject-correlation",
	localfile = "/home/chris/studium/masterarbeit/paper/Dmochowski (2014). Audience preferences are predicted by temporal reliability of neural processing",
	publisher = "Nature Publishing Group",
	title = "{Audience preferences are predicted by temporal reliability of neural processing}",
	volume = "5",
	year = "2014"
}

@article{dorr_2010_variability_of_eye_moves_dynamic_scenes,
	abstract = {How similar are the eye movement patterns of different subjects when free viewing dynamic natural scenes? We collected a large database of eye movements from 54 subjects on 18 high-resolution videos of outdoor scenes and measured their variability using the Normalized Scanpath Saliency, which we extended to the temporal domain. Even though up to about 80\% of subjects looked at the same image region in some video parts, variability usually was much greater. Eye movements on natural movies were then compared with eye movements in several control conditions. "Stop-motion" movies had almost identical semantic content as the original videos but lacked continuous motion. Hollywood action movie trailers were used to probe the upper limit of eye movement coherence that can be achieved by deliberate camera work, scene cuts, etc. In a "repetitive" condition, subjects viewed the same movies ten times each over the course of 2 days. Results show several systematic differences between conditions both for general eye movement parameters such as saccade amplitude and fixation duration and for eye movement variability. Most importantly, eye movements on static images are initially driven by stimulus onset effects and later, more so than on continuous videos, by subject-specific idiosyncrasies; eye movements on Hollywood movies are significantly more coherent than those on natural movies. We conclude that the stimuli types often used in laboratory experiments, static images and professionally cut material, are not very representative of natural viewing behavior. All stimuli and gaze data are publicly available at http://www.inb.uni-luebeck.de/tools-demos/gaze.},
	author = "Michael Dorr and Thomas Martinetz and Karl R Gegenfurtner and Erhardt Barth",
	journal = "Journal of Vision",
	localfile = "/home/chris/studium/masterarbeit/paper/Dorr (2010). Variability of eye movements when viewing dynamic natural scenes.pdf",
	nlmuniqueid = "101147197",
	number = "10",
	pages = "1--17",
	pii = "10.10.28",
	pubmed = "20884493",
	title = "{Variability of eye movements when viewing dynamic natural scenes}",
	volume = "10",
	x-color = "#ffff00",
	x-fetchedfrom = "PubMed",
	year = "2010"
}

@incollection{ehrsson_2012_concept-body-ownership,
	address = "Cambridge",
	author = "H.H. Ehrsson",
	booktitle = "{The New Handbook of Multisensory Processes}",
	editor = "B.E. Stein",
	localfile = "/home/chris/studium/masterarbeit/paper/Ehrsson (2012). The concept of body ownership and its relation to multisensory integration (review).pdf",
	owner = "chris",
	pages = "775--792",
	publisher = "MIT Press",
	quality = "1",
	timestamp = "2013.10.11",
	title = "{The concept of body ownership and its relation to multisensory integration}",
	year = "2012"
}

@book{elkins_2009_camera_assistants_manual,
	author = "David E. Elkins",
	edition = "5",
	isbn = "9780240810577",
	keywords = "cinematography",
	localfile = "/home/chris/studium/masterarbeit/cinematography /Elkins - The Camera Assistants Manual (5th ed., 2009).pdf",
	month = "3",
	publisher = "Focal Press",
	timestamp = "2015.07.31",
	title = "{The Camera Assistant's Manual}",
	totalpages = "544",
	url = "http://amazon.com/o/ASIN/0240810570",
	year = "2009"
}

@article{epstein_2003_viewpoint-specific_scene_representation_parahippocampal,
	abstract = "The ``parahippocampal place area'' (PPA) responds more strongly in functional magnetic resonance imaging (fMRI) to scenes than to faces, objects, or other visual stimuli. We used an event-related fMRI adaptation paradigm to test whether the PPA represents scenes in a viewpoint-specific or viewpoint-invariant manner. The PPA responded just as strongly to view-point changes that preserved intrinsic scene geometry as it did to complete scene changes, but less strongly to object changes within the scene. In contrast, lateral occipital cortex responded more strongly to object changes than to spatial changes. These results demonstrate that scene processing in the PPA is viewpoint specific and suggest that the PPA represents the relationship between the observer and the surfaces that define local space.",
	author = "Russell Epstein and Kim S Graham and Paul E Downing",
	journal = "Neuron",
	keywords = "parahippocampal place area; PPA; fMRI; viewpoint",
	localfile = "/home/chris/studium/masterarbeit/paper/Epstein (2003). Viewpoint-Specific Scene Representations in Human Parahippocampal Cortex.pdf",
	number = "5",
	pages = "865--876",
	publisher = "Elsevier",
	title = "{Viewpoint-specific scene representations in human parahippocampal cortex}",
	volume = "37",
	x-color = "#ffff00",
	year = "2003"
}

@article{epstein_1999_parahippocampal_place_area,
	abstract = "The parahippocampal place area (PPA) has been dem- onstrated to respond more strongly in fMRI to scenes depicting places than to other kinds of visual stimuli. Here, we test several hypotheses about the function of the PPA. We find that PPA activity (1) is not affected by the subjects{\rq} familiarity with the place depicted, (2) does not increase when subjects experience a sense of motion through the scene, and (3) is greater when viewing novel versus repeated scenes but not novel versus repeated faces. Thus, we find no evidence that the PPA is involved in matching perceptual information to stored representations in memory, in planning routes, or in monitoring locomotion through the local or distal environment but some evidence that it is in- volved in encoding new perceptual information about the appearance and layout of scenes.",
	author = "Russell Epstein and Alison Harris and Damian Stanley and Nancy Kanwisher",
	journal = "Neuron",
	localfile = "/home/chris/studium/masterarbeit/paper/Epstein (1999). The Parahippocampal Place Area. Recognition, Navigation, or Encoding.pdf",
	number = "1",
	pages = "115--125",
	publisher = "Elsevier",
	title = "{The parahippocampal place area: Recognition, navigation, or encoding?}",
	volume = "23",
	x-color = "#ffff00",
	year = "1999"
}

@article{farrell_2000_updating_egocentric_spatial_relationships,
	abstract = "The non-visual updating of body-centred spatial relationships was investigated in an experiment in which blindfolded patients had to point to previously seen targets after a body rotation in the absence of vision. Patients with lesions to the right dorsal (RD) area were impaired at updating their positions relative to non-RD patients and normal subjects: they tended to underestimate systematically the angle through which they had turned. The results are interpreted in terms of impoverished locomotor input and/or systematically biased processing or locomotor proprioception in the RD patients, which prevented accurate tracking of changes in egocentric spatial relationships.",
	author = "Martin J Farrell and Ian H Robertson",
	journal = "Neuropsychologia",
	keywords = "Spatial; Orientation; Egocentric; Dorsal stream; body-centered; patients",
	localfile = "/home/chris/studium/masterarbeit/paper/Farrell (2000). Automatic updating of egocentric spatial relationships and its impairment due to right posterior cortical lesions.pdf",
	number = "5",
	pages = "585--595",
	publisher = "Elsevier",
	title = "{The automatic updating of egocentric spatial relationships and its impairment due to right posterior cortical lesions}",
	volume = "38",
	x-color = "#ffff00",
	year = "2000"
}

@article{furman_2007_they_saw_movie,
	abstract = "We measured long-term memory for a narrative film. During the study session, participants watched a 27-min movie episode, without instructions to remember it. During the test session, administered at a delay ranging from 3 h to 9 mo after the study session, long-term memory for the movie was probed using a computerized questionnaire that assessed cued recall, recognition, and metamemory of movie events sampled âŒ20 sec apart. The performance of each group of participants was measured at a single time point only. The participants remembered many events in the movie even months after watching it. Analysis of performance, using multiple measures, indicates differences between recent (weeks) and remote (months) memory. While high-confidence recognition performance was a reliable index of memory throughout the measured time span, cued recall accuracy was higher for relatively recent information. Analysis of different content elements in the movie revealed differential memory performance profiles according to time since encoding. We also used the data to propose lower limits on the capacity of long-term memory. This experimental paradigm is useful not only for the analysis of behavioral performance that results from encoding episodes in a continuous real-life-like situation, but is also suitable for studying brain substrates and processes of real-life memory using functional brain imaging.",
	author = "Orit Furman and Nimrod Dorfman and Uri Hasson and Lila Davachi and Yadin Dudai",
	journal = "Learning \& Memory",
	keywords = "long-term memory; recall; recognition",
	localfile = "/home/chris/studium/masterarbeit/paper/Furman (2007). They saw a movie.pdf",
	number = "6",
	pages = "457--467",
	publisher = "Cold Spring Harbor Lab",
	title = "{They saw a movie: Long-term memory for an extended audiovisual narrative}",
	volume = "14",
	x-color = "#ffffa5",
	year = "2007"
}

@article{gardner_2011_imagined_transformations_whole_bodyperspective,
	author = "Mark R. Gardner and Rosalind Potts",
	keywords = "Perspective taking; Spatial compatibility; Mental rotation; Own body transformation; Temporoparietal junction; Embodiment",
	localfile = "/home/chris/studium/masterarbeit/paper/Gardner (2011). Domain general mechanisms account for imagined transformations of whole body perspective.pdf",
	title = "{Domain general mechanisms account for imagined transformations of whole body perspective}",
	year = "2011"
}

@article{goldstein_2006_where_look_watching_movies,
	abstract = "Magnification around the most important point of a movie scene (center of interest---COI) might aid people with visual impairments that cause resolution loss. This will be effective only if most people look at the same place when watching a movie. We recorded the eye movements of 20 normally sighted subjects as each watched six movie clips, totaling 37.5 min. More than half of the time the distribution of subject gaze points fell within an area statistic that was less than 12\% of the movie scene. Male and older subjects were more likely to look in the same place than female and younger subjects, respectively. We conclude that the between-subject agreement is sufficient to make the approach practical.",
	added-at = "2012-05-21T00:00:00.000+0200",
	author = "Robert B. Goldstein and Russell L. Woods and Eli Peli",
	interhash = "3dc98be33aad71148414ed0d1f76a225",
	intrahash = "a8d35a1681d12a4199119e37d646688c",
	journal = "Computers in Biology and Medicine",
	keywords = "eye movements; video",
	localfile = "/home/chris/studium/masterarbeit/paper/Goldstein (2007). Where people look when watching movies.pdf",
	number = "7",
	pages = "957--964",
	title = "{Where people look when watching movies: Do all viewers look at the same place?}",
	volume = "37",
	x-color = "#ffff00",
	x-fetchedfrom = "Bibsonomy",
	year = "2007"
}

@article{golland_2007_extrinsic_and_intrinsic,
	abstract = {When exposing subjects to a continuous segment of an audiovisual movie, a large expanse of human cortex, especially in the posterior half of the cerebral cortex, shows stimulus-driven activity. However, embedded within this widespread activity, there are cortical regions whose activity is dissociated from the external stimulation. These regions are intercorrelated among themselves, forming a functional network, which largely overlaps with cortical areas previously shown to be deactivated by task-oriented paradigms. Moreover, the network of areas whose neuronal dynamics are associated with external inputs and the network of areas that appears to be intrinsically driven complement each other, providing coverage of most of the posterior cortex. Thus, we propose that naturalistic stimuli reveal a fundamental neuroanatomical partition of the human posterior cortex into 2 global networks: an "extrinsic" system, comprising areas associated with the processing of external inputs, and an "intrinsic" system, largely overlapping with the task-negative, default-mode network, comprising areas associated with--as yet not fully understood--intrinsically oriented functions.},
	author = "Yulia Golland and Shlomo Bentin and Hagar Gelbard and Yoav Benjamini and Ruth Heller and Yuval Nir and Uri Hasson and Rafael Malach",
	journal = "Cerebral Cortex",
	keywords = "default mode; fMRI; global network; intrinsic; natural viewing; The Good; the Bad; and the Ugly",
	localfile = "/home/chris/studium/masterarbeit/paper/Golland (2007). Extrinsic and Intrinsic Systems in the Posterior Cortex of the Human Brain Revealed during Natural Sensory Stimulation.pdf",
	month = apr,
	nlmuniqueid = "9110718",
	note = {stimulus: "The Good, the Bad, and the Ugly"},
	number = "4",
	pages = "766--777",
	pii = "bhk030",
	pubmed = "16699080",
	title = "{Extrinsic and intrinsic systems in the posterior cortex of the human brain revealed during natural sensory stimulation}",
	volume = "17",
	x-color = "#ffffa5",
	x-fetchedfrom = "PubMed",
	year = "2007"
}

@phdthesis{hanke_2009_PhD_mvpa,
	author = "Michael Hanke",
	file = ":Hanke2009a.pdf:PDF",
	review = "Advancing the Understanding of Brain Function with Multivariate Pattern Analysis Der Fakultï¿œt fï¿œr Naturwissenschaften der Otto-von-Guericke-Universitï¿œt Magdeburg zur Erlangung des akademischen Grades doctor rerum naturalium (Dr. rer. nat.) am 24. Mï¿œrz 2009 eingereichte Dissertation, vorgelegt von Dipl.-Psych. Michael Hanke",
	title = "{Advancing the Understanding of Brain Function with Multivariate Pattern Analysis}",
	year = "2009"
}

@article{hanke_2014_high-resolution_dataset,
	abstract = "Here we present a high-resolution functional magnetic resonance (fMRI) dataset -- 20 participants recorded at high field strength (7 Tesla) during prolonged stimulation with an auditory feature film (``Forrest Gump''). In addition, a comprehensive set of auxiliary data (T1w, T2w, DTI, susceptibility-weighted image, angiography) as well as measurements to assess technical and physiological noise components have been acquired. An initial analysis confirms that these data can be used to study common and idiosyncratic brain response patterns to complex auditory stimulation. Among the potential uses of this dataset are the study of auditory attention and cognition, language and music perception, and social perception. The auxiliary measurements enable a large variety of additional analysis strategies that relate functional response patterns to structural properties of the brain. Alongside the acquired data, we provide source code and detailed information on all employed procedures -- from stimulus creation to data analysis. In order to facilitate replicative and derived works, only free and open-source software was utilized.",
	author = "Michael Hanke and Florian J Baumgartner and Pierre Ibe and Falko R Kaule and Stefan Pollmann and Oliver Speck and Wolf Zinke and Jï¿œrg Stadler",
	journal = "Scientific Data",
	localfile = "/home/chris/studium/masterarbeit/paper/Hanke (2014). A high-resolution 7-Tesla fMRI dataset from complex natural stimulation with an audio movie.pdf",
	pages = "1--18",
	publisher = "Nature Publishing Group",
	title = "{A high-resolution 7-Tesla fMRI dataset from complex natural stimulation with an audio movie}",
	volume = "1",
	year = "2014"
}

@article{hanke_2010_statistical_learning,
	abstract = {Encouraged by a rise of reciprocal interest between the machine learning and neuroscience communities, several recent studies have demonstrated the explanatory power of statistical learning techniques for the analysis of neural data. In order to facilitate a wider adoption of these methods, neuroscientific research needs to ensure a maximum of transparency to allow for comprehensive evaluation of the employed procedures. We argue that such transparency requires "neuroscience-aware" technology for the performance of multivariate pattern analyses of neural data that can be documented in a comprehensive, yet comprehensible way. Recently, we introduced PyMVPA, a specialized Python framework for machine learning based data analysis that addresses this demand. Here, we review its features and applicability to various neural data modalities.},
	author = "Michael Hanke and Yaroslav O Halchenko and James V Haxby and Stefan Pollmann",
	journal = "Frontiers in Neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Hanke (2010). Statistical Learning Analysis in Neuroscience. Aiming for Transparency.pdf",
	nlmuniqueid = "101478481",
	pages = "38--43",
	pmc = "PMC2891484",
	pubmed = "20582270",
	title = "{Statistical learning analysis in neuroscience: Aiming for transparency}",
	url = "https://ncbi.nlm.nih.gov/pmc/articles/PMC2891484",
	volume = "4",
	x-fetchedfrom = "PubMed",
	year = "2010"
}

@article{hanke_2009_PyMVPA_unifying,
	abstract = "The Python programming language is steadily increasing in popularity as the language of choice for scientific computing. The ability of this scripting environment to access a huge code base in various languages, combined with its syntactical simplicity, make it the ideal tool for implementing and sharing ideas among scientists from numerous fields and with heterogeneous methodological backgrounds. The recent rise of reciprocal interest between the machine learning (ML) and neuroscience communities is an example of the desire for an inter-disciplinary transfer of computational methods that can benefit from a Python-based framework. For many years, a large fraction of both research communities have addressed, almost independently, very high-dimensional problems with almost completely non-overlapping methods. However, a number of recently published studies that applied ML methods to neuroscience research questions attracted a lot of attention from researchers from both fields, as well as the general public, and showed that this approach can provide novel and fruitful insights into the functioning of the brain. In this article we show how PyMVPA, a specialized Python framework for machine learning based data analysis, can help to facilitate this inter-disciplinary technology transfer by providing a single interface to a wide array of machine learning libraries and neural data-processing methods. We demonstrate the general applicability and power of PyMVPA via analyses of a number of neural data modalities, including fMRI, EEG, MEG, and extracellular recordings.",
	author = "Michael Hanke and Yaroslav O Halchenko and Per B Sederberg and Emanuele Olivetti and Ingo Frï¿œnd and Jochem W Rieger and Christoph S Herrmann and James V Haxby and Stephen Josï¿œ Hanson and Stefan Pollmann",
	doi = "10.3389/neuro.11.003.2009",
	journal = "Frontiers in Neuroinformatics",
	nlmuniqueid = "101477957",
	pages = "1--13",
	pmc = "PMC2638552",
	pubmed = "19212459",
	title = "{PyMVPA: A Unifying Approach to the Analysis of Neuroscientific Data}",
	volume = "3",
	x-fetchedfrom = "PubMed",
	year = "2009"
}

@article{hanson_2009_eigenvalue_problem,
	abstract = "Brain measures often show highly structured temporal dynamics that synchronize when observers are doing the same task. The standard method for analysis of brain imaging signals (e.g. fMRI) uses the GLM for each voxel indexed against a specified experimental design but does not explicitly involve temporal dynamics. Consequently, the design variables that determine the functional brain areas are those correlated with the design variation rather than the common or conserved brain areas across subjects with the same temporal dynamics given the same stimulus conditions. This raises an important theoretical question: Are temporal dynamics conserved across individuals experiencing the same stimulus task? This general question can be framed in a dynamical systems context and further be posed as an eigenvalue problem about the conservation of synchrony across all brains simultaneously. We show that solving the problem results in a non-arbitrary measure of temporal dynamics across brains that scales over any number of subjects, stabilizes with increasing sample size, and varies systematically across tasks and stimulus conditions.",
	added-at = "2012-07-02T00:00:00.000+0200",
	author = "S. J. Hanson and A. D. Gagliardi and Catherine Hanson",
	interhash = "4ca75628580ef8c7464d75725fab19ea",
	intrahash = "514408ef9b07d7ccf2bf75b23005d6e6",
	journal = "Journal of Computational Neuroscience",
	keywords = "Neuroimaging; Time series; Eigenvalue; Event perception; Synchrony; Temporal dynamics; Inter-subject-correlation",
	localfile = "/home/chris/studium/masterarbeit/paper/Hanson (2009). Solving the brain synchrony eigenvalue problem. conservation of temporal dynamics (fMRI).pdf",
	number = "1",
	pages = "103--114",
	title = "{Solving the brain synchrony eigenvalue problem: conservation of temporal dynamics (fMRI) over subjects doing the same task.}",
	url = "http://dx.doi.org/10.1007/s10827-008-0129-z; http://www.bibsonomy.org/bibtex/2514408ef9b07d7ccf2bf75b23005d6e6/dblp",
	volume = "27",
	x-fetchedfrom = "Bibsonomy",
	year = "2009"
}

@article{hartley_2003_well-worn_route,
	author = "Tom Hartley and Eleanor A Maguire and Hugo J Spiers and Neil Burgess",
	journal = "Neuron",
	localfile = "/home/chris/studium/masterarbeit/paper/Hartley (2003). The Well-Worn Route and the Path Less Traveled. Distinct Neural Bases of Route Following and Wayfinding in Humans.pdf",
	number = "5",
	pages = "877--888",
	publisher = "Elsevier",
	title = "{The well-worn route and the path less traveled: Distinct neural bases of route following and wayfinding in humans}",
	volume = "37",
	x-color = "#ffffa5",
	year = "2003"
}

@article{hasson_2008_correlations_during_movie,
	abstract = "While much has been learned regarding the neural substrates supporting episodic encoding using highly controlled experimental protocols, relatively little is known regarding the neural bases of episodic encoding of real-world events. In an effort to examine this issue, we measured fMRI activity while observers viewed a novel TV sitcom. Three weeks later, subsequent memory (SM) for the narrative content of movie events was assessed. We analyzed the encoding data for intersubject correlations (ISC) based on subjects' subsequent memory (ISC-SM) performance to identify brain regions whose BOLD response is significantly more correlated across subjects during portions of the movie that are successfully as compared to unsuccessfully encoded. These regions include the parahippocampal gyrus, superior temporal gyrus, anterior temporal poles, and the temporal-parietal junction. Further analyses reveal (1) that these correlated regions can display distinct activation profiles and (2) that the results seen with the ISC-SM analysis are complementary to more traditional linear models and allow analysis of complex time course data. Thus, the ISC-SM analysis extends traditional subsequent memory findings to a rich, dynamic and more ecologically valid situation.",
	author = "Uri Hasson and Orit Furman and Dav Clark and Yadin Dudai and Lila Davachi",
	journal = "Neuron",
	keywords = "intersubject-correlation; TV sitcom; parahippocampal gyrus; superior temporal gyrus; anterior temporal poles; temporal-parietal junction",
	localfile = "/home/chris/studium/masterarbeit/paper/Hasson (2008). Enhanced intersubject correlations during movie viewing correlate with successful episodic encoding.pdf",
	mid = "NIHMS157847",
	month = feb,
	nlmuniqueid = "8809320",
	note = {stimulus: "Curb Your Enthusiasm" TV series},
	number = "3",
	pages = "452--462",
	pii = "S0896-6273(07)01008-2",
	pmc = "PMC2789242",
	pubmed = "18255037",
	title = "{Enhanced intersubject correlations during movie viewing correlate with successful episodic encoding}",
	volume = "57",
	x-color = "#0033ff",
	x-fetchedfrom = "PubMed",
	year = "2008"
}

@article{hasson_2008_neurocinematics,
	abstract = "This article describes a new method for assessing the effect of a given film on viewers' brain activity. Brain activity was measured using functional magnetic resonance imaging (fMRI) during free viewing of films, and inter-subject correlation analysis (ISC) was used to assess similarities in the spatiotemporal responses across viewers' brains during movie watching. Our results demonstrate that some films can exert considerable control over brain activity and eye movements. However, this was not the case for all types of motion picture sequences, and the level of control over viewers' brain activity differed as a function of movie content, editing, and directing style. We propose that ISC may be useful to film studies by providing a quantitative neuroscientific assessment of the impact of different styles of filmmaking on viewers' brains, and a valuable method for the film industry to better assess its products. Finally, we suggest that this method brings together two separate and largely unrelated disciplines, cognitive neuroscience and film studies, and may open the way for a new interdisciplinary field of ``neurocinematic'' studies.",
	author = "Uri Hasson and Ohad Landesman and Barbara Knappmeyer and Ignacio Vallines and Nava Rubin and David J Heeger",
	journal = "Projections",
	keywords = "review",
	localfile = "/home/chris/studium/masterarbeit/paper/Hasson (2008). Neurocinematics.pdf",
	number = "1",
	pages = "1--26",
	publisher = "Berghahn Journals",
	title = "{Neurocinematics: The neuroscience of film}",
	url = "http://www.ingentaconnect.com/content/berghahn/proj/2008/00000002/00000001/art00002",
	volume = "2",
	x-color = "#0033ff",
	year = "2008"
}

@inproceedings{hasson_2006_human_brain_during_dynamic_scenes,
	abstract = "To what extent do brains of different human individuals operate in a similar manner? Here we explored the organization and function of different brain regions under progressively more natural conditions. Applying an unbiased analysis, in which spatio- temporal activity patterns in one brain were used to {\lq}model{\rq} activity in another brain, we found a striking level of voxel by voxel synchronization between individuals during free viewing of an audio-visual movie. This intersubject correlation was evident not only in primary and secondary visual and auditory areas, but also in association cortices. The results reveal a surprising tendency of individual brains to {\lq}tick collectively{\rq} during natural vision. Moreover, our results demonstrate that the unitary nature of conscious experience in fact consists of temporally interleaved and highly selective activations in an ensemble of specialized regions, each of which {\lq}picks-up{\rq} and analyses its own unique subset of stimuli according to its functional specialization. Applying reverse correlation to the movie stimuli provides a powerful methodology for revealing the both known and unexpected functional specializations in those cortical areas activated by the movie.",
	author = "Uri Hasson and Rafael Malach",
	booktitle = "{Novartis Foundation Symposium}",
	localfile = "/home/chris/studium/masterarbeit/paper/Hasson (2005). Human Brain Activation During Viewing of Dynamic Natural Scenes.pdf",
	organization = "Chichester; New York; John Wiley; 1999",
	pages = "203--216",
	title = "{Human brain activation during viewing of dynamic natural scenes}",
	volume = "270",
	x-color = "#ffff00",
	year = "2006"
}

@article{hasson_2009_natural_stim_review,
	abstract = "Response reliability is complementary to more conventional measurements of response amplitudes, and can reveal phenomena that response amplitudes do not. Here we review studies that measured reliability of cortical activity within or between human subjects in response to naturalistic stimulation (e.g. free viewing of movies). Despite the seemingly uncontrolled nature of the task, some of these complex stimuli evoke highly reliable, selective and time-locked activity in many brain areas, including some regions that show little response modulation in most conventional experimental protocols. This activity provides an opportunity to address novel questions concerning natural vision, temporal scale of processing, memory and the neural basis of inter-group differences.",
	author = "Uri Hasson and Rafael Malach and David J Heeger",
	journal = "Trends in Cognitive Sciences",
	keywords = "review",
	localfile = "/home/chris/studium/masterarbeit/paper/Hasson (2009). Reliability of cortical activity during natural stimulation.pdf",
	mid = "NIHMS157641",
	month = jan,
	nlmuniqueid = "9708669",
	number = "1",
	pages = "40--48",
	pii = "S1364-6613(09)00239-3",
	pmc = "PMC2818432",
	pubmed = "20004608",
	title = "{Reliability of cortical activity during natural stimulation}",
	volume = "14",
	x-color = "#0033ff",
	x-fetchedfrom = "PubMed",
	year = "2009"
}

@article{hasson_2004_synchronization_natural_vision,
	abstract = {To what extent do all brains work alike during natural conditions? We explored this question by letting five subjects freely view half an hour of a popular movie while undergoing functional brain imaging. Applying an unbiased analysis in which spatiotemporal activity patterns in one brain were used to "model" activity in another brain, we found a striking level of voxel-by-voxel synchronization between individuals, not only in primary and secondary visual and auditory areas but also in association cortices. The results reveal a surprising tendency of individual brains to "tick collectively" during natural vision. The intersubject synchronization consisted of a widespread cortical activation pattern correlated with emotionally arousing scenes and regionally selective components. The characteristics of these activations were revealed with the use of an open-ended "reverse-correlation" approach, which inverts the conventional analysis by letting the brain signals themselves "pick up" the optimal stimuli for each specialized cortical area.},
	author = "Uri Hasson and Yuval Nir and Ifat Levy and Galit Fuhrmann and Rafael Malach",
	journal = "Science",
	keywords = "The Good; The Bad; and The Ugly",
	localfile = "/home/chris/studium/masterarbeit/paper/Hasson (2004). Intersubject synchronization of cortical activity during natural vision.pdf",
	month = mar,
	nlmuniqueid = "0404511",
	number = "5664",
	pages = "1634--40",
	pii = "303/5664/1634",
	pubmed = "15016991",
	title = "{Intersubject synchronization of cortical activity during natural vision}",
	volume = "303",
	x-color = "#ffff00",
	x-fetchedfrom = "PubMed",
	year = "2004"
}

@article{hasson_2008_hierarchy_temporal_windows,
	abstract = "Real-world events unfold at different time scales and, therefore, cognitive and neuronal processes must likewise occur at different time scales. We present a novel procedure that identifies brain regions responsive to sensory information accumulated over different time scales. We measured functional magnetic resonance imaging activity while observers viewed silent films presented forward, backward, or piecewise-scrambled in time. Early visual areas (e.g., primary visual cortex and the motion-sensitive area MT+) exhibited high response reliability regardless of disruptions in temporal structure. In contrast, the reliability of responses in several higher brain areas, including the superior temporal sulcus (STS), precuneus, posterior lateral sulcus (LS), temporal parietal junction (TPJ), and frontal eye field (FEF), was affected by information accumulated over longer time scales. These regions showed highly reproducible responses for repeated forward, but not for backward or piecewise-scrambled presentations. Moreover, these regions exhibited marked differences in temporal characteristics, with LS, TPJ, and FEF responses depending on information accumulated over longer durations (approximately 36 s) than STS and precuneus (approximately 12 s). We conclude that, similar to the known cortical hierarchy of spatial receptive fields, there is a hierarchy of progressively longer temporal receptive windows in the human brain.",
	author = "Uri Hasson and Eunice Yang and Ignacio Vallines and David J Heeger and Nava Rubin",
	journal = "Journal of Neuroscience",
	keywords = "temporal coding; fMRI; cortex; receptive fields; functional organization; time; silent movies",
	localfile = "/home/chris/studium/masterarbeit/paper/Hasson (2008). A hierarchy of temporal receptive windows in human cortex.pdf",
	mid = "NIHMS60336",
	month = mar,
	nlmuniqueid = "8102140",
	number = "10",
	pages = "2539--2550",
	pii = "28/10/2539",
	pmc = "PMC2556707",
	pubmed = "18322098",
	title = "{A hierarchy of temporal receptive windows in human cortex}",
	volume = "28",
	x-color = "#ffff00",
	x-fetchedfrom = "PubMed",
	year = "2008"
}

@article{haxby_2012_mvpa_beginnings,
	added-at = "2013-02-06T00:00:00.000+0100",
	author = "James V. Haxby",
	interhash = "17d1f605e8479fb9efbbf5a495693c0c",
	intrahash = "8e720b8ea5facabf6ec46bc5d884641b",
	journal = "NeuroImage",
	keywords = "dblp",
	localfile = "/home/chris/studium/masterarbeit/paper/Haxby (2012). Multivariate pattern analysis of fMRI. The early beginnings.pdf",
	number = "2",
	pages = "852--855",
	title = "{Multivariate pattern analysis of fMRI: The early beginnings}",
	url = "http://dblp.uni-trier.de/db/journals/neuroimage/neuroimage62.html#Haxby12; http://dx.doi.org/10.1016/j.neuroimage.2012.03.016; http://www.bibsonomy.org/bibtex/28e720b8ea5facabf6ec46bc5d884641b/dblp",
	volume = "62",
	x-fetchedfrom = "Bibsonomy",
	year = "2012"
}

@article{haxby_2011_high-dimensional_model,
	abstract = {We present a high-dimensional model of the representational space in human ventral temporal (VT) cortex in which dimensions are response-tuning functions that are common across individuals and patterns of response are modeled as weighted sums of basis patterns associated with these response tunings. We map response-pattern vectors, measured with fMRI, from individual subjects' voxel spaces into this common model space using a new method, "hyperalignment." Hyperalignment parameters based on responses during one experiment--movie viewing--identified 35 common response-tuning functions that captured fine-grained distinctions among a wide range of stimuli in the movie and in two category perception experiments. Between-subject classification (BSC, multivariate pattern classification based on other subjects' data) of response-pattern vectors in common model space greatly exceeded BSC of anatomically aligned responses and matched within-subject classification. Results indicate that population codes for complex visual stimuli in VT cortex are based on response-tuning functions that are common across individuals.},
	author = "James V Haxby and J Swaroop Guntupalli and Andrew C Connolly and Yaroslav O Halchenko and Bryan R Conroy and M Ida Gobbini and Michael Hanke and Peter J Ramadge",
	journal = "Neuron",
	localfile = "/home/chris/studium/masterarbeit/paper/Haxby (2011). A common, high-dimensional model of the representational space in human ventral temporal cortex.pdf",
	mid = "NIHMS324344",
	month = oct,
	nlmuniqueid = "8809320",
	number = "2",
	pages = "404--416",
	pii = "S0896-6273(11)00781-1",
	pmc = "PMC3201764",
	pubmed = "22017997",
	title = "{A common, high-dimensional model of the representational space in human ventral temporal cortex}",
	volume = "72",
	x-fetchedfrom = "PubMed",
	year = "2011"
}

@article{haynes_2006_deconding_metal_states,
	abstract = "Recent advances in human neuroimaging have shown that it is possible to accurately decode a person's conscious experience based only on non-invasive measurements of their brain activity. Such 'brain reading' has mostly been studied in the domain of visual perception, where it helps reveal the way in which individual experiences are encoded in the human brain. The same approach can also be extended to other types of mental state, such as covert attitudes and lie detection. Such applications raise important ethical issues concerning the privacy of personal thought.",
	author = "John-Dylan Haynes and Geraint Rees",
	doi = "10.1038/nrn1931",
	journal = "Nature Reviews Neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Haynes (2006). Decoding mental states from brain activity in humans.pdf",
	month = jul,
	nlmuniqueid = "100962781",
	number = "7",
	pages = "523--534",
	pii = "nrn1931",
	pubmed = "16791142",
	title = "{Decoding mental states from brain activity in humans}",
	volume = "7",
	x-fetchedfrom = "PubMed",
	year = "2006"
}

@article{henderson_2008_full_scenes_vs_close-ups,
	abstract = "We used fMRI to directly compare activation in two cortical regions previously identified as relevant to real-world scene processing: retrosplenial cortex and a region of posterior parahippocampal cortex functionally defined as the parahippocampal place area (PPA). We compared activation in these regions to full views of scenes from a global perspective, close-up views of sub-regions from the same scene category, and single objects highly diagnostic of that scene category. Faces were included as a control condition. Activation in parahip- pocampal place area was greatest for full scene views that explicitly included the 3D spatial structure of the environment, with progres- sively less activation for close-up views of local scene regions containing diagnostic objects but less explicitly depicting 3D scene geometry, followed by single scene-diagnostic objects. Faces did not activate parahippocampal place area. In contrast, activation in ret- rosplenial cortex was greatest for full scene views, and did not differ among close-up views, diagnostic objects, and faces. The results showed that parahippocampal place area responds in a graded fashion as images become more completely scene-like and include more explicit 3D structure, whereas retrosplenial cortex responds in a step-wise manner to the presence of a complete scene. These results sug- gest scene processing areas are particularly sensitive to the 3D geometric structure that distinguishes scenes from other types of complex and meaningful visual stimuli.",
	author = "John M. Henderson and Christine L. Larson and David C. Zhu",
	journal = "Brain and cognition",
	keywords = "fMRI; Scene processing; Real-world scenes; Object processing; Parahippocampal place area; Parahippocampal cortex; Retrosplenial cortex",
	localfile = "/home/chris/studium/masterarbeit/paper/Henderson (2008). Full Scenes produce more activation than Close-up Scenes and Scene-Diagnostic Objects in parahippocampal and retrosplenial cortex.pdf",
	number = "1",
	pages = "40--49",
	publisher = "Elsevier",
	title = "{Full scenes produce more activation than close-up scenes and scene-diagnostic objects in parahippocampal and retrosplenial cortex: an fMRI study}",
	volume = "66",
	x-color = "#0033ff",
	year = "2008"
}

@article{hewig_2005_revised_film_set,
	abstract = "In the past decade several film sets for the induction of emotions have been developed. These film sets mainly consist of emotional clips from feature films. Since the neutral stimuli in these sets were abstract scenes, documentary or television excerpts, the aim of the present study was to develop a set that includes comparable neutral stimuli from commercially available feature films that match the emotional ones in their content. Furthermore, the capacity of the emotional film clips to elicit a specific target emotion was evaluated. Four neutral clips were selected and shown to 38 subjects, together with 16 emotional clips from earlier studies on emotion induction. Four clips were selected to elicit anger, and three clips to elicit each of the target emotions disgust, fear, sadness, and amusement. The participants rated their feelings on 21 emotion scales. Cluster analysis confirmed the six a priori groups of films. ANOVA further revealed that the four neutral clips, were rated neutral on the valence and low on the intensity dimension. Most of the emotional film clips primarily elicited their respective target emotion. In summary, at least two clips for each target emotion were able to elicit that emotion selectively.",
	author = "Johannes Hewig and Dirk Hagemann and Jan Seifert and Mario Gollwitzer and Ewald Naumann and Dieter Bartussek",
	journal = "Cognition \& Emotion",
	localfile = "/home/chris/studium/masterarbeit/paper/Hewig (2005). A revised film set for the induction of basic emotions.pdf",
	nlmuniqueid = "101183755",
	number = "7",
	pages = "1095--1109",
	pmc = "PMC2919416",
	pubmed = "20711473",
	title = "{A revised film set for the induction of basic emotions}",
	url = "http://www.tandfonline.com/doi/abs/10.1080/02699930541000084#.VOXAL5-c3Qo",
	volume = "19",
	x-fetchedfrom = "PubMed",
	year = "2010"
}

@article{hirose_2010_perception_memory_across_viewpoint_changes_in_movies,
	abstract = "Current understanding of scene perception derives largely from experiments using static scenes and psychological understanding of how moving images are processed is under-developed. We examined eye movement patterns and recognition memory performance as observers looked at short movies involving a change in viewpoint (a cut). At the time of the cut, four types of object property (color, position, identity and shape) were manipulated. Results show differential sensitivity to object property changes, reflected in both eye movement behavior after the cut and memory performance when object properties are remembered after viewing. When object properties change across a cut, memory is generally biased towards information present after the cut, except for position information which showed no bias. Our findings suggest that spatial information is represented differently to other forms of object information when viewing movies that include changes in viewpoint.",
	author = "Yoriko Hirose and Alan Kennedy and Benjamin W Tatler",
	journal = "Journal of vision",
	keywords = "eye movements; visual memory; scene perception; motion; movie; representation; behavior",
	localfile = "/home/chris/studium/masterarbeit/paper/Hirose (2010). Perception and memory across viewpoint changes in moving images.pdf",
	number = "4",
	pages = "1--20",
	publisher = "The Association for Research in Vision and Ophthalmology",
	title = "{Perception and memory across viewpoint changes in moving images}",
	volume = "10",
	x-color = "#ffff00",
	year = "2010"
}

@article{huttunen_2013_mind_reading_logistic_regression,
	abstract = "In this paper, we consider the problem of multino- mial classification of magnetoencephalography (MEG) data. The proposed method participated in the MEG mind reading competition of ICANN{\rq}11 conference, where the goal was to train a classifier for predicting the movie the test person was shown. Our approach was the best among ten submissions, reaching accuracy of 68 \% of correct classifications in this five category problem. The method is based on a regularized logistic regression model, whose efficient feature selection is critical for cases with more measurements than samples. Moreover, a special attention is paid to the estimation of the generalization error in order to avoid overfitting to the train- ing data. Here, in addition to describing our competition entry in detail, we report selected additional experiments, which question the usefulness of complex feature extraction proce- dures and the basic frequency decomposition of MEG signal for this application.",
	added-at = "2013-07-22T00:00:00.000+0200",
	author = "Heikki Huttunen and Tapio Manninen and Jukka-Pekka Kauppi and Jussi Tohka",
	interhash = "3a9ff57e5b0339f16b6f4c3a18618cfc",
	intrahash = "684a6183467a5ca616275d9c04e9f0eb",
	journal = "Machine Vision and Applications",
	keywords = "Logistic regression; Elastic net regularization; Classification; Decoding; Magnetoencephalography; MEG; Natural stimulus",
	localfile = "/home/chris/studium/masterarbeit/paper/Huttunen (2013). Mind reading with regularized multinomial logistic regression.pdf",
	number = "6",
	pages = "1311--1325",
	title = "{Mind reading with regularized multinomial logistic regression}",
	url = "http://dx.doi.org/10.1007/s00138-012-0464-y",
	volume = "24",
	x-fetchedfrom = "Bibsonomy",
	year = "2013"
}

@article{ionta_2011_multi-sensory-foundations,
	author = "Silvio Ionta and Roger Gassert and Olaf Blanke",
	journal = "Frontiers in Psychology",
	keywords = "review",
	localfile = "/home/chris/studium/masterarbeit/paper/Ionta (2011). Multi-sensory and sensorimotor foundation of bodily self-consciousness (review).pdf",
	pages = "1--8",
	publisher = "Frontiers Media SA",
	title = "{Multi-sensory and sensorimotor foundation of bodily self-consciousness--an interdisciplinary approach}",
	volume = "2",
	year = "2011"
}

@article{ionta_2011_multisensory-TPJ,
	abstract = "Self-consciousness has mostly been approached by philosophical enquiry and not by empirical neurosci- entific study, leading to an overabundance of diverging theories and an absence of data-driven theories. Using robotic technology, we achieved specific bodily conflicts and induced predictable changes in a fundamental aspect of self-conscious- ness by altering where healthy subjects experienced themselves to be (self-location). Functional magnetic resonance imaging revealed that temporo-parietal junction (TPJ) activity reflected experimental changes in self-location that also depended on the first-person perspective due to visuo-tactile and visuo-vestibular conflicts. Moreover, in a large lesion analysis study of neurological patients with a well- defined state of abnormal self-location, brain damage was also localized at TPJ, providing causal evidence that TPJ encodes self-location. Our find- ings reveal that multisensory integration at the TPJ reflects one of the most fundamental subjective feel- ings of humans: the feeling of being an entity local- ized at a position in space and perceiving the world from this position and perspective.",
	author = "Silvio Ionta and Lukas Heydrich and Bigna Lenggenhager and Michael Mouthon and Eleonora Fornari and Dominique Chapuis and Roger Gassert and Olaf Blanke",
	journal = "Neuron",
	localfile = "/home/chris/studium/masterarbeit/paper/Ionta, Blanke (2011). Multisensory Mechanisms in Temporo-Parietal Cortex.pdf",
	number = "2",
	pages = "363--374",
	publisher = "Elsevier",
	title = "{Multisensory mechanisms in temporo-parietal cortex support self-location and first-person perspective}",
	volume = "70",
	x-color = "#ffffa5",
	year = "2011"
}

@article{ionta_2014_network_reflecting_bodily_self-consciousness,
	author = "Silvio Ionta and Roberto Martuzzi and Roy Salomon and Olaf Blanke",
	journal = "Social cognitive and affective neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Ionta (2014). The Brain Network reflecting Bodily Self-Consciousness.pdf",
	number = "12",
	pages = "1904--1913",
	publisher = "Oxford University Press",
	title = "{The brain network reflecting bodily self-consciousness: A functional connectivity study}",
	volume = "9",
	year = "2014"
}

@article{jaaskelainen_2008_inter-subject_synchronization,
	abstract = {Hemodynamic activity in occipital, temporal, and parietal cortical areas were recently shown to correlate across subjects during viewing of a 30-minute movie clip. However, most of the frontal cortex lacked between-subject correlations. Here we presented 12 healthy naï¿œve volunteers with the first 72 minutes of a movie ("Crash", 2005, Lions Gate Films) outside of the fMRI scanner to involve the subjects in the plot of the movie, followed by presentation of the last 36 minutes during fMRI scanning. We observed significant between-subjects correlation of fMRI activity in especially right hemisphere frontal cortical areas, in addition to the correlation of activity in temporal, occipital, and parietal areas. It is possible that this resulted from the subjects following the plot of the movie and being emotionally engaged in the movie during fMRI scanning. We further show that probabilistic independent component analysis (ICA) reveals meaningful activations in individual subjects during natural viewing.},
	author = "Iiro P Jääskeläinen and Katri Koskentalo and Marja H Balk and Taina Autti and Jaakko Kauramäki and Cajus Pomren and Mikko Sams",
	journal = "Open Neuroimaging Journal",
	keywords = "probabilistic independent component analysis; ICA; Crash; movie",
	localfile = "/home/chris/studium/masterarbeit/paper/Jääskeläinen (2008). Inter-Subject Synchronization of Prefrontal Cortex Hemodynamic Activity.pdf",
	nlmuniqueid = "101480502",
	note = {stimulus: "Crash" (2005)},
	pages = "14--19",
	pmc = "PMC2577941",
	pubmed = "19018313",
	title = "{Inter-subject synchronization of prefrontal cortex hemodynamic activity during natural viewing}",
	volume = "2",
	x-color = "#ffff00",
	x-fetchedfrom = "PubMed",
	year = "2008"
}

@book{katz_1991_film_direction,
	author = "Steven D. Katz",
	edition = "1",
	isbn = "9780941188104",
	keywords = "cinematography",
	localfile = "/home/chris/studium/masterarbeit/cinematography /Katz - Film Directing Shot by Shot.pdf",
	publisher = "Focal Press",
	timestamp = "2015.04.09",
	title = "{Film Directing Shot by Shot: Visualizing from Concept to Screen}",
	totalpages = "366",
	url = "http://amazon.com/o/ASIN/0941188108",
	year = "1991"
}

@article{kauppi_2010_inter-subject_correlation,
	abstract = "Cinema is a promising naturalistic stimulus that enables, for instance, elicitation of robust emotions during functional magnetic resonance imaging (fMRI). Inter-subject correlation (ISC) has been used as a model-free analysis method to map the highly complex hemodynamic responses that are evoked during watching a movie. Here, we extended the ISC analysis to frequency domain using wavelet analysis combined with non-parametric permutation methods for making voxel-wise statistical inferences about frequency-band specific ISC. We applied these novel analysis methods to a dataset collected in our previous study where 12 subjects watched an emotionally engaging movie ``Crash'' during fMRI scanning. Our results suggest that several regions within the frontal and temporal lobes show ISC predominantly at low frequency bands, whereas visual cortical areas exhibit ISC also at higher frequencies. It is possible that these findings relate to recent observations of a cortical hierarchy of temporal receptive windows, or that the types of events processed in temporal and prefrontal cortical areas (e.g., social interactions) occur over longer time periods than the stimulus features processed in the visual areas. Software tools to perform frequency-specific ISC analysis, together with a visualization application, are available as open source Matlab code.",
	author = "Jukka-Pekka Kauppi and Iiro P. Jääskeläinen and Mikko Sams and Jussi Tohka",
	journal = "Frontiers in Neuroinformatics",
	keywords = "natural vision; BOLD; fMRI; intersubject correlation; stationary wavelet transform; permutation test; Crash; movie",
	localfile = "/home/chris/studium/masterarbeit/paper/Kauppi (2010). Inter-Subject Correlation of Brain Hemodynamic Responses During Watching a Movie. Localization in Space and Frequency.pdf",
	mid = "NIHMS324344",
	nlmuniqueid = "8809320",
	note = {stimulus: "Crash" (2005)},
	pages = "1--10",
	pii = "S0896-6273(11)00781-1",
	pmc = "PMC3201764",
	pubmed = "22017997",
	title = "{Inter-subject correlation of brain hemodynamic responses during watching a movie: Localization in space and frequency}",
	url = "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2859808",
	volume = "4",
	x-fetchedfrom = "PubMed",
	year = "2010"
}

@article{kauppi_2013_decoding_rhythmic_MEG,
	abstract = "We propose a new data-driven decoding method called Spectral Linear Discriminant Analysis (Spectral LDA) for the analysis of magnetoencephalography (MEG). The method allows investigation of changes in rhythmic neural activity as a result of different stimuli and tasks. The introduced classification model only assumes that each ``brain state'' can be characterized as a combination of neural sources, each of which shows rhythmic activity at one or several frequency bands. Furthermore, the model allows the oscillation frequencies to be different for each such state. We present decoding results from 9 subjects in a four-category classification problem defined by an experiment involving randomly alternating epochs of auditory, visual and tactile stimuli interspersed with rest periods. The performance of Spectral LDA was very competitive compared with four alternative classifiers based on different assumptions concerning the organization of rhythmic brain activity. In addition, the spectral and spatial patterns extracted automatically on the basis of trained classifiers showed that Spectral LDA offers a novel and interesting way of analyzing spectrospatial oscillatory neural activity across the brain. All the presented classification methods and visualization tools are freely available as a Matlab toolbox.",
	added-at = "2013-12-29T00:00:00.000+0100",
	author = "Jukka-Pekka Kauppi and Lauri Parkkonen and Riitta Hari and Aapo Hyvï¿œrinen",
	interhash = "73276d398790ebaffa24531acbd08621",
	intrahash = "868360c9f98d72e3545c65ac86122ee5",
	journal = "NeuroImage",
	keywords = "Decoding; Magnetoencephalography; Rhythmic activity; Time--frequency analysis; Linear discriminant analysis; Independent component analysis; ICA; MEG; movie",
	localfile = "/home/chris/studium/masterarbeit/paper/Kauppi (2013). Decoding magnetoencephalographic rhythmic activity using spectrospatial information.pdf",
	pages = "921--936",
	title = "{Decoding magnetoencephalographic rhythmic activity using spectrospatial information}",
	url = "http://www.sciencedirect.com/science/article/pii/S1053811913007817",
	volume = "83",
	x-fetchedfrom = "Bibsonomy",
	year = "2013"
}

@article{kauttonen_2015_optimizing_methods_cinematic_features_to_fMRI,
	added-at = "2015-07-26T00:00:00.000+0200",
	author = "Janne Kauttonen and Yevhen Hlushchuk and Pia Tikka",
	interhash = "d2964c1a4019a320411d71a03fe87e75",
	intrahash = "297f49ca10318ff97780083d356797f1",
	journal = "NeuroImage",
	keywords = "fMRI; Neurocinematics; Elastic-net regularization; Linear regression; Independent component analysis; ICA; Naturalistic stimuli; Annotation; at land",
	localfile = "/home/chris/studium/masterarbeit/paper/Kauttonen (2015). Optimizing methods for linking cinematic features to fMRI data.pdf",
	pages = "136--148",
	timestamp = "2015-07-28T11:35:32.000+0200",
	title = "{Optimizing methods for linking cinematic features to fMRI data}",
	volume = "110",
	x-color = "#ffff00",
	x-fetchedfrom = "Bibsonomy",
	year = "2015"
}

@article{kolodyazhniy_2011_emotion_specificity,
	abstract = "The hypothesis of physiological emotion specificity has been tested using pattern classification analysis (PCA). To address limitations of prior research using PCA, we studied effects of feature selection (sequential forward selection, sequential backward selection), classifier type (linear and quadratic discriminant analysis, neural networks, k-nearest neighbors method), and cross-validation method (subject- and stimulus-(in)dependence). Analyses were run on a data set of 34 participants watching two sets of three 10-min film clips (fearful, sad, neutral) while autonomic, respiratory, and facial muscle activity were assessed. Results demonstrate that the three states can be classified with high accuracy by most classifiers, with the sparsest model having only five features, even for the most difficult task of identifying the emotion of an unknown subject in an unknown situation (77.5\%). Implications for choosing PCA parameters are discussed.",
	author = "Vitaliy Kolodyazhniy and Sylvia D Kreibig and James J Gross and Walton T Roth and Frank H Wilhelm",
	journal = "Psychophysiology",
	keywords = "Emotion; Pattern classification; Feature selection; Autonomic nervous system; Cardiovascular system; Respiration; Electrodermal system; Affective neuroscience; Affective computing",
	localfile = "/home/chris/studium/masterarbeit/paper/Kolodyazhniy (2011). An affective computing approach to physiological emotion specificity.pdf",
	number = "7",
	pages = "908--922",
	publisher = "Wiley Online Library",
	title = "{An affective computing approach to physiological emotion specificity: Toward subject-independent and stimulus-independent classification of film-induced emotions}",
	volume = "48",
	year = "2011"
}

@article{krause_2000_eeg_to_emotional_film,
	abstract = "The reactivity of different narrow electroencephalographic (EEG) frequencies (4-6, 6-8, 8-10 and 10-12 Hz) to three types of emotionally laden film clips (aggressive, sad, neutral) were examined. We observed that different EEG frequency bands responded differently to the three types of film content. In the 4-6 Hz frequency band, the viewing of aggressive film content elicited greater relative synchronization as compared the responses elicited by the viewing of sad and neutral film content. The 6-8 Hz and 8-10 Hz frequency bands exhibited reactivity to the chronological succession of film viewing whereas the responses of the 10-12 Hz frequency band evolved within minutes during film viewing. Our results propose dissociations between the responses of different frequencies within the EEG to different emotion-related stimuli. Narrow frequency band EEG analysis offers an adequate tool for studying cortical activation patterns during emotion-related information processing.",
	author = "C M Krause and V Viemerö and A Rosenqvist and L Sillanmäki and T Aström",
	journal = "Neuroscience Letters",
	keywords = "Electroencephalography; EEG; Relative desynchronization/synchronization; Alpha; Theta; Emotion; Film; Visual",
	localfile = "/home/chris/studium/masterarbeit/paper/Krause (2000). Relative electroencephalographic desynchronization and synchronization in humans to emotional film content.pdff",
	month = may,
	nlmuniqueid = "7600130",
	number = "1",
	pages = "9--12",
	pii = "S0304-3940(00)01092-2",
	pubmed = "10822140",
	title = "{Relative electroencephalographic desynchronization and synchronization in humans to emotional film content: an analysis of the 4-6, 6-8, 8-10 and 10-12 Hz frequency bands}",
	volume = "286",
	x-fetchedfrom = "PubMed",
	year = "2000"
}

@article{kurby_zacks_2011_age_differences_in_perception_hierarchical_structure,
	author = "Christopher A Kurby and Jeffrey M Zacks",
	localfile = "/home/chris/studium/masterarbeit/paper/Kurby (2011). Age differences in the perception of hierarchical structure in events.pdf",
	pages = "75--91",
	title = "{Age differences in the perception of hierarchical structure in events}",
	year = "2011"
}

@article{kurby_2008_segmentation_in_perception_review,
	abstract = "People make sense of continuous streams of observed behavior in part by segmenting them into events. Event segmentation seems to be an ongoing component of everyday perception. Events are segmented simul- taneously at multiple timescales, and are grouped hier- archically. Activity in brain regions including the posterior temporal and parietal cortex and lateral frontal cortex increases transiently at event boundaries. The parsing of ongoing activity into events is related to the updating of working memory, to the contents of long-term memory, and to the learning of new pro- cedures. Event segmentation might arise as a side effect of an adaptive mechanism that integrates information over the recent past to improve predictions about the near future.",
	author = "Christopher A Kurby and Jeffrey M Zacks",
	journal = "Trends in cognitive sciences",
	keywords = "review",
	localfile = "/home/chris/studium/masterarbeit/paper/Kurby, Zacks (2007). Segmentation in the perception and memory of events (review).pdf",
	number = "2",
	pages = "72--79",
	publisher = "Elsevier",
	title = "{Segmentation in the perception and memory of events}",
	volume = "12",
	year = "2008"
}

@article{lahnakoski_2014_synchronous_brain_activity_across_indivduals,
	abstract = "For successful communication, we need to understand the external world consistently with others. This task requires sufficiently similar cognitive schemas or psychological perspectives that act as filters to guide the selection, interpretation and storage of sensory information, perceptual objects and events. Here we show that when individuals adopt a similar psychological perspective during natural viewing, their brain activity becomes synchronized in specific brain regions. We measured brain activity with functional magnetic resonance imaging (fMRI) from 33 healthy participants who viewed a 10-min movie twice, assuming once a {\lq}social{\rq} (detective) and once a {\lq}non-social{\rq} (interior decorator) perspective to the movie events. Pearson's correlation coefficient was used to derive multisubject voxelwise similarity measures (inter-subject correlations; ISCs) of functional MRI data. We used k-nearest-neighbor and support vector machine classifiers as well as a Mantel test on the ISC matrices to reveal brain areas wherein ISC predicted the participants' current perspective. ISC was stronger in several brain regions---most robustly in the parahippocampal gyrus, posterior parietal cortex and lateral occipital cortex---when the participants viewed the movie with similar rather than different perspectives. Synchronization was not explained by differences in visual sampling of the movies, as estimated by eye gaze. We propose that synchronous brain activity across individuals adopting similar psychological perspectives could be an important neural mechanism supporting shared understanding of the environment.",
	author = "Juha M Lahnakoski and Enrico Glerean and Iiro P Jääskeläinen and Jukka Hyönä and Riitta Hari and Mikko Sams and Lauri Nummenmaa",
	journal = "NeuroImage",
	keywords = "Psychological perspective; Inter-subject correlation; Attention; fMRI",
	localfile = "/home/chris/studium/masterarbeit/paper/Lahnakoski (2014). Synchronous brain activity across individuals underlies shared psychological perspectives.pdf",
	pages = "316--324",
	publisher = "Elsevier",
	title = "{Synchronous brain activity across individuals underlies shared psychological perspectives}",
	volume = "100",
	x-color = "#ffff00",
	year = "2014"
}

@article{lahnakoski_2012_naturalistic_fmri_mapping_reveals,
	author = "Juha M Lahnakoski and Enrico Glerean and Juha Salmi and Iiro P Jääskeläinen and Mikko Sams and Riitta Hari and Lauri Nummenmaa and others",
	keywords = "social brain; posterior STS; face; speech; pain; body; social interaction; goal-oriented action; fMRI",
	localfile = "/home/chris/studium/masterarbeit/paper/Lahnakoski (2012). Naturalistic fMRI Mapping Reveals Superior Temporal Sulcus as the Hub for the Distributed Brain Network for Social Perception.pdf",
	publisher = "Frontiers Media SA",
	title = "{Naturalistic FMRI mapping reveals superior temporal sulcus as the hub for the distributed brain network for social perception}",
	x-color = "#ffffa5",
	year = "2012"
}

@article{lahnakoski_2012_viewing_feature_film,
	abstract = "Understanding how the brain processes stimuli in a rich natural environment is a fundamental goal of neuroscience. Here, we showed a feature film to 10 healthy volunteers during functional magnetic resonance imaging (fMRI) of hemodynamic brain activity. We then annotated auditory and visual features of the motion picture to inform analysis of the hemodynamic data. The annotations were fitted to both voxel-wise data and brain network time courses extracted by independent component analysis (ICA). Auditory annotations correlated with two independent components (IC) disclosing two functional networks, one responding to variety of auditory stimulation and another responding preferentially to speech but parts of the network also responding to non-verbal communication. Visual feature annotations correlated with four ICs delineating visual areas according to their sensitivity to different visual stimulus features. In comparison, a separate voxel-wise general linear model based analysis disclosed brain areas preferentially responding to sound energy, speech, music, visual contrast edges, body motion and hand motion which largely overlapped the results revealed by ICA. Differences between the results of IC- and voxel-based analyses demonstrate that thorough analysis of voxel time courses is important for understanding the activity of specific sub-areas of the functional networks, while ICA is a valuable tool for revealing novel information about functional connectivity which need not be explained by the predefined model. Our results encourage the use of naturalistic stimuli and tasks in cognitive neuroimaging to study how the brain processes stimuli in rich natural environments.",
	author = "Juha M Lahnakoski and Juha Salmi and Iiro P Jääskeläinen and Jouko Lampinen and Enrico Glerean and Pia Tikka and Mikko Sams",
	journal = "PLoS ONE",
	keywords = "fMRI; independent component analysis; ICA; Match Factory Girl",
	localfile = "/home/chris/studium/masterarbeit/paper/Lahnakoski (2012). Stimulus-Related Independent Component and Voxel-Wise Analysis of Human Brain Activity during Free Viewing of a Feature Film.pdf",
	nlmuniqueid = "101285081",
	note = "feature film {\lq}{\lq}Match Factory Girl{\rq}{\rq} (Aki Kaurismaki, 1990)",
	number = "4",
	pages = "e35215",
	pii = "PONE-D-11-13765",
	pmc = "PMC3320648",
	pubmed = "22496909",
	title = "{Stimulus-related independent component and voxel-wise analysis of human brain activity during free viewing of a feature film}",
	volume = "7",
	x-color = "#ffff00",
	x-fetchedfrom = "PubMed",
	year = "2012"
}

@article{lambrey_2012_imagining_being_somewhere_else,
	abstract = "The capacity to imagine being somewhere else and seeing the environment from a different point of view is crucial for spatial planning in daily life and for understanding the intentions, actions, and state of mind of other people. The neural bases of spatial updating of multiple object locations were investigated using functional magnetic resonance imaging. Healthy volunteers saw an array of objects on a table in a virtual reality environment and imagined movement of their own viewpoint or rotation of the array. Their memory for the locations of the objects was then tested with a change-detection task. Behavioral results confirmed the advan- tage for imagined viewpoint change compared with imagined array rotation of equivalent size. Encoding of object locations was associated with a network of areas, including bilateral superior and inferior parietal cortices. The precuneus was additionally activated by the demands of both viewpoint- and array rotation. The parieto- occipital sulcus/retrosplenial cortex and hippocampus were additionally activated by the demands of viewpoint rotation, while array rotation was associated with activation of the right intra- parietal sulcus. These findings support a computational model of spatial memory in which parieto-occipital sulcus/retrosplenial cortex mediates spatial updating as part of a process of translation between {\lq}{\lq}egocentric{\rq}{\rq} and {\lq}{\lq}allocentric{\rq}{\rq} reference frames.",
	author = "Simon Lambrey and Christian Doeller and Alain Berthoz and Neil Burgess",
	journal = "Cerebral cortex",
	keywords = "fMRI; hippocampus; perspective taking; retrosplenial cortex; spatial memory; virtual reality",
	localfile = "/home/chris/studium/masterarbeit/paper/Lambrey (2012). Imagining Being Somewhere Else.pdf",
	number = "1",
	pages = "166--174",
	publisher = "Oxford Univ Press",
	title = "{Imagining being somewhere else: Neural basis of changing perspective in space}",
	volume = "22",
	x-color = "#0033ff",
	year = "2012"
}

@article{lankinen_2014_MEG_during_movie,
	abstract = "According to recent functional magnetic resonance imaging (fMRI) studies, spectators of a movie may share similar spatiotemporal patterns of brain activity. We aimed to extend these findings of intersubject correlation to temporally accurate single-trial magnetoencephalography (MEG). A silent 15-min black-and-white movie was shown to eight subjects twice. We adopted a spatial filtering model and estimated its parameter values by using multi-set canonical correlation analysis (M-CCA) so that the intersubject correlation was maximized. The procedure resulted in multiple (mutually uncorrelated) time-courses with statistically significant intersubject correlations at frequencies below 10 Hz; the maximum correlation was 0.28 ï¿œ 0.075 in the â€1 Hz band. Moreover, the 24-Hz frame rate elicited steady-state responses with statistically significant intersubject correlations up to 0.29 ï¿œ 0.12. To assess the brain origin of the across-subjects correlated signals, the time-courses were correlated with minimum-norm source current estimates (MNEs) projected to the cortex. The time series implied across-subjects synchronous activity in the early visual, posterior and inferior parietal, lateral temporo-occipital, and motor cortices, and in the superior temporal sulcus (STS) bilaterally. These findings demonstrate the capability of the proposed methodology to uncover cortical MEG signatures from single-trial signals that are consistent across spectators of a movie.",
	author = "K Lankinen and J Saari and R Hari and M Koskinen",
	doi = "10.1016/j.neuroimage.2014.02.004",
	journal = "Neuroimage",
	keywords = "Magnetoencephalography; MEG; Minimum norm estimate; MNE; Movie; Multi-set canonical correlation analysis; M-CCA",
	localfile = "/home/chris/studium/masterarbeit/paper/Lankinen (2014). Intersubject consistency of cortical MEG signals during movie viewing.pdf",
	month = may,
	nlmuniqueid = "9215515",
	pages = "217--224",
	pii = "S1053-8119(14)00095-0",
	pubmed = "24531052",
	title = "{Intersubject consistency of cortical MEG signals during movie viewing}",
	volume = "92",
	x-color = "#ffff00",
	x-fetchedfrom = "PubMed",
	year = "2014"
}

@article{lengen_2012_sense_of_place_identity_review,
	abstract = "The aim of this review is to bring the phenomenological sense of place approach together with current results from neuroscience. We searched in neuroscientific literature for ten dimensions which were beforehand identified to be important in a phenomenological sense of place/place identity model: behaviour, body, emotion, attention, perception, memory, orientation, spirituality, meaning/value and culture/sociality. Neuroscience has identified many neurobiological correlates of phenomenological observations concerning sense of place. The human brain comprises specific and specialised structures and processes to perceive, memorise, link, assess and use spatial information. Specific parts (hippocampus, entorhinal, parahippocampal and parietal cortex), subregions (parahippocampal place area, lingual landmark area), and cells (place cells, grid cells, border cells, head direction cells) have been identified, their specific function could be understood and their interaction traced. Neuroscience has provided evidence that place constitutes a distinct dimension in neuronal processing. This reinforces the phenomenological argumentation of human geography and environmental psychology.",
	author = "Charis Lengen and Thomas Kistemann",
	journal = "Health \& Place",
	keywords = "Sense of place; Place identity; Memory; Attention; Perception; Orientation; Emotion",
	localfile = "/home/chris/studium/masterarbeit/paper/Lengen (2012). Sense of place and place identity. Review of neuroscientific evidence.pdf",
	number = "5",
	pages = "1162--1171",
	publisher = "Elsevier",
	title = "{Sense of place and place identity: Review of neuroscientific evidence}",
	volume = "18",
	year = "2012"
}

@article{luo_2010_auditory_cortex_tracks,
	abstract = {Integrating information across sensory domains to construct a unified representation of multi-sensory signals is a fundamental characteristic of perception in ecological contexts. One provocative hypothesis deriving from neurophysiology suggests that there exists early and direct cross-modal phase modulation. We provide evidence, based on magnetoencephalography (MEG) recordings from participants viewing audiovisual movies, that low-frequency neuronal information lies at the basis of the synergistic coordination of information across auditory and visual streams. In particular, the phase of the 2-7 Hz delta and theta band responses carries robust (in single trials) and usable information (for parsing the temporal structure) about stimulus dynamics in both sensory modalities concurrently. These experiments are the first to show in humans that a particular cortical mechanism, delta-theta phase modulation across early sensory areas, plays an important "active" role in continuously tracking naturalistic audio-visual streams, carrying dynamic multi-sensory information, and reflecting cross-sensory interaction in real time.},
	author = "Huan Luo and Zuxiang Liu and David Poeppel",
	doi = "10.1371/journal.pbio.1000445",
	journal = "PLoS Biol.",
	localfile = "/home/chris/studium/masterarbeit/paper/Luo (2010). Auditory Cortex Tracks Both Auditory and Visual Stimulus Dynamics Using Low-Frequency Neuronal Phase Modulation.pdf",
	nlmuniqueid = "101183755",
	number = "8",
	pages = "e1000445",
	pmc = "PMC2919416",
	pubmed = "20711473",
	title = "{Auditory cortex tracks both auditory and visual stimulus dynamics using low-frequency neuronal phase modulation}",
	volume = "8",
	x-fetchedfrom = "PubMed",
	year = "2010"
}

@article{magliano_2011_impact_of_continuity_editing,
	author = "Joseph P. Magliano and Jeffrey M. Zacks",
	keywords = "Film comprehension; Event comprehension; Event segmentation; Situation models; Mental models; fMRI",
	localfile = "/home/chris/studium/masterarbeit/paper/Magliano, Zacks (2011). The Impact of Continuity Editing in Narrative Film on Event Segmentation.pdf",
	title = "{The impact of continuity editing in narrative film on event segmentation}",
	x-color = "#ffffa5",
	year = "2011"
}

@article{maguire_1998_knowing_where_and_getting_there,
	abstract = "The neural basis of navigation by humans was investigated with functional neuroimaging of brain activity during navigation in a familiar, yet complex virtual reality town. Activation of the right hippocampus was strongly associated with knowing accurately where places were located and navigating accurately between them. Getting to those places quickly was strongly associated with activation of the right caudate nucleus. These two right-side brain structures function in the context of associated activity in right inferior parietal and bilateral medial parietal regions that support egocentric movement through the virtual town, and activity in other left-side regions (hippocampus, frontal cortex) probably involved in nonspatial aspects of navigation. These findings outline a network of brain areas that support navigation in humans and link the functions of these regions to physiological observations in other mammals.",
	author = "Eleanor A Maguire and Neil Burgess and James G Donnett and Richard SJ Frackowiak and Christopher D Frith and John O'Keefe",
	journal = "Science",
	localfile = "/home/chris/studium/masterarbeit/paper/Maguire (1998). Knowing where and getting there. A human navigation network.pdf",
	number = "5365",
	pages = "921--924",
	publisher = "American Association for the Advancement of Science",
	title = "{Knowing where and getting there: A human navigation network}",
	volume = "280",
	x-color = "#ffff00",
	year = "1998"
}

@article{malinen_2011_sorting_ICAs,
	abstract = "In human brain imaging with naturalistic stimuli, hemodynamic responses are difficult to predict and thus data-driven approaches, such as independent component analysis (ICA), may be beneficial. Here we propose inter-subject correlation (ISC) maps as stimulus-sensitive functional templates for sorting the independent components (ICs) to identify the most stimulus-related networks without stimulus-dependent temporal covariates. We collected 3-T functional magnetic resonance imaging (fMRI) data during perception of continuous audiovisual speech. Ten adults viewed a video, in which speech intelligibility was varied by altering the sound level. Five ICs with strongest overlap with the ISC map comprised auditory and visual cortices, and the sixth was a left-hemisphere-dominant network (left posterior superior temporal sulcus, inferior frontal gyrus, anterior superior temporal pole, supplementary motor cortex, and right angular gyrus) that was activated stronger during soft than loud speech. Corresponding temporal-model-based analysis revealed only temporal- and parietal-lobe activations without involvement of the anterior areas. The performance of the ISC-based IC selection was confirmed with fMRI data collected during free viewing of movie. Since ISC-ICA requires no predetermined temporal models on stimulus timing, it seems feasible for fMRI studies where hemodynamic variations are difficult to model because of the complex temporal structure of the naturalistic stimulation.",
	author = "Sanna Malinen and Riitta Hari",
	journal = "Neuroscience Research",
	keywords = "ICA; independent component analysis; Inter-subject correlation; Naturalistic stimuli; Human brain; Speech",
	localfile = "/home/chris/studium/masterarbeit/paper/Malinen (2011). Data-based functional template for sorting independent components of fMRI.pdf",
	month = dec,
	nlmuniqueid = "8500749",
	note = "self made movie stimulus ?",
	number = "4",
	pages = "369--376",
	pii = "S0168-0102(11)02067-0",
	pubmed = "21925216",
	title = "{Data-based functional template for sorting independent components of fMRI activity}",
	volume = "71",
	x-color = "#ffff00",
	x-fetchedfrom = "PubMed",
	year = "2011"
}

@article{malinen_2007_towards_natural_stimulation,
	abstract = {In search for suitable tools to study brain activation in natural environments, where the stimuli are multimodal, poorly predictable and irregularly varying, we collected functional magnetic resonance imaging data from 6 subjects during a continuous 8-min stimulus sequence that comprised auditory (speech or tone pips), visual (video clips dominated by faces, hands, or buildings), and tactile finger stimuli in blocks of 6-33 s. Results obtained by independent component analysis (ICA) and general-linear-model-based analysis (GLM) were compared. ICA separated in the superior temporal gyrus one independent component (IC) that reacted to all auditory stimuli and in the superior temporal sulcus another IC responding only to speech. Several distinct and rather symmetric vision-sensitive ICs were found in the posterior brain. An IC in the V5/MT region reacted to videos depicting faces or hands, whereas ICs in the V1/V2 region reacted to all video clips, including buildings. The corresponding GLM-derived activations in the auditory and early visual cortices comprised sub-areas of the ICA-revealed activations. ICA separated a prominent IC in the primary somatosensory cortex whereas the GLM-based analysis failed to show any touch-related activation. "Intrinsic" components, unrelated to the stimuli but spatially consistent across subjects, were discerned as well. The individual time courses were highly consistent in sensory projection cortices and more variable elsewhere. The ability to differentiate functionally meaningful composites of activated brain areas and to straightforwardly reveal their temporal dynamics renders ICA a sensitive tool to study brain responses to complex natural stimuli.},
	author = "Sanna Malinen and Yevhen Hlushchuk and Riitta Hari",
	journal = "Neuroimage",
	keywords = "independent component analysis; ICA; general-linear-model-based analysis; GLM",
	localfile = "/home/chris/studium/masterarbeit/paper/Malinen (2007). Towards natural stimulation in fMRI. Issues of data analysis.pdf",
	month = mar,
	nlmuniqueid = "9215515",
	number = "1",
	pages = "131--139",
	pii = "S1053-8119(06)01125-6",
	pubmed = "17208459",
	title = "{Towards natural stimulation in fMRI--issues of data analysis}",
	volume = "35",
	x-color = "#ffff00",
	x-fetchedfrom = "PubMed",
	year = "2007"
}

@article{mantini_2012_data-driven_monkeys_human_natural_vision,
	abstract = "Inferences about functional correspondences between functional networks of human and non-human primates largely rely on proximity and anatomical expansion models. However, it has been demonstrated that topologically correspondent areas in two species can have different functional properties, suggesting that anatomy-based approaches should be complemented with alternative methods to perform functional comparisons. We have recently shown that comparative analyses based on temporal correlations of sensory-driven fMRI responses can reveal functional correspondent areas in monkeys and humans without relying on spatial assumptions. Inter-species activity correlation (ISAC) analyses require the definition of seed areas in one species to reveal functional correspondences across the cortex of the same and other species. Here we propose an extension of the ISAC method that does not rely on any seed definition, hence a method void of any spatial assumption. Specifically, we apply independent component analysis (ICA) separately to monkey and human data to define species-specific networks of areas with coherent stimulusrelated activity. Then, we use a hierarchical cluster analysis to identify ICA-based ISAC clusters of monkey and human networks with similar timecourses. We implemented this approach on fMRI data collected in monkeys and humans during movie watching, a condition that evokes widespread sensory-driven activity throughout large portions of the cortex. Using ICA-based ISAC, we detected seven monkey--human clusters. The timecourses of several clusters showed significant correspondences either with the motion energy in the movie or with eye-movement parameters. Five of the clusters spanned putative homologous functional networks in either primary or extrastriate visual regions, whereas two clusters included higher-level visual areas at topological locations that are not predicted by cortical surface expansion models. Overall, our ICAbased ISAC analysis complemented the findings of our previous seed-based investigations, and suggested that functional processes can be executed by brain networks in different species that are functionally but not necessarily anatomically correspondent. Overall, our method provides a novel approach to reveal evolution-driven functional changes in the primate brain with no spatial assumptions.",
	added-at = "2013-02-06T00:00:00.000+0100",
	author = "Dante Mantini and Maurizio Corbetta and Gian Luca Romani and Guy A. Orban and Wim Vanduffel",
	interhash = "19b0f669a35a4a9ff731cb1a4d4ef4ac",
	intrahash = "ae0518adfc7f44a113bef8df4ca736c1",
	journal = "NeuroImage",
	keywords = "Cluster analysis; Independent component analysis; ICA; fmri; Primate brain; Evolution; Functional correspondence",
	localfile = "/home/chris/studium/masterarbeit/paper/Mantini (2012). Data-driven analysis of analogous brain networks in monkeys and humans during natural vision.pdf",
	number = "3",
	pages = "1107--1118",
	title = "{Data-driven analysis of analogous brain networks in monkeys and humans during natural vision}",
	volume = "63",
	x-fetchedfrom = "Bibsonomy",
	year = "2012"
}

@article{mantini_2012_interspecies_activity,
	abstract = "Evolution-driven functional changes in the primate brain are typically assessed by aligning monkey and human activation maps using cortical surface expansion models. These models use putative homologous areas as registration landmarks, assuming they are functionally correspondent. For cases in which functional changes have occurred in an area, this assumption prohibits to reveal whether other areas may have assumed lost functions. Here we describe a method to examine functional correspondences across species. Without making spatial assumptions, we assessed similarities in sensory-driven functional magnetic resonance imaging responses between monkey (Macaca mulatta) and human brain areas by temporal correlation. Using natural vision data, we revealed regions for which functional processing has shifted to topologically divergent locations during evolution. We conclude that substantial evolution-driven functional reorganizations have occurred, not always consistent with cortical expansion processes. This framework for evaluating changes in functional architecture is crucial to building more accurate evolutionary models.",
	author = "Dante Mantini and Uri Hasson and Viviana Betti and Mauro G Perrucci and Gian Luca Romani and Maurizio Corbetta and Guy A Orban and Wim Vanduffel",
	doi = "10.1038/nmeth.1868",
	journal = "Nature Methods",
	localfile = "/home/chris/studium/masterarbeit/paper/Mantini (2012). Interspecies activity correlations reveal functional correspondence between monkey and human brain areas.pdf",
	mid = "NIHMS397892",
	month = mar,
	nlmuniqueid = "101215604",
	number = "3",
	pages = "277--282",
	pii = "nmeth.1868",
	pmc = "PMC3438906",
	pubmed = "22306809",
	title = "{Interspecies activity correlations reveal functional correspondence between monkey and human brain areas}",
	volume = "9",
	x-color = "#fffb6d",
	x-fetchedfrom = "PubMed",
	year = "2012"
}

@book{mascelli_1998_five_Cs_of_cincematography,
	asin = "B00H29MO6U",
	author = "Joseph V. Mascelli",
	keywords = "cinematography",
	publisher = "Silman-James Press",
	timestamp = "2015.04.09",
	title = "{The Five C's of Cinematography: Motion Picture Filming Techniques}",
	totalpages = "551",
	url = "http://amazon.com/o/ASIN/B00H29MO6U",
	year = "1998"
}

@article{maselli_slater_2013_building_blocks_body_ownership,
	abstract = "Previous work has reported that it is not difficult to give people the illusion of ownership over an artificial body, providing a powerful tool for the investigation of the neural and cognitive mechanisms underlying body perception and self consciousness. We present an experimental study that uses immersive virtual reality (IVR) focused on identifying the perceptual building blocks of this illusion. We systematically manipulated visuotactile and visual sensorimotor contingencies, visual perspective, and the appearance of the virtual body in order to assess their relative role and mutual interaction. Consistent results from subjective reports and physiological measures showed that a first person perspective over a fake humanoid body is essential for eliciting a body ownership illusion. We found that the illusion of ownership can be generated when the virtual body has a realistic skin tone and spatially substitutes the real body seen from a first person perspective. In this case there is no need for an additional contribution of congruent visuotactile or sensorimotor cues. Additionally, we found that the processing of incongruent perceptual cues can be modulated by the level of the illusion: when the illusion is strong, incongruent cues are not experienced as incorrect. Participants exposed to asynchronous visuotactile stimulation can experience the ownership illusion and perceive touch as originating from an object seen to contact the virtual body. Analogously, when the level of realism of the virtual body is not high enough and/or when there is no spatial overlap between the two bodies, then the contribution of congruent multisensory and/or sensorimotor cues is required for evoking the illusion. On the basis of these results and inspired by findings from neurophysiological recordings in the monkey, we propose a model that accounts for many of the results reported in the literature.",
	author = "Antonella Maselli and Mel Slater",
	doi = "10.3389/fnhum.2013.00083",
	journal = "Front Hum Neurosci",
	localfile = "/home/chris/studium/masterarbeit/paper/Marselli, Slater (2013). The building blocks of the full body ownership illusion.pdf",
	nlmuniqueid = "101477954",
	pages = "1--15",
	pmc = "PMC3604638",
	pubmed = "23519597",
	title = "{The building blocks of the full body ownership illusion}",
	volume = "7",
	x-fetchedfrom = "PubMed",
	year = "2013"
}

@inproceedings{matran-fernandez_2015_ERPs_induced_by_cuts,
	author = "Ana Matran-Fernandez and Riccardo Poli",
	booktitle = "{Neural Engineering (NER), 2015 7th International IEEE/EMBS Conference on}",
	localfile = "/home/chris/studium/masterarbeit/paper/Matran-Fernandez (2015). Event-Related Potentials induced by cuts in feature movies and their exploitation for understanding cut efficacy.pdf",
	title = "{Event-Related Potentials induced by cuts in feature movies and their exploitation for understanding cut efficacy}",
	x-color = "#cc3300",
	year = "2015"
}

@article{matran-fernandes_2014_ERPs_induced_by_cuts_in_movies,
	author = "Ana Matran-Fernandez and Riccardo Poli",
	localfile = "/home/chris/studium/masterarbeit/paper/Matran-Fernandez (2014). Analysis of the Event-Related Potentials induced by Cuts in Feature Movies.pdf",
	publisher = "CES-533",
	title = "{Analysis of the Event-related Potentials induced by cuts in feature movies and evaluation of the possibility of using such ERPs for understanding the effects of cuts on viewers}",
	x-color = "#cc3300",
	year = "2014"
}

@article{nishimoto2011reconstructing,
	abstract = "Quantitative modeling of human brain activity can provide crucial insights about cortical representations [1 and 2] and can form the basis for brain decoding devices [3, 4 and 5]. Recent functional magnetic resonance imaging (fMRI) studies have modeled brain activity elicited by static visual patterns and have reconstructed these patterns from brain activity [6, 7 and 8]. However, blood oxygen level-dependent (BOLD) signals measured via fMRI are very slow [9], so it has been difficult to model brain activity elicited by dynamic stimuli such as natural movies. Here we present a new motion-energy [10 and 11] encoding model that largely overcomes this limitation. The model describes fast visual information and slow hemodynamics by separate components. We recorded BOLD signals in occipitotemporal visual cortex of human subjects who watched natural movies and fit the model separately to individual voxels. Visualization of the fit models reveals how early visual areas represent the information in movies. To demonstrate the power of our approach, we also constructed a Bayesian decoder [8] by combining estimated encoding models with a sampled natural movie prior. The decoder provides remarkable reconstructions of the viewed movies. These results demonstrate that dynamic brain activity measured under naturalistic conditions can be decoded using current fMRI technology.",
	added-at = "2013-01-26T20:23:24.000+0100",
	author = "S. Nishimoto and A.T. Vu and T. Naselaris and Y. Benjamini and B. Yu and J.L. Gallant",
	interhash = "09ce93720f7f217becf010e06421a07a",
	intrahash = "3af449cbf3cb64db02c846cd595dfcf7",
	journal = "Current Biology",
	keywords = "biology inverse linear problem; regression",
	localfile = "/home/chris/studium/masterarbeit/paper/Nishimoto (2011). Reconstructing Visual Experiences from Brain Activity Evoked by Natural Movies.pdf",
	number = "19",
	pages = "1641--1646",
	publisher = "Elsevier",
	title = "{Reconstructing visual experiences from brain activity evoked by natural movies}",
	volume = "21",
	x-fetchedfrom = "Bibsonomy",
	year = "2011"
}

@article{nummnmaa_2012_emotions_promote_interactions,
	abstract = {Sharing others' emotional states may facilitate understanding their intentions and actions. Here we show that networks of brain areas "tick together" in participants who are viewing similar emotional events in a movie. Participants' brain activity was measured with functional MRI while they watched movies depicting unpleasant, neutral, and pleasant emotions. After scanning, participants watched the movies again and continuously rated their experience of pleasantness-unpleasantness (i.e., valence) and of arousal-calmness. Pearson's correlation coefficient was used to derive multisubject voxelwise similarity measures [intersubject correlations (ISCs)] of functional MRI data. Valence and arousal time series were used to predict the moment-to-moment ISCs computed using a 17-s moving average. During movie viewing, participants' brain activity was synchronized in lower- and higher-order sensory areas and in corticolimbic emotion circuits. Negative valence was associated with increased ISC in the emotion-processing network (thalamus, ventral striatum, insula) and in the default-mode network (precuneus, temporoparietal junction, medial prefrontal cortex, posterior superior temporal sulcus). High arousal was associated with increased ISC in the somatosensory cortices and visual and dorsal attention networks comprising the visual cortex, bilateral intraparietal sulci, and frontal eye fields. Seed-voxel-based correlation analysis confirmed that these sets of regions constitute dissociable, functional networks. We propose that negative valence synchronizes individuals' brain areas supporting emotional sensations and understanding of another's actions, whereas high arousal directs individuals' attention to similar features of the environment. By enhancing the synchrony of brain activity across individuals, emotions may promote social interaction and facilitate interpersonal understanding.},
	author = "Lauri Nummenmaa and Enrico Glerean and Mikko Viinikainen and Iiro P Jï¿œï¿œskelï¿œinen and Riitta Hari and Mikko Sams",
	journal = "Proc. Natl. Acad. Sci. U.S.A.",
	localfile = "/home/chris/studium/masterarbeit/paper/Nummenmaa (2012). Emotions promote social interaction by synchronizing.pdf",
	month = jun,
	nlmuniqueid = "7505876",
	note = "clips from When Harry Met Sally and The Godfather",
	number = "24",
	pages = "9599--9604",
	pii = "1206095109",
	pmc = "PMC3386135",
	pubmed = "22623534",
	title = "{Emotions promote social interaction by synchronizing brain activity across individuals}",
	volume = "109",
	x-color = "#ffff00",
	x-fetchedfrom = "PubMed",
	year = "2012"
}

@article{pajula_2012_intersubject_correlation_fmri,
	abstract = "Within functional magnetic resonance imaging (fMRI), the use of the traditional general linear model (GLM) based analysis methods is often restricted to strictly controlled research setups requiring a parametric activation model. Instead, Inter-Subject Correlation (ISC) method is based on voxel-wise correlation between the time series of the subjects, which makes it completely non-parametric and thus suitable for naturalistic stimulus paradigms such as movie watching. In this study, we compared an ISC based analysis results with those of a GLM based in five distinct controlled research setups. We used International Consortium for Brain Mapping functional reference battery (FRB) fMRI data available from the Laboratory of Neuro Imaging image data archive. The selected data included measurements from 37 right-handed subjects, who all had performed the same five tasks from FRB. The GLM was expected to locate activations accurately in FRB data and thus provide good grounds for investigating relationship between ISC and stimulus induced fMRI activation. The statistical maps of ISC and GLM were compared with two measures. The first measure was the Pearson's correlation between the non-thresholded ISC test-statistics and absolute values of the GLM Z-statistics. The average correlation value over five tasks was 0.74. The second was the Dice index between the activation regions of the methods. The average Dice value over the tasks and three threshold levels was 0.73. The results of this study indicated how the data driven ISC analysis found the same foci as the model-based GLM analysis. The agreement of the results is highly interesting, because ISC is applicable in situations where GLM is not suitable, for example, when analyzing data from a naturalistic stimuli experiment.",
	author = "Juha Pajula and Jukka-Pekka Kauppi and Jussi Tohka",
	journal = "PLoS ONE",
	localfile = "/home/chris/studium/masterarbeit/paper/Pajula & Kauppi (2012). Inter-Subject Correlation in fMRI. Method Validation against Stimulus-Model Based Analysis.pdf",
	nlmuniqueid = "101285081",
	number = "8",
	pages = "e41196",
	pii = "PONE-D-12-04734",
	pmc = "PMC3414505",
	pubmed = "22924089",
	title = "{Inter-subject correlation in fMRI: method validation against stimulus-model based analysis.}",
	volume = "7",
	x-fetchedfrom = "PubMed",
	year = "2012"
}

@article{pamilo_2012_group-ICA_cinema,
	abstract = {Independent component analysis (ICA) can unravel functional brain networks from functional magnetic resonance imaging (fMRI) data. The number of the estimated components affects both the spatial pattern of the identified networks and their time-course estimates. Here group-ICA was applied at four dimensionalities (10, 20, 40, and 58 components) to fMRI data collected from 15 subjects who viewed a 15-min silent film ("At land" by Maya Deren). We focused on the dorsal attention network, the default-mode network, and the sensorimotor network. The lowest dimensionalities demonstrated most prominent activity within the dorsal attention network, combined with the visual areas, and in the default-mode network; the sensorimotor network only appeared with ICA comprising at least 20 components. The results suggest that even very low-dimensional ICA can unravel the most prominent functionally-connected brain networks. However, increasing the number of components gives a more detailed picture and functionally feasible subdivision of the major networks. These results improve our understanding of the hierarchical subdivision of brain networks during viewing of a movie that provides continuous stimulation embedded in an attention-directing narrative.},
	author = "Siina Pamilo and Sanna Malinen and Yevhen Hlushchuk and Mika Seppï¿œ and Pia Tikka and Riitta Hari",
	journal = "PLoS ONE",
	keywords = "Independent component analysis; ICA; silent movie; at land",
	localfile = "/home/chris/studium/masterarbeit/paper/Pamilo (2012). Functional Subdivision of Group-ICA Results of fMRI Data.pdf",
	nlmuniqueid = "101285081",
	note = "silent black-and-white film {\lq}{\lq}At Land{\rq}{\rq} by Maya Deren, 1944",
	number = "7",
	pages = "e42000",
	pii = "PONE-D-12-11505",
	pmc = "PMC3408398",
	pubmed = "22860044",
	title = "{Functional subdivision of group-ICA results of fMRI data collected during cinema viewing}",
	volume = "7",
	x-color = "#ffff00",
	x-fetchedfrom = "PubMed",
	year = "2012"
}

@article{park_2009_panoramic_scene_perception,
	author = "Soojin Park and Marvin M Chun",
	journal = "Neuroimage",
	keywords = "behavioral priority; fMRI; human parietal cortex; vision for action; spatial processing",
	localfile = "/home/chris/studium/masterarbeit/paper/Park (2009). Different roles of the parahippocampal place area (PPA) and retrosplenial cortex (RSC) in panoramic scene perception.pdf",
	number = "4",
	pages = "1747--1756",
	publisher = "Elsevier",
	title = "{Different roles of the parahippocampal place area (PPA) and retrosplenial cortex (RSC) in panoramic scene perception}",
	volume = "47",
	x-color = "#ffff00",
	year = "2009"
}

@article{ruby_2001_subjective_perspective_during_action_simulation,
	abstract = "Perspective taking is an essential component in the mechanisms that account for intersubjectivity and agency. Mental simulation of action can be used as a natural protocol to explore the cognitive and neural processing involved in agency. Here we took PET measurements while subjects simulated actions with either a first-person or a third-person perspective. Both conditions were associated with common activation in the SMA, the precentral gyrus, the precuneus and the MT/V5 complex. When compared to the first-person perspective, the third-person perspective recruited right inferior parietal, precuneus, posterior cingulate and frontopolar cortex. The opposite contrast revealed activation in left inferior parietal and somatosensory cortex. We suggest that the right inferior parietal, precuneus and somatosensory cortex are specifically involved in distinguishing self-produced actions from those generated by others.",
	author = "Perrine Ruby and Jean Decety",
	localfile = "/home/chris/studium/masterarbeit/paper/Ruby (2001). Effect of subjective perspective taking during simulation of action a PET investigation of agency.pdf",
	title = "{Effect of subjective perspective taking during simulation of action: a PET investigation of agency}",
	year = "2001"
}

@article{salmi_2014_others_actions_during_natural_viewing,
	abstract = "Abstract: The posterior parietal cortex (PPC) has been associated with multiple stimulus-driven (e.g., processing stimulus movements, providing visual signals for the motor system), goal-directed (e.g., directing visual attention to a target, processing behavioral priority of intentions), and action-related functions in previous studies with non-naturalistic paradigms. Here, we examined how these functions reflect PPC activity during natural viewing. Fourteen healthy volunteers watched a re-edited movie during functional magnetic resonance imaging (fMRI). Participants separately annotated behavioral priority (accounting for percepts, thoughts, and emotions) they had experienced during movie epi- sodes. Movements in the movie were quantified with computer vision and eye movements were recorded from a separate group of subjects. Our results show that while overlapping dorsomedial PPC areas respond to episodes with multiple types of stimulus content, ventrolateral PPC areas exhibit enhanced activity when viewing goal-directed human hand actions. Furthermore, PPC activity related to viewing goal-directed human hand actions was more accurately explained by behavioral priority than by movements of the stimulus or eye movements. Taken together, our results suggest that PPC participates in perception of goal-directed human hand actions, supporting the view that PPC has a special role in providing visual signals for the motor system (``how''), in addition to processing visual spatial movements (``where'').",
	author = "Juha Salmi and Enrico Glerean and Iiro P Jääskeläinen and Juha M Lahnakoski and Juho Kettunen and Jouko Lampinen and Pia Tikka and Mikko Sams",
	journal = "Human brain mapping",
	localfile = "/home/chris/studium/masterarbeit/paper/Salmi (2014). Posterior parietal cortex activity reflects the significance of others actions during natural viewing.pdf",
	number = "9",
	pages = "4767--4776",
	publisher = "Wiley Online Library",
	title = "{Posterior Parietal Cortex Activity Reflects the Significance of Others{\rq} Actions During Natural Viewing}",
	volume = "35",
	x-color = "#ffffa5",
	year = "2014"
}

@article{schutz_2011_eye_movements_perception_review,
	author = "Alexander C Schütz and Doris I Braun and Karl R Gegenfurtner",
	journal = "Journal of vision",
	localfile = "/home/chris/studium/masterarbeit/paper/Schütz (2010). Eye movements and perception. A selective review.pdf",
	number = "5",
	pages = "9--9",
	publisher = "The Association for Research in Vision and Ophthalmology",
	title = "{Eye movements and perception: A selective review}",
	volume = "11",
	x-color = "#ffff00",
	year = "2011"
}

@article{schwan_2000_film_cuts_facilitate_organization,
	author = "Stephan Schwan and Bärbel Garsoffky and Friedrich W Hesse",
	journal = "Memory \& Cognition",
	localfile = "/home/chris/studium/masterarbeit/paper/Schwan (2000). Do film cuts facilitate the perceptual and cognitive organization of activity sequences.pdf",
	number = "2",
	pages = "214--223",
	publisher = "Springer",
	title = "{Do film cuts facilitate the perceptual and cognitive organization of activitiy sequences?}",
	volume = "28",
	year = "2000"
}

@article{schwan_2010_movie_first_time,
	abstract = "Although film, television, and video play an important role in modern societies, the extent to which the similarities of cinematographic images to natural, unmediated conditions of visual experience contribute to viewers' comprehension is largely an open question. To address this question, we compared 20 inexperienced adult viewers from southern Turkey with groups of medium- and high-experienced adult viewers from the same region. In individual sessions, each participant was shown a set of 14 film clips that included a number of perceptual discontinuities typical for film. The viewers' interpretations were recorded and analyzed. The findings show that it is not the similarity to conditions of natural perception but the presence of a familiar line of action that determines the comprehensibility of films for inexperienced viewers. In the absence of such a line of action, extended prior experience is required for appropriate interpretation of cinematographic images such as those we investigated in this study.",
	author = "Stephan Schwan and Sermin Ildirar",
	journal = "Psychological Science",
	localfile = "/home/chris/studium/masterarbeit/paper/Schwan_(2010)_Watching Film for the First Time.pdf",
	month = jul,
	nlmuniqueid = "9007542",
	number = "7",
	pages = "970--976",
	pii = "0956797610372632",
	pubmed = "20530390",
	title = "{Watching film for the first time: How adult viewers interpret perceptual discontinuities in film}",
	volume = "21",
	x-fetchedfrom = "PubMed",
	year = "2010"
}

@article{shepherd_2010_human-monkey_gaze_correlation,
	abstract = "The neuroanatomical organization of the visual system is largely similar across primate species, predicting similar visual behaviors and perceptions. Although responses to trial-by-trial presentation of static images suggest that primates share visual orienting strategies, these reduced stimuli fail to capture key elements of the naturalistic, dynamic visual world in which we evolved. Here, we compared the gaze behavior of humans and macaques when they viewed three different 3-minute movie clips. We found significant intersubject and interspecies gaze correlations, suggesting that both species attend a common set of events in each scene. Comparing human and monkey gaze behavior with a computational saliency model revealed that interspecies gaze correlations were driven by biologically relevant social stimuli overlooked by low-level saliency models. Additionally, humans, but not monkeys, tended to gaze toward the targets of viewed individual's actions or gaze. Together, these data suggest that human and monkey gaze behavior comprises converging and diverging informational strategies, driven by both scene content and context; they are not fully described by simple low-level visual models.",
	author = "Stephen V Shepherd and Shawn A Steckenfinger and Uri Hasson and Asif A Ghazanfar",
	journal = "Current Biology",
	localfile = "/home/chris/studium/masterarbeit/paper/Shepherd (2010). Human-monkey gaze correlations reveal convergent and divergent patterns of movie viewing.pdf",
	mid = "NIHMS182522",
	month = apr,
	nlmuniqueid = "9107782",
	number = "7",
	pages = "649--656",
	pii = "S0960-9822(10)00219-8",
	pmc = "PMC2855404",
	pubmed = "20303267",
	title = "{Human-monkey gaze correlations reveal convergent and divergent patterns of movie viewing}",
	volume = "20",
	x-fetchedfrom = "PubMed",
	year = "2010"
}

@article{slater_2010_first_person_experience,
	author = "Mel Slater and Bernhard Spanlang and Maria V Sanchez-Vives and Olaf Blanke",
	journal = "PloS one",
	localfile = "/home/chris/studium/masterarbeit/paper/Slater, Blanke (2010). First Person Experience of Body Transfer in Virtual Reality.pdf",
	number = "5",
	pages = "1--9",
	publisher = "Public Library of Science",
	title = "{First person experience of body transfer in virtual reality}",
	volume = "5",
	year = "2010"
}

@article{smith_2013_watching_you_watching_movies,
	author = "Tim J Smith",
	localfile = "/home/chris/studium/masterarbeit/paper/Smith (2013). Watching You Watch Movies. Using Eye Tracking to Inform Cognitive Film Theory.pdf",
	publisher = "Oxford University Press",
	title = "{Watching you watch movies: Using eye tracking to inform film theory}",
	year = "2013"
}

@article{smith_2012_attentional_cinematic_continuity,
	abstract = "The intention of most film editing is to create the impression of continuity by editing together discontinuous viewpoints. The techniques used to achieve this, the continuity editing rules are well established yet there exists an incomplete understanding of their cognitive foundations. In this essay I will present the Attentional Theory of Cinematic Continuity (AToCC). AToCC identifies the critical role visual attention plays in the perception of continuity across cuts and demonstrates how perceptual expectations can be matched across cuts without the need for a coherent representation of the depicted space. The theory explains several key elements of the continuity editing style including match-action, matched-exit/entrances, shot/reverse-shot, the 180° rule and point-of-view editing. AToCC formalizes insights about viewer cognition that have been latent in the filmmaking community for nearly a century and demonstrates how much vision science in general can learn from film.",
	author = "Tim J Smith",
	journal = "Projections",
	localfile = "/home/chris/studium/masterarbeit/paper/Smith (2011). The Attentional Theory of Cinematic Continuity.pdf",
	number = "1",
	pages = "1--27",
	publisher = "Berghahn Journals",
	title = "{The attentional theory of cinematic continuity}",
	volume = "6",
	x-color = "#009966",
	year = "2012"
}

@incollection{smith_2010_film_cinema_perception,
	author = "Tim J Smith",
	localfile = "/home/chris/studium/masterarbeit/paper/Smith (2010). Film (cinema) perception. In: Goldstein, B.E. (ed.) Encyclopedia of Perception.pdf",
	publisher = "Sage",
	title = "{Film (cinema) perception}",
	year = "2010"
}

@article{smith_2008_edit_blindness,
	abstract = "Although we experience the visual world as a continuous, richly detailed space we often fail to notice large and significant changes. Such change blindness has been demonstrated for local object changes and changes to the visual form of whole images, however it is assumed that total changes from one image to another would be easily detected. Film editing presents such total changes several times a minute yet we rarely seem to be aware of them, a phenomenon we refer to here as edit blindness. This phenomenon has never been empirically demonstrated even though film editors believe they have at their disposal techniques that induce edit blindness, the Continuity Editing Rules. In the present study we tested the relationship between Continuity Editing Rules and edit blindness by instructing participants to detect edits while watching excerpts from feature films. Eye movements were recorded during the task. The results indicate that edits constructed according to the Continuity Editing Rules result in greater edit blindness than edits not adhering to the rules. A quarter of edits joining two viewpoints of the same scene were undetected and this increased to a third when the edit coincided with a sudden onset of motion. Some cuts may be missed due to suppression of the cut transients by coinciding with eyeblinks or saccadic eye movements but the majority seem to be due to inattentional blindness as viewers attend to the depicted narrative. In conclusion, this study presents the first empirical evidence of edit blindness and its relationship to natural attentional behaviour during dynamic scene viewing.",
	author = "Tim J Smith and John M Henderson",
	keywords = "film editing; eye movement; real-world scene; naturalistic scene; oculomotor capture; gaze cue; continuity editing",
	localfile = "/home/chris/studium/masterarbeit/paper/Smith (2008). Edit Blindness. The relationship between attention and global change blindness in dynamic scenes.pdf",
	title = "{Edit blindness: The relationship between attention and global change blindness in dynamic scenes}",
	x-color = "#ffff00",
	year = "2008"
}

@article{smith_2012_window_to_reality,
	abstract = "Edited moving images entertain, inform, and coerce us throughout our daily lives, yet until recently, the way people perceive movies has received little psychological attention. We review the history of empirical investigations into movie perception and the recent explosion of new research on the subject using methods such as behavioral experiments, functional magnetic resonance imagery (fMRI) eye tracking, and statistical corpus analysis. The Hollywood style of moviemaking, which permeates a wide range of visual media, has evolved formal conventions that are compatible with the natural dynamics of attention and humans{\rq} assumptions about continuity of space, time, and action. Identifying how people overcome the sensory differences between movies and reality provides an insight into how the same cognitive processes are used to perceive continuity in the real world.",
	author = "Tim J Smith and Daniel Levin and James E Cutting",
	journal = "Current Directions in Psychological Science",
	localfile = "/home/chris/studium/masterarbeit/paper/Smith (2012). A window on reality perceiving edited moving images.pdf",
	number = "2",
	pages = "107--113",
	publisher = "Sage Publications",
	title = "{A window on reality perceiving edited moving images}",
	url = "http://cdp.sagepub.com/content/21/2/107.short",
	volume = "21",
	x-color = "#ffffa5",
	year = "2012"
}

@article{spiers_2007_decoding_brain_during_real-world,
	abstract = "The human brain evolved to function and survive in a highly stimulating, complex and fast-changing world. Attempting to ascertain the neural substrates of operating in naturalistic contexts represents a huge challenge. Recently, however, researchers have begun to use several innovative analysis methods to interrogate functional magnetic resonance imaging (fMRI) data collected during dynamic naturalistic tasks. Central to these new developments is the inventive approach taken to segregating neural activity linked to specific events within the overall continuous stream of complex stimulation. In this review, we discuss the recent literature, detailing the key studies and their methods. These analytical techniques can be applied in a wide range of cognitive domains and, thus, offer exciting new opportunities for gaining insights into the brain bases of thoughts and behaviours in the real-world setting where they normally occur.",
	author = "Hugo J Spiers and Eleanor A Maguire",
	journal = "Trends Cognitive Sciences",
	localfile = "/home/chris/studium/masterarbeit/paper/Spiers (2007). Decoding human brain activity during real-world experiences.pdf",
	month = aug,
	nlmuniqueid = "9708669",
	number = "8",
	pages = "356--365",
	pii = "S1364-6613(07)00151-9",
	pubmed = "17618161",
	title = "{Decoding human brain activity during real-world experiences}",
	volume = "11",
	x-color = "#ffff00",
	x-fetchedfrom = "PubMed",
	year = "2007"
}

@article{spiers_2007_navigational_guidance_system,
	abstract = "Finding your way in large-scale space requires knowing where you currently are and how to get to your goal destination. While much is understood about the neural basis of one{\rq}s current position during navigation, surprisingly little is known about how the human brain guides navigation to goals. Computational accounts argue that specific brain regions support navigational guidance by coding the proximity and direction to the goal, but empirical evidence for such mechanisms is lacking. Here, we scanned subjects with functional MRI (fMRI) as they navigated to goal destinations in a highly accurate virtual simulation of a real city. Brain activity was then analysed in combination with metric measures of proximity and direction to goal destinations which were derived from each individual subject{\rq}s coordinates at every second of navigation. We found that activity in the medial prefrontal cortex was positively correlated, and activity in a right subicular/ entorhinal region was negatively correlated with goal proximity. By contrast, activity in bilateral posterior parietal cortex was correlated with egocentric direction to goals. Our results provide empirical evidence for a navigational guidance system in the human brain, and define more precisely the contribution of these three brain regions to human navigation. In addition, these findings may also have wider implications for how the brain monitors and integrates different types of information in the service of goal-directed behaviour in general.",
	author = "Hugo J. Spiers and Eleanor A. Maguire",
	keywords = "Navigation; goals; virtual reality; subiculum; medial prefrontal cortex; posterior parietal cortex",
	localfile = "/home/chris/studium/masterarbeit/paper/Spiers (2007). A navigational guidance system in the human brain.pdf",
	title = "{A navigational guidance system in the human brain}",
	year = "2007"
}

@article{spiers_2007_substrate_driving_behaviour,
	abstract = "Driving a vehicle is an indispensable daily behaviour for many people, yet we know little about how it is supported by the brain. Given that driving in the real world involves the engagement of many cognitive systems that rapidly change to meet varying environmental demands, identifying its neural basis presents substantial problems. By employing a unique combination of functional magnetic resonance imaging (fMRI), an accurate interactive virtual simulation of a bustling central London (UK) and a retrospective verbal report protocol, we surmounted these difficulties. We identified different events that characterise the driving process on a second by second basis and the brain regions that underlie them. Prepared actions such as starting, turning, reversing and stopping were associated with a common network comprised of premotor, parietal and cerebellar regions. Each prepared action also recruited additional brain areas. We also observed unexpected hazardous events such as swerving and avoiding collisions that were associated with activation of lateral occipital and parietal regions, insula, as well as a more posterior region in the medial premotor cortex than prepared actions. By contrast, planning future actions and monitoring fellow road users were associated with activity in superior parietal, lateral occipital cortices and the cerebellum. The anterior pre-SMA was also recruited during action planning. The right lateral prefrontal cortex was specifically engaged during the processing of road traffic rules. By systematically characterising the brain dynamics underlying naturalistic driving behaviour in a real city, our findings may have implications for how driving competence is considered in the context of neurological damage.",
	author = "Hugo J Spiers and Eleanor A Maguire",
	journal = "Neuroimage",
	keywords = "Virtual reality; fMRI; Verbal report; Action planning; Motor control; Rules; Monitoring; Traffic; Driver behaviour",
	localfile = "/home/chris/studium/masterarbeit/paper/Spiers (2007). Neural substrates of driving behaviour.pdf",
	number = "1",
	pages = "245--255",
	publisher = "Elsevier",
	title = "{Neural substrates of driving behaviour}",
	volume = "36",
	x-color = "#ffffa5",
	year = "2007"
}

@article{spiers_2006_thoughts_brain_during_navigation,
	abstract = "How does the human brain allow us to interact with and navigate through a constantly changing world? Whilst controlled experiments using functional brain imaging can give insightful snapshots of neuronal responses to relatively simplified stimuli, they cannot hope to mirror the challenges faced by the brain in the real world. However, trying to study the brain mechanisms supporting daily living represents a huge challenge. By combining functional neuroimaging, an accurate interactive virtual simulation of a bustling central London (UK), and a novel means of Freading\_ participants{\rq} thoughts whilst they moved around the city, we ascertained the online neural correlates underpin- ning navigation in this real-world context. A complex choreography of neural dynamics was revealed comprising focal and distributed, transient and sustained brain activity. Our results provide new insights into the specific roles of individual brain areas, in particular the hippocampus, retrosplenial, and frontal cortices, as well as offering clues about how functional specialisations operate within dynamic brain systems.",
	author = "Hugo J Spiers and Eleanor A Maguire",
	journal = "Neuroimage",
	localfile = "/home/chris/studium/masterarbeit/paper/Spiers (2006). Thoughts, behaviour, and brain dynamics during navigation in the real world.pdf",
	number = "4",
	pages = "1826--1840",
	publisher = "Elsevier",
	title = "{Thoughts, behaviour, and brain dynamics during navigation in the real world}",
	volume = "31",
	year = "2006"
}

@article{swallow_2009_event_boundaries_in_perception,
	author = "Khena M. Swallow and Jeffrey M. Zacks and Richard A. Abrams",
	localfile = "/home/chris/studium/masterarbeit/paper/Swallow, Zacks (2009). Event Boundaries in Perception Affect Memory Encoding and Updating.pdf",
	title = "{Event boundaries in perception affect memory encoding and updating.}",
	year = "2009"
}

@article{valuch_2015_influence_of_color_during_continuity_cuts,
	author = "Christian Valuch and Ulrich Ansorge",
	localfile = "/home/chris/studium/masterarbeit/paper/Valuch (2015). The influence of color during continuity cuts in edited movies. an eye-tracking study.pdf",
	title = "{The influence of color during continuity cuts in edited movies: An eye-tracking study}",
	year = "2015"
}

@article{vecchiato_2011_EEG_MEG_in_neuromarketing,
	abstract = "Here we present an overview of some published papers of interest for the marketing research employing electroencephalogram (EEG) and magnetoencephalogram (MEG) methods. The interest for these methodologies relies in their high-temporal resolution as opposed to the investigation of such problem with the functional Magnetic Resonance Imaging (fMRI) methodology, also largely used in the marketing research. In addition, EEG and MEG technologies have greatly improved their spatial resolution in the last decades with the introduction of advanced signal processing methodologies. By presenting data gathered through MEG and high resolution EEG we will show which kind of information it is possible to gather with these methodologies while the persons are watching marketing relevant stimuli. Such information will be related to the memorization and pleasantness related to such stimuli. We noted that temporal and frequency patterns of brain signals are able to provide possible descriptors conveying information about the cognitive and emotional processes in subjects observing commercial advertisements. These information could be unobtainable through common tools used in standard marketing research. We also show an example of how an EEG methodology could be used to analyze cultural differences between fruition of video commercials of carbonated beverages in Western and Eastern countries.",
	author = "Giovanni Vecchiato and Laura Astolfi and Fabrizio {De Vico Fallani} and Jlenia Toppi and Fabio Aloise and Francesco Bez and Daming Wei and Wanzeng Kong and Jounging Dai and Febo Cincotti and others",
	journal = "Computational intelligence and neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Vecchiato (2011). On the Use of EEG or MEG Brain Imaging Tools in Neuromarketing Research.pdf",
	note = "Review mit vielen References zu Studien mit TV commercials",
	pages = "3--12",
	publisher = "Hindawi Publishing Corp.",
	title = "{On the use of EEG or MEG brain imaging tools in neuromarketing research}",
	volume = "2011",
	year = "2011"
}

@article{vogeley_fink_2003_first_person_perspective,
	author = "Kai Vogeley and Gereon R Fink",
	localfile = "/home/chris/studium/masterarbeit/paper/Vogeley & Fink (2003). Neural correlates of the first-person-perspective.pdf",
	title = "{Neural correlates of the first-person-perspective}",
	x-color = "#009966",
	year = "2003"
}

@article{vogeley_2004_correlates_of_1st_person_perspective,
	author = "K. Vogeley and M. May and A. Ritzl and P. Falkai and K. Zilles and G. R. Fink",
	journal = "Journal of cognitive neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Vogeley (2004). Neural correlates of first-person perspective as one constituent of human self-consciousness.pdf",
	number = "5",
	pages = "817--827",
	publisher = "MIT Press",
	title = "{Neural correlates of first-person perspective as one constituent of human self-consciousness}",
	volume = "16",
	year = "2004"
}

@article{wallenius_2010_video_annotation_for_brain,
	abstract = "Studying the brain in naturalistic settings is a recent trend in neuroscience. Traditional brain imaging experiments have relied on using highly simplified and artificial stim- uli, but recently efforts have been put into studying the human brain in conditions closer to real-life. The methodology used in these studies involve imitating naturalis- tic stimuli with a movie. Because of the complexity of the naturalistic stimulus, a simplified model of it is needed to handle it computationally. This model is obtained by making annotations; collecting information of salient features of the movie to form a data structure. This data is compared with the brain activity evolving in time to search for possible corre- lations. All the features of a movie cannot be reliably annotated automatically: se- mantic features of a movie require manual annotations, which is in some occasions problematic due to the various cinematic techniques adopted. Understanding these methods helps analyzing and annotating movies. The movie Match Factory Girl (Aki Kaurismäki, 1990) was used as a stimulus in studying the brain in naturalistic settings. To help the analysis of the acquired data the salient visual features of the movie were annotated. In this work existing annotation approaches and available technologies for annotation were reviewed. Annotations help organizing information, therefore they are nowadays found every- where. Different tools and technologies are being developed constantly. Furthermore, development of automatic video analysis methods are going to provide more mean- ingful annotations in the future.",
	author = "Kalle Wallenius",
	journal = "Faculty of Electronics, Communications and Automation",
	localfile = "/home/chris/studium/masterarbeit/paper/Wallenius (2010). Video Annotation for Studying the Brain in Naturalistic Settings.pdf",
	pages = "1--4",
	publisher = "Citeseer",
	title = "{Video Annotation for Studying the Brain in Naturalistic Settings}",
	year = "2010"
}

@article{wang_2012_eye_movement_naturalistic_viewing,
	abstract = "The deployment of eye movements to complex spatiotemporal stimuli likely involves a variety of cognitive factors. However, eye movements to movies are surprisingly reliable both within and across observers. We exploited and manipulated that reliability to characterize observers' temporal viewing strategies while they viewed naturalistic movies. Introducing cuts and scrambling the temporal order of the resulting clips systematically changed eye movement reliability. We developed a computational model that exhibited this behavior and provided an excellent fit to the measured eye movement reliability. The model assumed that observers searched for, found, and tracked a point of interest and that this process reset when there was a cut. The model did not require that eye movements depend on temporal context in any other way, and it managed to describe eye movements consistently across different observers and two movie sequences. Thus, we found no evidence for the integration of information over long time scales (greater than a second). The results are consistent with the idea that observers employ a simple tracking strategy even while viewing complex, engaging naturalistic stimuli.",
	author = "Helena X Wang and Jeremy Freeman and Elisha P Merriam and Uri Hasson and David J Heeger",
	journal = "J Vis",
	localfile = "/home/chris/studium/masterarbeit/paper/Wang (2012). Temporal eye movement strategies during naturalistic viewing.pdf",
	mid = "NIHMS343254",
	nlmuniqueid = "101147197",
	note = {6 min clip of "Children of Men" as movie stimulus},
	number = "1",
	pages = "1--27",
	pii = "12.1.16",
	pmc = "PMC3273487",
	pubmed = "22262911",
	title = "{Temporal eye movement strategies during naturalistic viewing}",
	volume = "12",
	x-color = "#ffff00",
	x-fetchedfrom = "PubMed",
	year = "2012"
}

@article{westermann_1996_mood_induction_procedure,
	abstract = "The effectiveness and validity of 11 important mood induction procedures (MIPs) were comparatively evaluated by meta-analytical procedures. Two hundred and fifty effects of the experimental induction of positive, elated and negative, depressed mood in adult, non-clinical samples were integrated. Effect sizes were generally larger for negative than for positive mood inductions. The presentation of a film or story turned out to be most effective in inducing both positive and negative mood states. The effects are especially large when subjects are explicitly instructed to enter the specified mood state. For elated mood, all other MIPs yielded considerably lower effectiveness scores. For the induction of negative mood states, Imagination, Velten, Music, Social Interaction and Feedback MIPs were about as effective as the Film/Story MIP without instruction. Induction effects covaried with several study characteristics. Effects tend to be smaller when demand characteristics are controlled or subjects are not informed about the purpose of the experiment. For behavioural measures, effects are smaller than for self-reports but still larger than zero. Hence, the effects of MIPs can be partly, but not fully due to demand effects.\00",
	author = "Rainer Westermann and Kordelia Spies and Gï¿œnter Stahl and Friedrich W Hesse",
	journal = "European Journal of Social Psychology",
	note = "Woher Studie im Volltext nehmen?",
	number = "26",
	pages = "557--580",
	title = "{Relative effectiveness and validity of mood induction procedures: A meta-analysis}",
	url = "http://www.researchgate.net/publication/227957233_Westermann_R._Spies_K._Stahl_G._K.__Hesse_F._W._(1996)._Relative_effectiveness_and_vali-dity_of_mood_induction_procedures_A_meta-analysis._European_Journal_of_Social_Psychology_26_557-580",
	year = "1996"
}

@article{whittingstall_2010_movies_eeg_fmri,
	abstract = "Electroencephalography (EEG) and functional magnetic resonance imaging (fMRI) are noninvasive neuroimaging tools which can be used to measure brain activity with excellent temporal and spatial resolution, respectively. By combining the neural and hemodynamic recordings from these modalities, we can gain better insight into how and where the brain processes complex stimuli, which may be especially useful in patients with different neural diseases. However, due to their vastly different spatial and temporal resolutions, the integration of EEG and fMRI recordings is not always straightforward. One fundamental obstacle has been that paradigms used for EEG experiments usually rely on event-related paradigms, while fMRI is not limited in this regard. Therefore, here we ask whether one can reliably localize stimulus-driven EEG activity using the continuously varying feature intensities occurring in natural movie stimuli presented over relatively long periods of time. Specifically, we asked whether stimulus-driven aspects in the EEG signal would be co-localized with the corresponding stimulus-driven BOLD signal during free viewing of a movie. Secondly, we wanted to integrate the EEG signal directly with the BOLD signal, by estimating the underlying impulse response function (IRF) that relates the BOLD signal to the underlying current density in the primary visual area (V1). We made sequential fMRI and 64-channel EEG recordings in seven subjects who passively watched 2-min-long segments of a James Bond movie. To analyze EEG data in this natural setting, we developed a method based on independent component analysis (ICA) to reject EEG artifacts due to blinks, subject movement, etc., in a way unbiased by human judgment. We then calculated the EEG source strength of this artifact-free data at each time point of the movie within the entire brain volume using low-resolution electromagnetic tomography (LORETA). This provided for every voxel in the brain (i.e., in 3D space) an estimate of the current density at every time point. We then carried out a correlation between the time series of visual contrast changes in the movie with that of EEG voxels. We found the most significant correlations in visual area V1, just as seen in previous fMRI studies (Bartels A, Zeki, S, Logothetis NK. Natural vision reveals regional specialization to local motion and to contrast-invariant, global flow in the human brain. Cereb Cortex 2008;18(3):705-717), but on the time scale of milliseconds rather than of seconds. To obtain an estimate of how the EEG signal relates to the BOLD signal, we calculated the IRF between the BOLD signal and the estimated current density in area V1. We found that this IRF was very similar to that observed using combined intracortical recordings and fMRI experiments in nonhuman primates. Taken together, these findings open a new approach to noninvasive mapping of the brain. It allows, firstly, the localization of feature-selective brain areas during natural viewing conditions with the temporal resolution of EEG. Secondly, it provides a tool to assess EEG/BOLD transfer functions during processing of more natural stimuli. This is especially useful in combined EEG/fMRI experiments, where one can now potentially study neural-hemodynamic relationships across the whole brain volume in a noninvasive manner.",
	author = "Kevin Whittingstall and Andreas Bartels and Vanessa Singh and Soyoung Kwon and Nikos K Logothetis",
	journal = "Magnetic Resonance Imaging",
	keywords = "EEG; fMRI; Source localization; Natural scenes; James Bond; ow- resolution electromagnetic tomography; LORETA",
	localfile = "/home/chris/studium/masterarbeit/paper/Whittingstall (2010). Integration of EEG source imaging and fMRI during continuous viewing.pdf",
	month = oct,
	nlmuniqueid = "8214883",
	number = "8",
	pages = "1135--1142",
	pii = "S0730-725X(10)00133-5",
	pubmed = "20579829",
	title = "{Integration of EEG source imaging and fMRI during continuous viewing of natural movies}",
	volume = "28",
	x-color = "#ffffa5",
	x-fetchedfrom = "PubMed",
	year = "2010"
}

@article{wraga_2005_imagined_rotation_self_others,
	abstract = "This study used functional magnetic resonance imaging (fMRI) to investigate the neural mechanisms underlying two types of spatial transformations: imagined object rotations and imagined rotations of the self about an object. Participants viewed depictions of single three- dimensional Shepard--Metzler objects situated within a sphere. A T-shaped prompt appeared outside of the sphere at different locations across trials. In the object rotation task, participants imagined rotating the object so that one of its ends was aligned with the prompt. They then judged whether a textured portion of the object would be visible in its new orientation. In the self rotation task, they imagined rotating themselves to the location of the T-prompt, and then judged whether a textured portion of the object would be visible from the new viewpoint. Activation in both tasks was compared to respective control conditions in which identical judgments were made without rotation. A direct comparison of self and object rotation tasks revealed activation spreading from left premotor to left primary motor (M1) cortex (areas 6/4) for imagined object rotations, but not imagined self rotations. In contrast, the self rotation task activated left supplementary motor area (SMA; area 6). In both transformations, activation also occurred in other regions. These findings provide evidence for multiple spatial-transformation mechanisms within the human cognitive system.",
	author = "Maryjane Wraga and Jennifer M Shephard and Jessica A Church and Souheil Inati and Stephen M Kosslyn",
	journal = "Neuropsychologia",
	keywords = "Mental imagery; Mental rotation; Motor learning; fMRI; self rotation",
	localfile = "/home/chris/studium/masterarbeit/paper/Wraga (2005). Imagined rotations of self versus objects.pdf",
	number = "9",
	pages = "1351--1361",
	publisher = "Elsevier",
	title = "{Imagined rotations of self versus objects: an fMRI study}",
	volume = "43",
	year = "2005"
}

@article{zacks_1999_imagined_transformation_bodies,
	abstract = "A number of spatial reasoning problems can be solved by performing an imagined transformation of one's egocentric perspective. A series of experiments were carried out to characterize this process behaviorally and in terms of its brain basis, using functional magnetic resonance imaging (fMRI). In a task contrast designed to isolate egocentric perspective transformations, participants were slower to make left-right judgments about a human figure from the figure's perspective than from their own. This transformation led to increased cortical activity around the left parietal-temporal-occipital junction, as well as in other areas including left frontal cortex. In a second task contrast comparing judgments about inverted figures to judgments about upright figures (always from the figure's perspective), participants were slower to make left-right judgments about inverted figures than upright ones. This transformation led to activation in posterior areas near those active in the first experiment, but weaker in the left hemisphere and stronger in the right, and also to substantial left frontal activation. Together, the data support the specialization of areas near the parietal-temporal-occipital junction for egocentric perspective transformations. These results are also suggestive of a dissociation between egocentric perspective transformations and object- based spatial transformations such as mental rotation.",
	author = "Jeff Zacks and Bart Rypma and JDE Gabrieli and Barbara Tversky and Gary H Glover",
	keywords = "Mental rotation; fMRI; Egocentric; Spatial; Perspective",
	localfile = "/home/chris/studium/masterarbeit/paper/Zacks (1999). Imagined transformations of bodies.pdf",
	title = "{Imagined transformations of bodies: an fMRI investigation}",
	year = "1999"
}

@article{zacks_2008_mental_rotation_meta-analysis_and_review,
	author = "Jeffrey M. Zacks",
	localfile = "/home/chris/studium/masterarbeit/paper/Zacks (2008). Neuroimaging studies of mental rotation. A meta-analysis and review.pdf",
	title = "{Neuroimaging studies of mental rotation: A meta-analysis and review}",
	year = "2008"
}

@article{zacks_2001_perceptual_event_boundaries,
	abstract = "Temporal structure has a major role in human understanding of everyday events. Observers are able to segment ongoing activity into temporal parts and sub-parts that are reliable, meaningful and cor- related with ecologically relevant features of the action. Here we present evidence that a network of brain regions is tuned to perceptually salient event boundaries, both during intentional event segmentation and during naive passive viewing of events. Activity within this network may provide a basis for parsing the temporally evolving environment into meaningful units.",
	added-at = "2008-09-16T23:39:07.000+0200",
	author = "J. M. Zacks and T. S. Braver and M. A. Sheridan and D. I. Donaldson and A. Z. Snyder and J. M. Ollinger and R. L. Buckner and M. E. Raichle",
	interhash = "b815c8d4cd1cdb22e4f8dddbb8b04b28",
	intrahash = "26a666a502bc2cfcbea81ba651e918c9",
	journal = "Nature Neuroscience",
	keywords = "event boundaries; segmentation; fMRI",
	localfile = "/home/chris/studium/masterarbeit/paper/Zacks (2001). Human brain activity time-locked to perceptual event boundaries.pdf",
	number = "6",
	pages = "651--655",
	title = "{Human brain activity time-locked to perceptual event boundaries}",
	volume = "4",
	x-fetchedfrom = "Bibsonomy",
	year = "2001"
}

@article{zacks_2005_transformations_visuospatial_images,
	abstract = "Transformations of visuospatial mental images are important for action, navigation, and reasoning. They depend on repre- sentations in multiple spatial reference frames, implemented in the posterior parietal cortex and other brain regions. The multi- ple systems framework proposes that different transformations can be distinguished in terms of which spatial reference frame is updated. In an object-based transformation, the reference frame of an object moves relative to those of the observer and the envi- ronment. In a perspective transformation, the observer{\rq}s egocen- tric reference frame moves relative to those of the environment and of salient objects. These two types of spatial reference frame updating rely on distinct neural processing resources in the pari- etal, occipital, and temporal cortex. They are characterized by different behavioral patterns and unique individual differ- ences. Both object-based transformations and perspective trans- formations interact with posterior frontal cortical regions sub- serving the simulation of body movements. These interactions indicate that multiple systems coordinate to support everyday spatial problem solving.",
	author = "Jeffrey M Zacks and Pascale Michelon",
	keywords = "imagery; visuospatial; mental rotation; review",
	localfile = "/home/chris/studium/masterarbeit/paper/Zacks (2005). Transformations of Visuospatial Images.pdf",
	title = "{Transformations of visuospatial images}",
	year = "2005"
}

@article{zacks_2000_mental_transformations_of_objects_and_perspective,
	abstract = "This study sought evidence for the independence of two classes of mental spatial transformation: object-based spatial transformations and egocentric perspective transforma- tions. Two tasks were designed to selectively elicit these two transformations using the same materials, participants, and task parameters: one required same-different judgments about pairs of pictures, while the other required left-right judgments about single pictures. For pictures of human bodies, the two tasks showed strikingly different patterns of response time as a function of stimulus orientation. Moreover, across individuals, the two tasks had different relationships to psychometric tests of spatial ability. The chronometric and individual difference data converge with neuropsychological and neuroimaging data in suggesting that different mental spatial transformations are performed by dissociable neural systems.",
	author = "Jeffrey M. Zacks and Jon Mires and Barbara Tversky and Eliot Hazeltine",
	keywords = "cognition; cognitive neuroscience; individual differences; mental rotation; sex differences; spatial reasoning",
	localfile = "/home/chris/studium/masterarbeit/paper/Zacks (2000). Mental spatial transformations of objects and perspective.pdf",
	title = "{Mental spatial transformations of objects and perspective}",
	year = "2000"
}

@article{zacks_2002_parametric_mental_transformation_of_bodies,
	author = "Jeffrey M. Zacks and John M. Ollinger and Margaret A. Sheridan and Barbara Tversky",
	journal = "Neuroimage",
	localfile = "/home/chris/studium/masterarbeit/paper/Zacks (2002). Parametric Study of Mental Spatial Transformations of Bodies.pdf",
	number = "4",
	pages = "857--872",
	publisher = "Elsevier",
	title = "{A parametric study of mental spatial transformations of bodies}",
	volume = "16",
	x-color = "#ffffa5",
	year = "2002"
}

@article{zacks_2009_segmentation_reading_and_film,
	abstract = "When reading a story or watching a film, comprehenders construct a series of representations in order to understand the events depicted. Discourse comprehension theories and a recent theory of perceptual event segmentation both suggest that comprehenders monitor situational features such as characters{\rq} goals, to update these representations at natural boundaries in activity. However, the converging predictions of these theories had previously not been tested directly. Two studies provided evidence that changes in situational features such as characters, their locations, their interactions with objects, and their goals are related to the segmentation of events in both narrative texts and films. A 3rd study indicated that clauses with event boundaries are read more slowly than are other clauses and that changes in situational features partially mediate this relation. A final study suggested that the predictability of incoming information influences reading rate and possibly event segmentation. Taken together, these results suggest that processing situational changes during comprehension is an important determinant of how one segments ongoing activity into events and that this segmentation is related to the control of processing during reading.",
	author = "Jeffrey M. Zacks and Nicole K. Speer and Jeremy R. Reynolds",
	keywords = "situation models, event perception, text comprehension; event boundaries; segmentation",
	localfile = "/home/chris/studium/masterarbeit/paper/Zacks (2009). Segmentation in Reading and Film Comprehension.pdf",
	title = "{Segmentation in reading and film comprehension.}",
	year = "2009"
}

@article{zacks_2007_event_perception_mind-brain_perspective,
	abstract = "People perceive and conceive of activity in terms of discrete events. Here the authors propose a theory according to which the perception of boundaries between events arises from ongoing perceptual processing and regulates attention and memory. Perceptual systems continuously make predictions about what will happen next. When transient errors in predictions arise, an event boundary is perceived. According to the theory, the perception of events depends on both sensory cues and knowledge structures that represent previously learned information about event parts and inferences about actors' goals and plans. Neurological and neurophysiological data suggest that representations of events may be implemented by structures in the lateral prefrontal cortex and that perceptual prediction error is calculated and evaluated by a processing pathway, including the anterior cingulate cortex and subcortical neuromodulatory systems.",
	author = "Jeffrey M Zacks and Nicole K Speer and Khena M Swallow and Todd S Braver and Jeremy R Reynolds",
	doi = "10.1037/0033-2909.133.2.273",
	journal = "Psycholgical Bulletin",
	keywords = "events; attention; memory; prefrontal cortex; orienting response; segmentation; event boundaries",
	localfile = "/home/chris/studium/masterarbeit/paper/Zacks (2007). Event Perception. A Mind-Brain Perspective (review).pdf",
	mid = "NIHMS185252",
	month = mar,
	nlmuniqueid = "0376473",
	number = "2",
	pages = "273--93",
	pii = "2007-02367-005",
	pmc = "PMC2852534",
	pubmed = "17338600",
	title = "{Event perception: a mind-brain perspective}",
	volume = "133",
	x-fetchedfrom = "PubMed",
	year = "2007"
}

@article{zacks_2010_brains_cutting_room,
	abstract = "Observers segment ongoing activity into meaningful events. Segmentation is a core component of perception that helps determine memory and guide planning. The current study tested the hypotheses that event segmentation is an automatic component of the perception of extended naturalistic activity, and that the identification of event boundaries in such activities results in part from processing changes in the perceived situation. Observers may identify boundaries between events as a result of processing changes in the observed situation. To test this hypothesis and study this potential mechanism, we measured brain activity while participants viewed an extended narrative film. Large transient responses were observed when the activity was segmented, and these responses were mediated by changes in the observed activity, including characters and their interactions, interactions with objects, spatial location, goals, and causes. These results support accounts that propose event segmentation is automatic and depends on processing meaningful changes in the perceived situation; they are the first to show such effects for extended naturalistic human activity.",
	author = "Jeffrey M Zacks and Nicole K Speer and Khena M Swallow and Corey J Maley",
	journal = "Front Hum Neurosci",
	keywords = "action; cinema; discourse; event perception; functional MRI; event boundaries; segmentation",
	localfile = "/home/chris/studium/masterarbeit/paper/Zacks (2010). The Brains cutting-room floor.pdf",
	nlmuniqueid = "101477954",
	note = "Movie Stimulus: The Red Balloon",
	pmc = "PMC2955413",
	pubmed = "20953234",
	title = "{The brain's cutting-room floor: Segmentation of narrative cinema}",
	volume = "4",
	x-color = "#cc3300",
	x-fetchedfrom = "PubMed",
	year = "2010"
}

@article{zacks_2003_imagined_viewer_and_object_rotations,
	abstract = "Human spatial reasoning may depend in part on two dissociable types of mental image transformations: object- based transformations, in which an object is imagined to move in space relative to the viewer and the environment, and perspective transformations, in which the viewer imagines the scene from a different vantage point. This study measured local brain activity with event-related fMRI while participants were instructed to either imagine an array of objects rotating (an object-based transformation) or imagine themselves rotating around the array (a perspective transformation). Object-based transformations led to selec- tive increases in right parietal cortex and decreases in left parietal cortex, whereas perspective transformations led to selective increases in left temporal cortex. These results argue against the view that mental image transformations are performed by a unitary neural processing system, and they suggest that different overlapping systems are engaged for different image transformations.",
	author = "Jeffrey M Zacks and Jean M Vettel and Pascale Michelon",
	journal = "Journal of Cognitive Neuroscience",
	keywords = "self rotation; perspective transformation",
	localfile = "/home/chris/studium/masterarbeit/paper/Zacks (2003). Imagined Viewer and Object Rotations Dissociated with Event-Related fMRI.pdf",
	number = "7",
	pages = "1002--1018",
	publisher = "MIT Press",
	title = "{Imagined viewer and object rotations dissociated with event-related fMRI}",
	volume = "15",
	x-color = "#ffffa5",
	year = "2003"
}

@book{ward_2009_students_guide,
	author = "Jamie Ward",
	edition = "2",
	isbn = "9781848720039",
	month = "12",
	publisher = "Psychology Press",
	title = "{The Student's Guide to Cognitive Neuroscience, 2nd Edition}",
	year = "2009"
}

@book{bear_connors_paradiso_2006_neuroscience,
	author = "Mark F. Bear and Barry W. Connors and Michael A. Paradiso",
	edition = "3rd",
	isbn = "9780781760034",
	month = "2",
	publisher = "Lippincott Williams and Wilkins",
	title = "{Neuroscience: Exploring the Brain}",
	year = "2006"
}

@article{aminoff_2013_role_of_parahippocampal_cortex,
	author = "Elissa M Aminoff and Kestutis Kveraga and Moshe Bar",
	journal = "Trends in Cognitive Sciences",
	keywords = "review",
	localfile = "/home/chris/studium/masterarbeit/paper/Aminoff (2013). The role of the parahippocampal cortex in cognition (review).pdf",
	number = "8",
	pages = "379--390",
	publisher = "Elsevier",
	title = "{The role of the parahippocampal cortex in cognition}",
	volume = "17",
	x-color = "#ffff00",
	year = "2013"
}

@article{best_2001_spatial_processing_review,
	author = "Phillip J Best and Aaron M White and Ali Minai",
	journal = "Annual review of neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Best (2001). Spatial Processing in the Brain. The Activity of Hippocampal Place Cells (review).pdf",
	number = "1",
	pages = "459--486",
	title = "{Spatial Processing in the brain: The activity of hippocampal place cells}",
	volume = "24",
	year = "2001"
}

@article{burgess_2002_human_hippocampus_spatial_episodic_memory_review,
	abstract = "Finding one{\rq}s way around an environment and remem- bering the events that occur within it are crucial cogni- tive abilities that have been linked to the hippocampus and medial temporal lobes. Our review of neuropsy- chological, behavioral, and neuroimaging studies of human hippocampal involvement in spatial memory concentrates on three important concepts in this field: spatial frameworks, dimensionality, and orientation and self-motion. We also compare variation in hippo- campal structure and function across and within spe- cies. We discuss how its spatial role relates to its accepted role in episodic memory. Five related studies use virtual reality to examine these two types of mem- ory in ecologically valid situations. While processing of spatial scenes involves the parahippocampus, the right hippocampus appears particularly involved in memory for locations within an environment, with the left hippocampus more involved in context-dependent episodic or autobiographical memory.",
	author = "Neil Burgess and Eleanor A Maguire and John O'Keefe",
	journal = "Neuron",
	keywords = "left hippocampus; right hippocampus",
	localfile = "/home/chris/studium/masterarbeit/paper/Burgess (2002). The Human Hippocampus and Spatial and Episodic Memory (review).pdf",
	number = "4",
	pages = "625--641",
	publisher = "Elsevier",
	title = "{The human hippocampus and spatial and episodic memory}",
	volume = "35",
	x-color = "#ffffa5",
	year = "2002"
}

@article{burgess_2006_spatial_memory_egocentric_allocentric,
	author = "Neil Burgess",
	journal = "Trends in Cognitive Sciences",
	localfile = "/home/chris/studium/masterarbeit/paper/Burgess (2006). Spatial memory. How egocentric and allocentric combine.pdf",
	number = "12",
	pages = "551--557",
	publisher = "Elsevier",
	title = "{Spatial memory: How egocentric and allocentric combine}",
	volume = "10",
	x-color = "#ffff00",
	year = "2006"
}

@article{burgess_2008_spatial_cognition_review,
	abstract = "Recent advances in the understanding of spatial cognition are reviewed, focusing on memory for locations in large-scale space and on those advances inspired by single-unit recording and lesion studies in animals. Spatial memory appears to be supported by multiple parallel representations, including egocentric and allocentric representations, and those updated to accommodate self- motion. The effects of these representations can be dissociated behaviorally, developmentally, and in terms of their neural bases. It is now becoming possible to construct a mechanistic neural-level model of at least some aspects of spatial memory and imagery, with the hippocampus and medial temporal lobe providing allocentric environmental representations, the parietal lobe egocentric representations, and the retrosplenial cortex and parieto-occipital sulcus allowing both types of representation to interact. Insights from this model include a common mechanism for the construction of spatial scenes in the service of both imagery and episodic retrieval and a role for the remainder of Papez{\rq}s circuit in orienting the viewpoint used. In addition, it appears that hippocampal and striatal systems process different aspects of environmental layout (boundaries and local landmarks, respectively) and do so using different learning rules (incidental learning and associative reinforcement, respectively).",
	author = "Neil Burgess",
	journal = "Annals of the New York Academy of Sciences",
	keywords = "parietal; hippocampal; striatal; fMRI; place cells; grid cells; allocentric; egocentric; computational modeling",
	localfile = "/home/chris/studium/masterarbeit/paper/Burgess (2008). Spatial Cognition and the Brain (review).pdf",
	number = "1",
	pages = "77--97",
	publisher = "Wiley Online Library",
	title = "{Spatial cognition and the brain}",
	volume = "1124",
	x-color = "#ffff00",
	year = "2008"
}

@article{corbetta_2008_reorienting_system,
	author = "Maurizio Corbetta and Gaurav Patel and Gordon L Shulman",
	journal = "Neuron",
	localfile = "/home/chris/studium/masterarbeit/paper/Corbetta (2008). The Reorienting System of the Human Brain. From Environment to Theory of Mind (review).pdf",
	number = "3",
	pages = "306--324",
	publisher = "Elsevier",
	title = "{The reorienting system of the human brain: from environment to theory of mind}",
	volume = "58",
	x-color = "#ffff00",
	year = "2008"
}

@article{eichenbaum_1999_hippocampus_memory_place_cells_review,
	author = "Howard Eichenbaum and Paul Dudchenko and Emma Wood and Matthew Shapiro and Heikki Tanila",
	journal = "Neuron",
	localfile = "/home/chris/studium/masterarbeit/paper/Eichenbaum (1999). The Hippocampus, Memory, and Place Cells. Is It Spatial Memory or a Memory Space (review).pdf",
	number = "2",
	pages = "209--226",
	publisher = "Elsevier",
	title = "{The hippocampus, memory, and place cells: is it spatial memory or a memory space?}",
	volume = "23",
	year = "1999"
}

@article{eichenbaum_2001_hippocampus_declarative_memory_review,
	abstract = "It is widely accepted that the hippocampus and related brain areas mediate declarative (or explicit) memory in humans. However, little is known about the fundamental cognitive mechanisms of hippocampal dependent memory or about the nature of hippocampal neural representations that underlie properties of declarative memory. Here, it is proposed that the hippocampus plays a critical role, when distinct personal experiences must be encoded in relation to one another and linked within an organization that supports flexible, inferential memory expression. This set of fundamental cognitive mechanisms is consistent with key properties of declarative memory as observed in humans. Furthermore, emerging evidence from recordings of hippocampal neural activity shows that hippocampal networks encode episodic memories as sequences of events and the places, where they occur. In addition, hippocampal neuronal networks encode events and places that are common across related episodes. This combination of coding properties suggests that the hippocampus contributes to declarative memory by mediating the construction of a {\lq}memory space{\rq} composed of a network of linked episodic representations. © 2001 Elsevier Science B.V. All rights reserved.",
	author = "Howard Eichenbaum",
	journal = "Behavioural brain research",
	keywords = "Episodic memory; Declarative memory; Semantic memory; Transitive inference; Hippocampus; Cognitive maps; Place cells",
	localfile = "/home/chris/studium/masterarbeit/paper/Eichenbaum (2001). The hippocampus and declarative memory. Cognitive mechanisms and neural codes (review).pdf",
	number = "1",
	pages = "199--207",
	publisher = "Elsevier",
	title = "{The hippocampus and declarative memory: cognitive mechanisms and neural codes}",
	volume = "127",
	x-color = "#ffffa5",
	year = "2001"
}

@inproceedings{eichenbaum_2003_hippocampus_all_come_together_review,
	abstract = "It is widely accepted that the hippocampus and related brain areas mediate declarative memory in humans. However, little is known about the fundamental cognitive mechanisms of hippocampal- dependent memory or about the nature of hippocampal neural representations that underlie properties of declarative memory. Here it is proposed that the hippocampus plays a critical role in two ways: first in representing experiences as a series of events and the places where they occur, and second in linking episodic representations to one another by common events. This organization of linked episodic memories supports a capacity for flexible, inferential memory expression. A growing body of data from ablation and recording studies supports this characterization of hippocampal memory processing as a fundamental property of declarative memory.",
	author = "Howard Eichenbaum",
	booktitle = "{International Congress Series}",
	keywords = "Episodic memory; Declarative memory; Semantic memory; Recognition; Transitive inference; Hippocampus; Place cells",
	localfile = "/home/chris/studium/masterarbeit/paper/Eichenbaum (2003). The hippocampus, episodic memory, declarative memory, spatial memory. where does it all come together (review).pdf",
	organization = "Elsevier",
	pages = "235--244",
	title = "{The hippocampus, episodic memory, declarative memory, spatial memory{\ldots} where does it all come together?}",
	volume = "1250",
	x-color = "#ffffa5",
	year = "2003"
}

@article{eichenbaum_2004_hippocampus_cogn_processes_review,
	abstract = "The hippocampus serves a critical role in declarative memory---our capacity to recall everyday facts and events. Recent studies using functional brain imaging in humans and neuropsychological analyses of hu- mans and animals with hippocampal damage have revealed some of the elemental cognitive processes mediated by the hippocampus. In addition, recent characterizations of neuronal firing patterns in behav- ing animals and humans have suggested how neural representations in the hippocampus underlie those el- emental cognitive processes in the service of declara- tive memory.",
	author = "Howard Eichenbaum",
	journal = "Neuron",
	localfile = "/home/chris/studium/masterarbeit/paper/Eichenbaum (2004). Hippocampus. Cognitive Processes and Neural Representations that Underlie Declarative Memory (review).pdf",
	number = "1",
	pages = "109--120",
	publisher = "Elsevier",
	title = "{Hippocampus: Cognitive processes and neural representations that underlie declarative memory}",
	volume = "44",
	year = "2004"
}

@article{epstein_2008_parahippocampal_retrospinal_navigation,
	abstract = "Spatial navigation is a core cognitive ability in humans and animals. Neuroimaging studies have identified two functionally defined brain regions that activate during navigational tasks and also during passive viewing of navigationally relevant stimuli such as environmental scenes: the parahippocampal place area (PPA) and the retrosplenial complex (RSC). Recent findings indicate that the PPA and RSC have distinct and complementary roles in spatial navigation, with the PPA more concerned with representation of the local visual scene and RSC more concerned with situating the scene within the broader spatial environment. These findings are a first step towards understanding the separate components of the cortical network that mediates spatial navigation in humans.",
	author = "Russell A Epstein",
	localfile = "/home/chris/studium/masterarbeit/paper/Epstein (2008). Parahippocampal and retrosplenial contributions to human spatial navigation (review).pdf",
	title = "{Parahippocampal and retrosplenial contributions to human spatial navigation}",
	x-color = "#ffff00",
	year = "2008"
}

@article{gaussier_2002_view_cells_place_cells_cognitive_map_learning,
	abstract = "The goal of this paper is to propose a model of the hippocampal system that reconciles the presence of neurons that look like ``place cells'' with the implication of the hippocampus (Hs) in other cognitive tasks (e.g., complex conditioning acquisition and memory tasks). In the proposed model, ``place cells'' or ``view cells'' are learned in the perirhinal and entorhinal cortex. The role of the Hs is not fundamentally dedicated to navigation or map building, the Hs is used to learn, store, and predict transitions between multimodal states. This transition prediction mechanism could be important for novelty detection but, above all, it is crucial to merge planning and sensory±motor functions in a single and coherent system. A neural architecture embedding this model has been successfully tested on an autonomous robot, during navigation and planning in an open environment.",
	author = "Philippe Gaussier and Arnaud Revel and Jean-Paul Banquet and Vincent Babeau",
	journal = "Biological Cybernetics",
	localfile = "/home/chris/studium/masterarbeit/paper/Gaussiert (2002). From view cells and place cells to cognitive map learning. Processing stages of the hippocampal system.pdf",
	number = "1",
	pages = "15--28",
	publisher = "Springer",
	title = "{From view cells and place cells to cognitive map learning: processing stages of the hippocampal system}",
	volume = "86",
	year = "2002"
}

@article{hartley_2005_complementary_memory_systems,
	abstract = "Spatial navigation depends on dissociable memory systems that have distinct neural bases and employ different forms of representation. One system gradually acquires reliable sequences of responses to given situations (e.g. repeatedly following a fixed route), and depends on the striatum. The other develops flexible representations permitting novel responses (e.g. finding new shortcuts), and depends on the hippocampus. Voermans and colleagues explore the interaction between these two systems using functional neuroima- ging and behavioural measures in a clinical population.",
	author = "Tom Hartley and Neil Burgess",
	journal = "Trends in Neurosciences",
	localfile = "/home/chris/studium/masterarbeit/paper/Hartley (2005). Complementary memory systems. Competition, cooperation and compensation.pdf",
	number = "4",
	pages = "169--170",
	publisher = "Elsevier",
	title = "{Complementary memory systems: Competition, cooperation and compensation}",
	volume = "28",
	year = "2005"
}

@article{king_2002_human_hippocampus_viewpoint_dependence,
	abstract = "Virtual reality was used to sequentially present objects within a town square and to test recognition of object locations from the same viewpoint as presentation, or from a shifted viewpoint. A develop- mental amnesic case with focal bilateral hippocampal pathology showed a massive additional impairment when tested from the shifted viewpoint compared with a mild, list length-dependent, impairment when tested from the same viewpoint. While the same-view condition could be solved by visual pattern matching, the shifted-view condition requires a view- point independent representation or an equivalent mechanism for trans- lating or rotating viewpoints in memory. The latter mechanism was indi- cated by control subjects{\rq} response latencies in the shifted-view condition, although the amnesic case is not impaired in tests of mental rotation of single objects. These results show that the human hippocam- pus supports viewpoint independence in spatial memory, and suggest that it does so by providing a mechanism for viewpoint manipulation in memory. In addition, they suggest an extremely sensitive test for human hippocampal damage, and hint at the nature of the hipppocampal role in episodic recollection",
	author = "John A King and Neil Burgess and Tom Hartley and Faraneh Vargha-Khadem and John O'Keefe",
	journal = "Hippocampus",
	keywords = "developmental amnesia; hippocampal lesion; virtual re- ality; cognitive map; recognition memory; allocentric; mental rotation",
	localfile = "/home/chris/studium/masterarbeit/paper/King (2002). Human Hippocampus and Viewpoint Dependence in Spatial Memory.pdf",
	number = "6",
	pages = "811--820",
	publisher = "Wiley Online Library",
	title = "{Human hippocampus and viewpoint dependence in spatial memory}",
	volume = "12",
	x-color = "#ffff00",
	year = "2002"
}

@article{leutgeb_2005_place_cells_spatial_maps_review,
	abstract = "The study of population dynamics in hippocampal place cells has emerged as one of the most powerful tools for understanding the encoding, storage and retrieval of declarative memory. Recent work has laid out the contours of an attractor-based hippocampal population code for memory in recurrent circuits of the hippocampus. The code is based on inputs from a topographically organized, path-integration- dependent spatial map that lies upstream in the medial entorhinal cortex. The recurrent networks of the hippocampal formation enable these spatial inputs to be synthesized with nonspatial event-related information.",
	author = "Stefan Leutgeb and Jill K Leutgeb and May-Britt Moser and Edvard I Moser",
	journal = "Current Opinion in Neurobiology",
	localfile = "/home/chris/studium/masterarbeit/paper/Leutgeb (2005). Place cells, spatial maps and the population code for memory (review).pdf",
	number = "6",
	pages = "738--746",
	publisher = "Elsevier",
	title = "{Place cells, spatial maps and the population code for memory}",
	volume = "15",
	year = "2005"
}

@article{mcnamara_2003_cognitive_maps_hippocampus,
	abstract = "Following a familiar route and finding a novel route in a familiar environment depend on different cognitive pro- cesses and representations. A recent study by Hartley et al. begins to identity the neural basis of route follow- ing and wayfinding in humans. Their study also raises important questions about the functions of the hippocampus.",
	author = "Timothy P McNamara and Amy L Shelton",
	journal = "Trends in Cognitive Sciences",
	localfile = "/home/chris/studium/masterarbeit/paper/McNamara (2003). Cognitive maps and the hippocampus.pdf",
	number = "8",
	pages = "333--335",
	publisher = "Elsevier",
	title = "{Cognitive maps and the hippocampus}",
	volume = "7",
	year = "2003"
}

@article{moser_2001_new_excitement_in_cognitive_space,
	abstract = "Hippocampal principal neurons --- {\lq}place cells{\rq} -- exhibit location-specific firing. Recent work addresses the link between place cell activity and hippocampal memory function. New tasks that challenge spatial memory allow recording from single neurons, as well as ensembles of neurons, during memory computations, and insights into the cellular mechanisms of spatial memory are beginning to emerge.",
	author = "Edvard I Moser and Ole Paulsen",
	journal = "Current opinion in neurobiology",
	localfile = "/home/chris/studium/masterarbeit/paper/Moser (2001). New excitement in cognitive space: between place cells and spatial memory.pdf",
	number = "6",
	pages = "745--751",
	publisher = "Elsevier",
	title = "{New excitement in cognitive space: Between place cells and spatial memory}",
	volume = "11",
	year = "2001"
}

@article{moser_2008_place_cells_grid_cells_review,
	abstract = "More than three decades of research have demonstrated a role for hippocampal place cells in representation of the spatial environment in the brain. New studies have shown that place cells are part of a broader circuit for dynamic representation of self-location. A key component of this network is the entorhinal grid cells, which, by virtue of their tessel- lating firing fields, may provide the elements of a path integration--based neural map. Here we review how place cells and grid cells may form the basis for quantitative spatiotemporal representation of places, routes, and associated experiences during behavior and in memory. Because these cell types have some of the most conspicuous behavioral correlates among neurons in nonsensory cortical systems, and because their spatial firing structure reflects computations internally in the system, studies of entorhinal-hippocampal representations may offer considerable insight into general principles of cortical network dynamics.",
	author = "Edvard I Moser and Emilio Kropff and May-Britt Moser",
	journal = "Neuroscience",
	keywords = "hippocampus; entorhinal cortex; path integration; attractor; memory; phase precession",
	localfile = "/home/chris/studium/masterarbeit/paper/Moser (2006) Place Cells, Grid Cells, and the Brains Spatial Representation System (review).pdf",
	number = "1",
	pages = "69",
	title = "{Place cells, grid cells, and the brain's spatial representation system}",
	volume = "31",
	year = "2008"
}

@article{poucet_2003_place_cells_navigation,
	abstract = "Hippocampal place cells are characterized by location-specific firing, that is each cell fires in a restricted region of the envi- ronment explored by the rat. In this review, we briefly examine the sensory information used by place cells to anchor their firing fields in space and show that, among the various sensory cues that can influence place cell activity, visual and motion-related cues are the most relevant. We then explore the contribution of several cortical areas to the generation of the place cell signal with an emphasis on the role of the visual cortex and parietal cortex. Finally, we address the functional significance of place cell activity and demonstrate the existence of a clear relationship between place cell positional activity and spatial navigation performance. We conclude that place cells, together with head direction cells, provide information useful for spatially guided movements, and thus provide a unique model of how spatial information is encoded in the brain",
	author = "Bruno Poucet and Pierre-Pascal Lenck-Santini and Vietminh Paz-Villagrán and Etienne Save",
	journal = "Journal of Physiology-Paris",
	keywords = "Spatial memory; Navigation; Place cells; Sensory systems; Hippocampus; Parietal and retrosplenial cortex",
	localfile = "/home/chris/studium/masterarbeit/paper/Poucet (2003). Place cells, neocortex and spatial navigation. A short review.pdf",
	number = "4",
	pages = "537--546",
	publisher = "Elsevier",
	title = "{Place cells, neocortex and spatial navigation: A short review}",
	volume = "97",
	year = "2003"
}

@article{shelton_2001_systems_of_spatial_reference,
	abstract = "Seven experiments examined the spatial reference systems used in memory to represent the locations of objects in the environment. Participants learned the loca- tions of common objects in a room and then made judgments of relative direction using their memories of the layout (e.g., {\lq}{\lq}Imagine you are standing at the shoe, facing the lamp; point to the clock{\rq}{\rq}). The experiments manipulated the number of views that observers were allowed to experience, the presence or absence of local and global reference systems (e.g., a rectangular mat on which objects were placed and the walls of the room, respectively), and the congruence of local and global reference systems. Judgments of relative direction were more accurate for imagined headings parallel to study views than for imagined headings parallel to novel views, even with up to three study views. However, study views misaligned with salient reference systems in the environment were not strongly represented if they were experienced in the context of aligned views. Novel views aligned with a local refer- ence system were, under certain conditions, easier to imagine than were novel views misaligned with the local reference system. We propose that learning and remember- ing the spatial structure of the surrounding environment involves interpreting the layout in terms of a spatial reference system. This reference system is imposed on the environment but defined by egocentric experience.",
	author = "Amy L Shelton and Timothy P McNamara",
	journal = "Cognitive psychology",
	localfile = "/home/chris/studium/masterarbeit/paper/Shelton (2001). Systems of Spatial Reference in Human Memory.pdf",
	number = "4",
	pages = "274--310",
	publisher = "Elsevier",
	title = "{Systems of spatial reference in human memory}",
	volume = "43",
	year = "2001"
}

@article{sulpizio_2013_parahippocampal_retrosplenial_viewpoint_changes,
	author = "Valentina Sulpizio and Giorgia Committeri and Simon Lambrey and Alain Berthoz and Gaspare Galati",
	journal = "Behavioural brain research",
	localfile = "/home/chris/studium/masterarbeit/paper/Sulpizio (2013). Selective role of lingual, parahippocampal gyrus and retrosplenial complex in spatial memory across viewpoint changes relative to the environmental reference frame.pdf",
	pages = "62--75",
	publisher = "Elsevier",
	title = "{Selective role of lingual/parahippocampal gyrus and retrosplenial complex in spatial memory across viewpoint changes relative to the environmental reference frame}",
	volume = "242",
	x-color = "#ffff00",
	year = "2013"
}

@article{vanrie_2002_mental_rotation_vs_invariant_features_viewpoints,
	abstract = "It has been proposed that object perception can proceed through different routes, which can be situated on a continuum ranging from complete viewpoint-dependency to complete viewpoint-independency, depending on the objects and the task at hand. Although these different routes have been extensively demonstrated on the behavioral level, the corresponding distinction in the underlying neural substrate has not received the same attention. Our goal was to disentangle, on the behavioral and the neurofunctional level, a process associated with extreme viewpoint-dependency, i.e. mental rotation, and a process associated with extreme viewpoint-independency, i.e. the use of viewpoint-invariant, diagnostic features. Two sets of 3-D block figures were created that either differed in handedness (original versus mirrored) or in the angles joining the block components (orthogonal versus skewed). Behavioral measures on a same--different judgment task were predicted to be dependent on viewpoint in the rotation condition (same versus mirrored), but not in the invariance condition (same angles versus different angles). Six subjects participated in an fMRI experiment while presented with both conditions in alternating blocks. Both reaction times and accuracy confirmed the predicted dissociation between the two conditions. Neurofunctional results indicate that all cortical areas activated in the invariance condition were also activated in the rotation condition. Parietal areas were more activated than occipito-temporal areas in the rotation condition, while this pattern was reversed in the invariance condition. Furthermore, some areas were activated uniquely by the rotation condition, probably reflecting the additional processes apparent in the behavioral response patterns. © 2002 Elsevier Science Ltd. All rights reserved.",
	author = "Jan Vanrie and Erik Béatse and Johan Wagemans and Stefan Sunaert and Paul {Van Hecke}",
	journal = "Neuropsychologia",
	localfile = "/home/chris/studium/masterarbeit/paper/Vanrie (2002). Mental rotation versus invariant features in object perception from different viewpoints. An fMRI study.pdf",
	number = "7",
	pages = "917--930",
	publisher = "Elsevier",
	title = "{Mental rotation versus invariant features in object perception from different viewpoints: An fMRI study}",
	volume = "40",
	x-color = "#ffffa5",
	year = "2002"
}

@article{wang_2000_updating_egocentric_representations,
	abstract = "Seven experiments tested whether human navigation depends on enduring representations, or on momentary egocentric representations that are updated as one moves. Human subjects pointed to unseen targets, either while remaining oriented or after they had been disoriented by self-rotation. Disorientation reduced not only the absolute accuracy of pointing to all objects (`heading error') but also the relative accuracy of pointing to different objects (`con®g- uration error'). A single light providing a directional cue reduced both heading and con®g- uration errors if it was present throughout the experiment. If the light was present during learning and test but absent during the disorientation procedure, however, subjects showed low heading errors (indicating that they reoriented by the light) but high con®guration errors (indicating that they failed to retrieve an accurate cognitive map of their surroundings). These ®ndings provide evidence that object locations are represented egocentrically. Nevertheless, disorientation had little effect on the coherence of pointing to different room corners, suggest- ing both (a) that the disorientation effect on representations of object locations is not due to the experimental paradigm and (b) that room geometry is captured by an enduring representation. These findings cast doubt on the view that accurate navigation depends primarily on an enduring, observer-free cognitive map, for humans construct such a representation of extended surfaces but not of objects. Like insects, humans represent the egocentric distances and directions of objects and continuously update these representations as they move. The principal evolutionary advance in animal navigation may concern the number of unseen targets whose egocentric directions and distances can be represented and updated simulta- neously, rather than a qualitative shift in navigation toward reliance on an allocentric map.",
	author = "Ranxiao Frances Wang and Elizabeth S Spelke",
	journal = "Cognition",
	localfile = "/home/chris/studium/masterarbeit/paper/Wang (2000). Updating egocentric representations in human navigation.pdf",
	number = "3",
	pages = "215--250",
	publisher = "Elsevier",
	title = "{Updating egocentric representations in human navigation}",
	volume = "77",
	year = "2000"
}

@article{wang_2002_human_spatial_representation,
	abstract = "Human navigation is special: we use geographic maps to capture a world far beyond our unaided locomotion. In consequence, human navigation is widely thought to depend on internalized versions of these maps -- enduring, geocentric {\lq}cognitive maps{\rq} capturing diverse information about the environment. Contrary to this view, we argue that human navigation is best studied in relation to research on navigating animals as humble as ants. This research provides evidence that animals, including humans, navigate primarily by representations that are momentary rather than enduring, egocentric rather than geocentric, and limited in the environmental information that they capture. Uniquely human forms of navigation build on these representations.",
	author = "Ranxiao Frances Wang and Elizabeth S Spelke",
	journal = "Trends in cognitive sciences",
	localfile = "/home/chris/studium/masterarbeit/paper/Wang (2002). Human spatial representation. Insights from animals.pdf",
	number = "9",
	pages = "376--382",
	publisher = "Elsevier",
	title = "{Human spatial representation: Insights from animals}",
	volume = "6",
	year = "2002"
}

@article{wood_2000_hippocampal_neurons_encode,
	abstract = "Firing patterns of hippocampal complex-spike neu- rons were examined for the capacity to encode infor- mation important to the memory demands of a task even when the overt behavior and location of the ani- mal are held constant. Neuronal activity was recorded as rats continuously alternated left and right turns from the central stem of a modified T maze. Two-thirds of the cells fired differentially as the rat traversed the common stem on left-turn and right-turn trials, even when potentially confounding variations in running speed, heading, and position on the stem were taken into account. Other cells fired differentially on the two trial types in combination with behavioral and spatial factors or appeared to fire similarly on both trial types. This pattern of results suggests that hippocampal rep- resentations encode some of the information neces- sary for representing specific memory episodes.",
	author = "Emma R Wood and Paul A Dudchenko and R Jonathan Robitsek and Howard Eichenbaum",
	journal = "Neuron",
	localfile = "/home/chris/studium/masterarbeit/paper/Wood (2000). Hippocampal Neurons Encode Information about Different Types of Memory Episodes Occurring in the Same Loaction.pdf",
	number = "3",
	pages = "623--633",
	publisher = "Elsevier",
	title = "{Hippocampal neurons encode information about different types of memory episodes occurring in the same location}",
	volume = "27",
	year = "2000"
}

@article{epstein_2005_visual_scene_processing,
	abstract = "Several lines of evidence suggest that the human brain contains special-purpose machinery for processing information about visual scenes. In particular, a region in medial occipitotemporal cortexÐthe ``parahippocampal place area'', or PPAÐ represents the geometric structure of scenes as defined primarily by their back- ground elements. Neuroimaging studies have demonstrated that the PPA responds preferentially to scenes but not to the objects within them, while neuropsycholo- gical studies have shown that damage to this region leads to an impaired ability to learn new scenes. More recent evidence suggests that the PPA encodes novel scenes in a viewpoint-specific manner and that these codes are more reliable in good navigators than bad navigators. The PPA may be part of a larger network of regions involved in processing navigationally relevant spatial information. The role of this region in place recognition and gist comprehension is also discussed.",
	author = "Russell Epstein",
	journal = "Visual Cognition",
	localfile = "/home/chris/studium/masterarbeit/paper/Epstein (2005). The cortical basis of visual scene processing (review).pdf",
	number = "6",
	pages = "954--978",
	publisher = "Taylor \& Francis",
	title = "{The cortical basis of visual scene processing}",
	volume = "12",
	x-color = "#ffff00",
	year = "2005"
}

@article{lee_2012_hippocampus_visual_perception,
	author = "Andy CH Lee and Lok-Kin Yeung and Morgan D Barense",
	localfile = "/home/chris/studium/masterarbeit/paper/Lee (2012). Hippocampus and visual perception (review).pdf",
	publisher = "Frontiers in Human Neuroscience",
	title = "{The hippocampus and visual perception}",
	x-color = "#ffff00",
	year = "2012"
}

@article{smith_2006_hippocampal_place_cells_context_memory,
	author = "David M Smith and Sheri JY Mizumori",
	journal = "Hippocampus",
	localfile = "/home/chris/studium/masterarbeit/paper/Smith (2006). Hippocampal place cells, context, and episodic memory (review).pdf",
	number = "9",
	pages = "716--729",
	publisher = "Wiley Online Library",
	title = "{Hippocampal place cells, context, and episodic memory}",
	volume = "16",
	x-color = "#ffff00",
	year = "2006"
}

@article{vann_2009_what_does_retrospenical_cortex,
	author = "Seralynne D Vann and P {Aggleton John} and A {Maguire Eleanor}",
	journal = "Nature Reviews Neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Vann (2009). What does the retrosplenial cortex do (review).pdf",
	number = "11",
	pages = "792--802",
	publisher = "Nature Publishing Group",
	title = "{What does the retrosplenial cortex do?}",
	volume = "10",
	x-color = "#ffff00",
	year = "2009"
}

@article{epstein_kanwisher_1998_PPA_paper,
	abstract = "Medial temporal brain regions such as the hippocampal forma- tion and parahippocampal cortex have been generally implicated in navigation1--6 and visual memory7--9. However, the specific function of each of these regions is not yet clear. Here we present evidence that a particular area within human parahippocampal cortex is involved in a critical component of navigation: perceiv- ing the local visual environment. This region, which we name the {\lq}parahippocampal place area{\rq} (PPA), responds selectively and automatically in functional magnetic resonance imaging (fMRI) to passively viewed scenes, but only weakly to single objects and not at all to faces. The critical factor for this activation appears to be the presence in the stimulus of information about the layout of local space. The response in the PPA to scenes with spatial layout but no discrete objects (empty rooms) is as strong as the response to complex meaningful scenes containing multiple objects (the same rooms furnished) and over twice as strong as the response to arrays of multiple objects without three-dimensional spatial context (the furniture from these rooms on a blank background). This response is reduced if the surfaces in the scene are rearranged so that they no longer define a coherent space. We propose that the PPA represents places by encoding the geometry of the local environment.",
	author = "Russell Epstein and Nancy Kanwisher",
	localfile = "/home/chris/studium/masterarbeit/paper/Epstein, Kanwisher (1998). Cortical representation of the local visual environment.pdf",
	title = "{A cortical representation of the local visual environment}",
	x-color = "#ffff00",
	year = "1998"
}

@article{ekstrom_2003_cellular_network_human_navigation,
	abstract = "Place cells of the rodent hippocampus constitute one of the most striking examples of a correlation between neuronal activity and complex behaviour in mammals 1,2 . These cells increase their firing rates when the animal traverses specific regions of its surroundings, providing a context-dependent map of the environment 3--5 . Neuroimaging studies implicate the hippo- campus and the parahippocampal region in human naviga- tion 6--8 . However, these regions also respond selectively to visual stimuli 9--13 . It thus remains unclear whether rodent place coding has a homologue in humans or whether human navigation is driven by a different, visually based neural mech- anism. We directly recorded from 317 neurons in the human medial temporal and frontal lobes while subjects explored and navigated a virtual town. Here we present evidence for a neural code of human spatial navigation based on cells that respond at specific spatial locations and cells that respond to views of landmarks. The former are present primarily in the hippo- campus, and the latter in the parahippocampal region. Cells throughout the frontal and temporal lobes responded to the subjects{\rq} navigational goals and to conjunctions of place, goal and view.",
	author = "Arne D Ekstrom and Michael J Kahana and Jeremy B Caplan and Tony A Fields and Eve A Isham and Ehren L Newman and Itzhak Fried",
	journal = "Nature",
	keywords = "place cells",
	localfile = "/home/chris/studium/masterarbeit/paper/Ekstrom (2003). Cellular networks underlying human spatial navigation.pdf",
	number = "6954",
	pages = "184--188",
	publisher = "Nature Publishing Group",
	title = "{Cellular networks underlying human spatial navigation}",
	volume = "425",
	x-color = "#ffff00",
	year = "2003"
}

@article{ranganath_2012_systems_memory-guided_behaviour,
	author = "Charan Ranganath and Maureen Ritchey",
	localfile = "/home/chris/studium/masterarbeit/paper/Ranganath (2012). Two cortical systems for memory guided behavior.pdf",
	title = "{Two cortical systems for memory-guided behaviour}",
	x-color = "#ffff00",
	year = "2012"
}

@article{ocraven_2000_mental_imagery_faces_places,
	author = "Kathleen M O'Craven and Nancy Kanwisher",
	localfile = "/home/chris/studium/masterarbeit/paper/OCraven, Kaniwisher (2000). Mental imagery of faces and places.pdf",
	title = "{Mental Imagery of Faces and Places Activates Corresponding Stimulus-Specific Brain Regions}",
	year = "2000"
}

@article{bird_2012_hippocampus_contraints_imagery,
	abstract = "We review a model of imagery and memory retrieval based on allocentric spatial representation by place cells and boundary vector cells (BVCs) in the medial temporal lobe, and their translation into egocentric images in retrosplenial and parietal areas. In this model, the activity of place cells constrain the contents of imagery and retrieval to be coherent and consistent with the subject occupying a single location, while the activity of head-direction cells along Papez{\rq}s circuit determine the viewpoint direction for which the egocentric image is generated. An extension of this model is discussed in which a role for grid cells in dynamic updating of representations (mental navigation) is included. We also discuss the extension of this model to implement a version of the dual representation theory of post-traumatic stress disorder (PTSD) in which PTSD arises from an imbalance between weak allocentric hippocampal-mediated contextual representations and strong affective/sensory representations. The implications of these models for behavioral, neuropsychological, and neuroimaging data in humans are explored.",
	author = "Chris M Bird and James A Bisby and Neil Burgess",
	journal = "Frontiers in human neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Bird (2012). The hippocampus and spatial constraints on mental imagery (review).pdf",
	number = "142",
	title = "{The hippocampus and spatial constraints on mental imagery}",
	volume = "6",
	x-color = "#ffff00",
	year = "2012"
}

@article{chersi_2015_cognitive_architecture_navi,
	author = "Fabian Chersi and Neil Burgess",
	journal = "Neuron",
	localfile = "/home/chris/studium/masterarbeit/paper/Chersi (2015). The Cognitive Architecture of Spatial Navigation: Hippocampal and Striatal Contributions (review).pdf",
	number = "1",
	pages = "64--77",
	publisher = "Elsevier",
	title = "{The Cognitive Architecture of Spatial Navigation: Hippocampal and Striatal Contributions}",
	volume = "88",
	x-color = "#ffff00",
	year = "2015"
}

@article{chrastil_2013_framework_spatial_navi,
	author = "Elizabeth R Chrastil",
	journal = "Psychonomic bulletin \& review",
	localfile = "/home/chris/studium/masterarbeit/paper/Chrastil (2013). Neural evidence supports a novel framework for spatial navigation (review).pdf",
	number = "2",
	pages = "208--227",
	publisher = "Springer",
	title = "{Neural evidence supports a novel framework for spatial navigation}",
	volume = "20",
	x-color = "#ffff00",
	year = "2013"
}

@article{derdikman_2010_manifold_spatial_maps,
	author = "Dori Derdikman and Edvard I Moser",
	journal = "Trends in cognitive sciences",
	localfile = "/home/chris/studium/masterarbeit/paper/Derdikman (2010). A manifold of spatial maps in the brain (review).pdf",
	number = "12",
	pages = "561--569",
	publisher = "Elsevier",
	title = "{A manifold of spatial maps in the brain}",
	volume = "14",
	x-color = "#ffff00",
	year = "2010"
}

@article{epstein_2014_landmark-based_wayfinding,
	author = "Russell A Epstein and Lindsay K Vass",
	journal = "Philosophical Transactions of the Royal Society of London B: Biological Sciences",
	localfile = "/home/chris/studium/masterarbeit/paper/Epstein, Vass (2016). Neural systems for landmark-based wayfinding in humans (review).pdf",
	number = "1635",
	pages = "20120533",
	publisher = "The Royal Society",
	title = "{Neural systems for landmark-based wayfinding in humans}",
	volume = "369",
	x-color = "#ffff00",
	year = "2014"
}

@article{galati_2010_reference_frames_spatial_perception,
	author = "Gaspare Galati and Gina Pelle and Alain Berthoz and Giorgia Committeri",
	journal = "Experimental Brain Research",
	localfile = "/home/chris/studium/masterarbeit/paper/Galati (2010). Multiple reference frames used by the human brain (review).pdf",
	number = "2",
	pages = "109--120",
	publisher = "Springer",
	title = "{Multiple reference frames used by the human brain for spatial perception and memory}",
	volume = "206",
	x-color = "#0033ff",
	year = "2010"
}

@article{miller_2014_cues_context_memory_retrosplenial,
	abstract = "Spatial navigation requires memory representations of landmarks and other navigation cues. The retrosplenial cortex (RSC) is anatomically positioned between limbic areas important for memory formation, such as the hippocampus (HPC) and the anterior thalamus, and cortical regions along the dorsal stream known to contribute importantly to long-term spatial representation, such as the posterior parietal cortex. Damage to the RSC severely impairs allocentric representations of the environment, including the ability to derive navigational information from landmarks. The specific deficits seen in tests of human and rodent navigation suggest that the RSC supports allocentric representation by processing the stable features of the environment and the spatial relationships among them. In addition to spatial cognition, the RSC plays a key role in contextual and episodic memory. The RSC also contributes importantly to the acquisition and consolidation of long-term spatial and contextual memory through its interactions with the HPC. Within this framework, the RSC plays a dual role as part of the feedforward network providing sensory and mnemonic input to the HPC and as a target of the hippocampal-dependent systems consolidation of long-term memory.",
	author = "Adam MP Miller and Lindsey C Vedder and L Matthew Law and David M Smith",
	journal = "Front Hum Neurosci",
	localfile = "/home/chris/studium/masterarbeit/paper/Miller (2014). Cues, context, and long-term memory: the role of the retrosplenial cortex in spatial cognition (review).pdf",
	pages = "586",
	title = "{Cues, context, and long-term memory: the role of the retrosplenial cortex in spatial cognition}",
	volume = "8",
	x-color = "#ffff00",
	year = "2014"
}

@article{sewards_2011_scene_recognition_review,
	author = "Terence V Sewards",
	journal = "Neuropsychologia",
	localfile = "/home/chris/studium/masterarbeit/paper/Sewards (2011). Neural structures and mechanisms involved in scene recognition: A review and interpretation.pdf",
	number = "3",
	pages = "277--298",
	publisher = "Elsevier",
	title = "{Neural structures and mechanisms involved in scene recognition: a review and interpretation}",
	volume = "49",
	x-color = "#ffff00",
	year = "2011"
}

@article{van_2009_anatomy_of_memory,
	author = "NM {Van Strien} and NLM Cappaert and MP Witter",
	journal = "Nature Reviews Neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/van Strien (2009). The anatomy of memory: An interactive overview of the parahippocampal-hippocampal network (review).pdf",
	number = "4",
	pages = "272--282",
	publisher = "Nature Publishing Group",
	title = "{The anatomy of memory: an interactive overview of the parahippocampal--hippocampal network}",
	volume = "10",
	year = "2009"
}

@article{auger_2012_retrosplenial_contribution_landmarks,
	author = "Stephen D Auger and Sinéad L Mullally and Eleanor A Maguire",
	journal = "PLoS One",
	localfile = "/home/chris/studium/masterarbeit/paper/Auger (2012). Retrosplenial Cortex Codes for Permanent Landmarks.pdf",
	number = "8",
	pages = "e43620",
	publisher = "Public Library of Science",
	title = "{Retrosplenial cortex codes for permanent landmarks}",
	volume = "7",
	x-color = "#ffffa5",
	year = "2012"
}

@article{auger_2013_assessing_retrosplenial_navigators,
	author = "Stephen D Auger and Eleanor A Maguire",
	journal = "Cortex",
	keywords = "navigation; Retrosplenial cortex; landmarks",
	localfile = "/home/chris/studium/masterarbeit/paper/Auger (2013). Assessing the mechanism of response in the retrosplenial cortex of good and poor navigators.pdf",
	number = "10",
	pages = "2904--2913",
	publisher = "Elsevier",
	title = "{Assessing the mechanism of response in the retrosplenial cortex of good and poor navigators}",
	volume = "49",
	x-color = "#ffffa5",
	year = "2013"
}

@article{barense_2010_medial_temproal_effects_viewpoint,
	abstract = "The medial temporal lobe (MTL), a set of heavily inter- connected structures including the hippocampus and underlying entorhi- nal, perirhinal and parahippocampal cortex, is traditionally believed to be part of a unitary system dedicated to declarative memory. Recent studies, however, demonstrated perceptual impairments in amnesic indi- viduals with MTL damage, with hippocampal lesions causing scene discrimination deï¬cits, and perirhinal lesions causing object and face discrimination deï¬cits. The degree of impairment on these tasks was inï¬uenced by the need to process complex conjunctions of features: dis- criminations requiring the integration of multiple visual features caused deï¬cits, whereas discriminations that could be solved on the basis of a single feature did not. Here, we address these issues with functional neuroimaging in healthy participants as they performed a version of the oddity discrimination task used previously in patients. Three different types of stimuli (faces, scenes, novel objects) were presented from either identical or different viewpoints. Consistent with studies in patients, we observed increased perirhinal activity when participants distinguished between faces and objects presented from different, compared to identi- cal, viewpoints. The posterior hippocampus, by contrast, showed an effect of viewpoint for both faces and scenes. These ï¬ndings provide convergent evidence that the MTL is involved in processes beyond long- term declarative memory and suggest a critical role for these structures in integrating complex features of faces, objects, and scenes into view- invariant, abstract representations.",
	author = "Morgan D Barense and Richard NA Henson and Andy CH Lee and Kim S Graham",
	keywords = "Declarative memory; posterior hippocampus",
	localfile = "/home/chris/studium/masterarbeit/paper/Barense (2010). Medial temporal lobe activity during complex discrimination of faces, objects, and scenes: Effects of viewpoint.pdf",
	title = "{Medial Temporal Lobe Activity During Complex Discrimination of Faces, Objects, and Scenes: Effects of Viewpoint}",
	x-color = "#ffffa5",
	year = "2010"
}

@article{dhindsa_2014_examining_viewpoint_transformations,
	author = "Kiret Dhindsa and Vladislav Drobinin and John King and Geoffrey B Hall and Neil Burgess and Suzanna Becker",
	journal = "Front Hum Neurosci",
	localfile = "/home/chris/studium/masterarbeit/paper/Dhindsa (2014). Examining the role of the temporo-parietal network in memory, imagery, and viewpoint transformations.pdf",
	title = "{Examining the role of the temporo-parietal network in memory, imagery, and viewpoint transformations.}",
	volume = "8",
	x-color = "#ffff00",
	year = "2014"
}

@article{epstein_2005_learning_places_from_views,
	author = "Russell A Epstein and J Stephen Higgins and Sharon L Thompson-Schill",
	journal = "Cognitive Neuroscience, Journal of",
	localfile = "/home/chris/studium/masterarbeit/paper/Epstein (2005). Learning places from views.pdf",
	number = "1",
	pages = "73--83",
	publisher = "MIT Press",
	title = "{Learning places from views: variation in scene processing as a function of experience and navigational ability}",
	volume = "17",
	x-color = "#ffff00",
	year = "2005"
}

@article{epstein_2007_scene_familar_unfamiliar,
	author = "Russell A Epstein and J Stephen Higgins and Karen Jablonski and Alana M Feiler",
	journal = "Journal of Neurophysiology",
	localfile = "/home/chris/studium/masterarbeit/paper/Epstein (2007). Visual Scene Processing in Familiar and Unfamiliar Environments.pdf",
	number = "5",
	pages = "3670--3683",
	publisher = "Am Physiological Soc",
	title = "{Visual Scene Processing in Familiar and Unfamiliar Environments}",
	volume = "97",
	x-color = "#ffff00",
	year = "2007"
}

@article{hassabis_2009_decoding_ensembles_hippocampus,
	author = "Demis Hassabis and Carlton Chu and Geraint Rees and Nikolaus Weiskopf and Peter D Molyneux and Eleanor A Maguire",
	journal = "Current Biology",
	localfile = "/home/chris/studium/masterarbeit/paper/Hassabis (2009). Decoding Neuronal Ensembles in the Human Hippocampus.pdf",
	number = "7",
	pages = "546--554",
	publisher = "Elsevier",
	title = "{Decoding neuronal ensembles in the human hippocampus}",
	volume = "19",
	x-color = "#ffffa5",
	year = "2009"
}

@article{iaria_2007_retrosplenial_hippocampal_navigation,
	abstract = "The ability to orientate within familiar environments relies on the formation and use of a mental representation of the environment, namely a cognitive map. Neuropsychological and neuroimaging studies suggest that the retrosplenial and hippocampal brain regions are involved in topographical orientation. We combined functional magnetic resonance imaging with a virtual-reality paradigm to investigate the functional interaction of the hippocampus and retrosplenial cortex during the formation and utilization of cognitive maps by human subjects. We found that the anterior hippocampus is involved during the formation of the cognitive map, while the posterior hippocampus is involved when using it. In conjunction with the hippocampus, the retrosplenial cortex was active during both the formation and the use of the cognitive map. In accordance with earlier studies in non-human animals, these findings suggest that, while navigating within the environment, the retrosplenial cortex complements the hippocampal contribution to topographical orientation by updating the individual{\rq}s location as the frame of reference changes.",
	author = "Giuseppe Iaria and Jen-Kai Chen and Cecilia Guariglia and Alain Ptito and Michael Petrides",
	journal = "European Journal of Neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Iaria (2007). Retrosplenial and hippocampal brain regions in human navigation: complementary functional contributions to the formation and use of cognitive maps.pdf",
	number = "3",
	pages = "890--899",
	publisher = "Wiley Online Library",
	title = "{Retrosplenial and hippocampal brain regions in human navigation: complementary functional contributions to the formation and use of cognitive maps}",
	volume = "25",
	x-color = "#ffff00",
	year = "2007"
}

@article{knight_2014_allocentric_processing_retrosplenial_cortex,
	author = "Rebecca Knight and Robin Hayman",
	localfile = "/home/chris/studium/masterarbeit/paper/Knight (2014). Allocentric directional processing in the rodent and human retrosplenial cortex (short review).pdf",
	title = "{Allocentric directional processing in the rodent and human retrosplenial cortex}",
	x-color = "#ffffa5",
	year = "2014"
}

@article{marchette_2014_anchoring_neural_compass,
	abstract = "The neural systems that code for location and facing direction during spatial navigation have been investigated extensively; however, the mechanisms by which these quantities are referenced to external features of the world are not well understood. To address this issue, we examined behavioral priming and functional magnetic resonance imaging activity patterns while human subjects recalled spatial views from a recently learned virtual environment. Behavioral results indicated that imagined location and facing direction were represented during this task, and multivoxel pattern analyses indicated that the retrosplenial complex (RSC) was the anatomical locus of these spatial codes. Critically, in both cases, location and direction were defined on the basis of fixed elements of the local environment and generalized across geometrically similar local environments. These results suggest that RSC anchors internal spatial representations to local topographical features, thus allowing us to stay oriented while we navigate and retrieve from memory the experience of being in a particular place.",
	author = "Steven A Marchette and Lindsay K Vass and Jack Ryan and Russell A Epstein",
	journal = "Nature neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Marchette (2014). Anchoring the neural compass. Coding of local spatial reference frames in human medial parietal lobe.pdf",
	number = "11",
	pages = "1598--1606",
	publisher = "Nature Publishing Group",
	title = "{Anchoring the neural compass: coding of local spatial reference frames in human medial parietal lobe}",
	volume = "17",
	x-color = "#ffff00",
	year = "2014"
}

@article{mullally_2011_new_role_for_parahippocampal,
	abstract = "The debate surrounding the function of the human posterior parahippocampal cortex (PHC) is currently dominated by two competing theories. The spatial layout hypothesis proposes that PHC processes information about the shape of space embodied in layout-defining scene features. The contextual association hypothesis rejects this notion, proposing instead that PHC responds to highly contextualized, but not necessarily spatial, stimuli. Here we present a novel concept that suggests PHC is primarily concerned with any representation that depicts three-dimensional local space, be it scenes or even single objects. Specifically, we identified space-defining (SD) and space- ambiguous (SA) single objects, where SD objects consistently evoke a strong sense of the surrounding space while SA objects do not, in the absence of any background, spatial layout, or context. We found that participants could easily identify and distinguish between SD and SA objects. This distinction was subsequently affirmed at a neural level, where visualizing or viewing single SD objects compared with SA objects engaged PHC, despite these single SD objects offering no information about the shape or layout of the space. Moreover, this PHC response was robust and not accounted for by other factors, including contextual associations. Instead, it was linked to intrinsic object properties, specifically a combination of perceived object size and portability. By showing that PHC is responsive to the awareness of surrounding local space suggests its role in scene processing is basic and fundamental, such that it is not dependent on complex scene properties such as geometric structure, scene schema, or contextual associations.",
	author = "Sinéad L Mullally and Eleanor A Maguire",
	localfile = "/home/chris/studium/masterarbeit/paper/Mullally, Maguire (2011). A New Role for the Parahippocampal Cortex in Representing Space.pdf",
	title = "{A new role for the parahippocampal cortex in representing space}",
	x-color = "#ffff00",
	year = "2011"
}

@article{park_2011_disentangling_scene_content,
	author = "Soojin Park and Timothy F Brady and Michelle R Greene and Aude Oliva",
	keywords = "MVPA",
	localfile = "/home/chris/studium/masterarbeit/paper/Park (2011). Disentangling Scene Content from Spatial Boundary.pdf",
	title = "{Disentangling scene content from spatial boundary: complementary roles for the parahippocampal place area and lateral occipital complex in representing real-world scenes}",
	x-color = "#ffff00",
	year = "2011"
}

@article{sulpizio_2014_distributed_cognitive_maps,
	author = "Valentina Sulpizio and Giorgia Committeri and Gaspare Galati",
	journal = "Frontiers in human neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Sulpizio (2014). Distributed cognitive maps reflecting real distances between places and views in the human brain.pdf",
	publisher = "Frontiers Media SA",
	title = "{Distributed cognitive maps reflecting real distances between places and views in the human brain}",
	volume = "8",
	x-color = "#ffff00",
	year = "2014"
}

@article{van_assche_2016_scene_integration_viewpoint_changes,
	abstract = "The posterior parietal cortex (PPC) is an anatomically heterogeneous brain region implicated in a wide range of cognitive operations, in- cluding egocentric spatial processing and both short- and long-term memory. Here, we report functional speciï¬cities of cytoarchitectoni- cally deï¬ned subregions of PPC during the processing of scenes across changes in viewpoint. Participants (n = 16) saw photographs of familiar and unfamiliar places while undergoing functional mag- netic resonance imaging (fMRI). On each trial, 4 viewpoints of the same place were presented, with either a plausible sequence of viewpoints (SEQ) or a scrambled order (SCRA). Distinct response proï¬les were observed within PPC. Area 7A showed increased activity for SEQ versus SCRA order, regardless of place familiarity, whereas the rostral inferior parietal lobule showed preferential in- creases for unfamiliar versus familiar places in SEQ series. In con- trast, more posterior subregions in both superior and inferior PPC exhibited increases for familiar versus unfamiliar places at the end of the sequence, regardless of order. The data highlight the distinct- ive contribution of several subregions of PPC during the processing of scenes, with speciï¬c cortical areas involved in the progressive integration of spatial information across viewpoint changes, and others involved in the retrieval and maintenance of scene informa- tion in memory.",
	author = "Mitsouko {Van Assche} and Valeria Kebets and Patrik Vuilleumier and Frédéric Assal",
	localfile = "/home/chris/studium/masterarbeit/paper/van Assche (2016). Functional Dissociations Within Posterior Parietal Cortex During Scene Integration and Viewpoint Changes.pdf",
	title = "{Functional Dissociations Within Posterior Parietal Cortex During Scene Integration and Viewpoint Changes}",
	x-color = "#ffff00",
	year = "2016"
}

@article{vass_2013_representation_location_facing_direction,
	author = "Lindsay K Vass and Russell A Epstein",
	keywords = "MVPA",
	localfile = "/home/chris/studium/masterarbeit/paper/Vass, Epstein (2013). Abstract Representations of Location and Facing Direction in the Human Brain.pdf",
	title = "{Abstract representations of location and facing direction in the human brain}",
	x-color = "#ffff00",
	year = "2013"
}

@article{epstein_2012_visual_scenes_mvpa_inconsistencies,
	author = "Russell A Epstein and Lindsay K Morgan",
	localfile = "/home/chris/studium/masterarbeit/paper/Epstein (2012). Neural responses to visual scenes reveals inconsistencies between fMRI adaptation and multivoxel pattern analysis.pdf",
	title = "{Neural responses to visual scenes reveals inconsistencies between fMRI adaptation and multivoxel pattern analysis}",
	x-color = "#ffff00",
	year = "2012"
}

@article{labs_2015_portrayed_emos_in_Forrest,
	author = "Annika Labs and Theresa Reich and Helene Schulenburg and Manuel Boennen and Gehrke Mareike and Madleen Golz and Benita Hartigs and Nico Hoffmann and Sebastian Keil and Malú Perlow and others",
	journal = "F1000Research",
	localfile = "/home/chris/studium/masterarbeit/paper/Labs, Hanke (2015). Portrayed emotions in the movie Forrest Gump.pdf",
	number = "92",
	title = {{Portrayed emotions in the movie" Forrest Gump" [version 1; referees: 2 approved]}},
	volume = "4",
	year = "2015"
}

@article{gomez_2014_differential_hippocampal_retrosplenial,
	author = "Alice Gomez and Mélanie Cerles and Stéphane Rousset and Chantal Rémy and Monica Baciu",
	journal = "Frontiers in human neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Gomez (2014). Differential hippocampal and retrosplenial involvement in egocentric-updating, rotation, and allocentric processing during online spatial encoding: an fMRI study.pdf",
	pages = "150--150",
	publisher = "Frontiers Media SA",
	title = "{Differential hippocampal and retrosplenial involvement in egocentric-updating, rotation, and allocentric processing during online spatial encoding: an fMRI study.}",
	volume = "8",
	x-color = "#ffff00",
	year = "2013"
}

@article{nichols_2016_best_practices_mri,
	author = "Thomas E Nichols and Samir Das and Simon B Eickhoff and Alan C Evans and Tristan Glatard and Michael Hanke and Nikolaus Kriegeskorte and Michae P Milham and Russell A Poldrack and Jean-Baptiste Poline and others",
	journal = "bioRxiv",
	localfile = "/home/chris/studium/masterarbeit/paper/Nichols, Hanke (2016). Best practices in datan analysis and sharing in neuroimaging using MRI.pdf",
	pages = "054262",
	publisher = "Cold Spring Harbor Labs Journals",
	title = "{Best Practices in Data Analysis and Sharing in Neuroimaging using MRI}",
	year = "2016"
}

@article{hanke_2015_musical_genres,
	author = "Michael Hanke and Richard Dinga and Christian Häusler and J Swaroop Guntupalli and Michael Casey and Falko R Kaule and Jörg Stadler",
	localfile = "/home/chris/studium/masterarbeit/paper/Hanke (2015). High-resolution 7-Tesla fMRI data on the perception of musical genres.pdf",
	title = "{High-resolution 7-Tesla fMRI data on the perception of musical genres--an extension to the studyforrest dataset}",
	year = "2015"
}

@article{hanke_2016_simultaneous_fMRI_eye_gaze,
	abstract = "Here we present an update of the studyforrest (http://studyforrest.org) dataset that complements the previously released functional magnetic resonance imaging (fMRI) data for natural language processing with a new two-hour 3 Tesla fMRI acquisition while 15 of the original participants were shown an audio-visual version of the stimulus motion picture. We demonstrate with two validation analyses that these new data support mod- eling specific properties of the complex natural stimulus, as well as a substantial within- subject BOLD response congruency in brain areas related to the processing of auditory inputs, speech, and narrative when compared to the existing fMRI data for audio-only stimulation. In addition, we provide participants{\rq} eye gaze location as recorded simul- taneously with fMRI, and an additional sample of 15 control participants whose eye gaze trajectories for the entire movie were recorded in a lab setting --- to enable studies on attentional processes and comparative investigations on the potential impact of the stimulation setting on these processes.",
	author = "Michael Hanke and Nico Adelhöfer and Daniel Kottke and Vittorio Iacovella and Ayan Sengupta and Falko R Kaule and Roland Nigbur and Alexander Q Waite and Florian J Baumgartner and Jörg Stadler",
	journal = "bioRxiv",
	localfile = "/home/chris/studium/masterarbeit/paper/Hanke (2016). Simultaneous fMRI and eye gaze recordings during prolonged natural stimulation.pdf",
	pages = "046581",
	publisher = "Cold Spring Harbor Labs Journals",
	title = "{Simultaneous fMRI and eye gaze recordings during prolonged natural stimulation --- a studyforrest extension}",
	year = "2016"
}

@article{sengupta_hanke_2016_studyforrest_vision_research,
	author = "Ayan Sengupta and Falko R Kaule and J Swaroop Guntupalli and Michael B Hoffmann and Christian Häusler and Jörg Stadler and Michael Hanke",
	localfile = "/home/chris/studium/masterarbeit/paper/Sengupta, Hanke (2016). An extension of the studyforrest dataset for vision research.pdf",
	title = "{An extension of the studyforrest dataset for vision research}",
	year = "2016"
}

@article{holzschneider_wolbers_2012_cardiovascular_fitness,
	author = "Kathrin Holzschneider and Thomas Wolbers and Brigitte Röder and Kirsten Hötting",
	journal = "Neuroimage",
	localfile = "/home/chris/studium/masterarbeit/paper/Holzschneider, Wolbers (2012). Cardiovascular fitness modulates brain activation associated with spatial learning.pdf",
	number = "3",
	pages = "3003--3014",
	publisher = "Elsevier",
	title = "{Cardiovascular fitness modulates brain activation associated with spatial learning}",
	volume = "59",
	year = "2012"
}

@article{sommer_wolbers_2005_medial_temp_lobe_obj_loc,
	author = "Tobias Sommer and Michael Rose and Jan Gläscher and Thomas Wolbers and Christian Büchel",
	journal = "Learning \& Memory",
	localfile = "/home/chris/studium/masterarbeit/paper/Sommer, Wolbers (2005). Dissociable contributions within the medial temporal lobe to encoding of object-location associations.pdf",
	number = "3",
	pages = "343--351",
	publisher = "Cold Spring Harbor Lab",
	title = "{Dissociable contributions within the medial temporal lobe to encoding of object-location associations}",
	volume = "12",
	x-color = "#ffff00",
	year = "2005"
}

@article{wiener_2013_maladaptive_bias_extrahippocampal,
	author = "Jan M Wiener and Olivier de Condappa and Mathew A Harris and Thomas Wolbers",
	journal = "The Journal of Neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Wiener, Wolbers (2013). Maladaptive Bias for Extrahippocampal Navigation Strategies in Aging Humans.pdf",
	number = "14",
	pages = "6012--6017",
	publisher = "Soc Neuroscience",
	title = "{Maladaptive bias for extrahippocampal navigation strategies in aging humans}",
	volume = "33",
	year = "2013"
}

@article{wolbers_2004_emerging_route_knowledge,
	abstract = "Behavioral evidence suggests that spatial knowledge derived from ground-level navigation can consist of both route and survey knowledge. Neuroimaging and lesion studies aiming to identify the neural structures responsible for topographical learning in humans have yielded partially inconsistent results, probably due to the lack of an effective behavioral parameter allowing for a reliable distinction between different representations. Therefore, we employed a novel virtual reality environment that provides accuracy and reaction time measures precisely indicating the emergence of route vs. survey knowledge. Functional magnetic resonance imaging (fMRI) was used to localize brain regions involved in the acquisition of pure route knowledge in the form of associations between consecutive landmark views and the direction of intermediate movements. Participants were scanned during repeated encoding of the complex environment from a first-person, ground-level perspective. Behavioral data revealed emerging route knowledge in 11 out of 14 subjects. Overall comparisons between encoding and control conditions identified activation in medial frontal gyrus, retrosplenial cortex and posterior inferior parietal cortex. Most importantly, only posterior inferior parietal regions showed increasing activation across sessions, thus paralleling behavioral measures of route expertise. Given the established role of the posterior parietal cortex in spatial processing, this area is thought to provide the pivotal spatial link between two landmarks encountered in immediate temporal succession.",
	author = "Thomas Wolbers and Cornelius Weiller and Christian Büchel",
	journal = "Cognitive Brain Research",
	localfile = "/home/chris/studium/masterarbeit/paper/Wolbers (2004). Neural foundations of emerging route knowledge in complex spatial environments.pdf",
	number = "3",
	pages = "401--411",
	publisher = "Elsevier",
	title = "{Neural foundations of emerging route knowledge in complex spatial environments}",
	volume = "21",
	x-color = "#ffff00",
	year = "2004"
}

@article{wolbers_2005_retrosplenial_hippocampal_contributions,
	abstract = "During everyday navigation, humans encounter complex environments predominantly from a first-person perspective. Behavioral evidence suggests that these perceptual experiences can be used not only to acquire route knowledge but also to directly assemble map-like survey representations. Most studies of human navigation focus on the retrieval of previously learned environments, and the neural foundations of integrating sequential views into a coherent representation are not yet fully understood. We therefore used our recently introduced virtual-reality paradigm, which provides accuracy and reaction-time measurements precisely indicating the emer- gence of survey knowledge, and functional magnetic resonance imaging while participants repeatedly encoded a complex environment from a first-person ground-level perspective. Before the experiment, we gave specific instructions to induce survey learning, which, based on the clear evidence for emerging survey knowledge in the behavioral data from 11 participants, proved successful. Neuroimaging data revealed increasing activation across sessions only in bilateral retrosplenial cortices, thus paralleling behavioral measures of map expertise. In contrast, hippocampal activation did not follow absolute performance but rather reflected the amount of knowledge acquired in a given session. In other words, hippocampal activation was most prominent during the initial learning phase and decayed after performance had approached ceiling level. We therefore conclude that, during navigational learning, retrosplenial areas mainly serve to integrate egocentric spatial information with cues about self-motion, whereas the hippocampus is needed to incorporate new information into an emerging memory representation.",
	author = "Thomas Wolbers and Christian Büchel",
	journal = "The Journal of Neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Wolbers (2005). Dissociable Retrosplenial and Hippocampal Contributions to Successful Formation of Survey Representations.pdf",
	number = "13",
	pages = "3333--3340",
	publisher = "Soc Neuroscience",
	title = "{Dissociable retrosplenial and hippocampal contributions to successful formation of survey representations}",
	volume = "25",
	x-color = "#ffff00",
	year = "2005"
}

@article{wolbers_2007_differential_recruitment_path_integration,
	abstract = "Path integration, the ability to sense self-motion for keeping track of changes in orientation and position, constitutes a fundamental mechanism of spatial navigation and a keystone for the development of cognitive maps. Whereas animal path integration is predomi- nantly supported by the head-direction, grid, and place cell systems, the neural foundations are not well understood in humans. Here we used functional magnetic resonance imaging and a virtual rendition of a triangle completion paradigm to test whether human path integration recruits a cortical system similar to that of rodents and nonhuman primates. Participants traveled along two legs of a triangle before pointing toward the starting location. In accordance with animal models, stronger right hippocampal activation predicted more accurate updating of the starting location on a trial-by-trial basis. Moreover, between-subjects fluctuations in response consistency were negatively correlated with bilateral hippocampal and medial prefrontal activation, and bilateral recruitment of the human motion complex (hMTâ«¹) covaried with individual path integration capability. Given that these effects were absent in a perceptual control task, the present study provides the first evidence that visual path integration is related to the dynamic interplay of self-motion processing in hMTâ«¹, higher-level spatial processes in the hippocampus, and spatial working memory in medial prefrontal cortex.",
	author = "Thomas Wolbers and Jan M Wiener and Hanspeter A Mallot and Christian Büchel",
	journal = "The Journal of Neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Wolbers (2007). Differential Recruitment of the Hippocampus, Medial Prefrontal Cortex, and the Human Motion Complex during Path Integration in Humans.pdf",
	number = "35",
	pages = "9408--9416",
	publisher = "Soc Neuroscience",
	title = "{Differential recruitment of the hippocampus, medial prefrontal cortex, and the human motion complex during path integration in humans}",
	volume = "27",
	x-color = "#ffff00",
	year = "2007"
}

@article{wolbers_2008_spatial_updating_keep_track,
	abstract = "As you move through an environment, the positions of surrounding objects relative to your body constantly change. Updating these locations is a central feature of situational awareness and readiness to act. Here, we used functional magnetic resonance imaging and a virtual environment to test how the human brain uses optic flow to monitor changing object coordinates. Only activation profiles in the precuneus and the dorsal premotor cortex (PMd) were indicative of an updating process operating on a memorized egocentric map of space. A subsequent eye movement study argued against the alternative explanation that activation in PMd could be driven by oculomotor signals. Finally, introducing a verbal response mode revealed a dissociation between the two regions, with the PMd only showing updating-related responses when participants responded by pointing. We conclude that visual spatial updating relies on the construction of updated representations in the precuneus and the context-dependent planning of motor actions in PMd.",
	author = "Thomas Wolbers and Mary Hegarty and Christian Büchel and Jack M Loomis",
	journal = "Nature neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Wolbers (2008). Spatial updating. How the brain keeps track of changing object locations during observer motion.pdf",
	number = "10",
	pages = "1223--1230",
	publisher = "Nature Publishing Group",
	title = "{Spatial updating: How the brain keeps track of changing object locations during observer motion}",
	volume = "11",
	x-color = "#ffffa5",
	year = "2008"
}

@article{wolbers_2010_determines_spatial_abilities,
	abstract = "The ability to find one{\rq}s way in our complex environ- ments represents one of the most fundamental cognitive functions. Although involving basic perceptual and memory related processes, spatial navigation is particu- larly complex because it is a multisensory process in which information needs to be integrated and manipu- lated over time and space. Not surprisingly, humans differ widely in this ability, and recent animal and human work has begun to unveil the underlying mechanisms. Here, we consider three interdependent domains that have been related to navigational abilities: cognitive and perceptual factors, neural information processing and variability in brain microstructure. Together, the findings converge into an emerging model of how different fac- tors interact to produce individual patterns of naviga- tional performance.",
	author = "Thomas Wolbers and Mary Hegarty",
	localfile = "/home/chris/studium/masterarbeit/paper/Wolbers (2010). What determines our navigational abilities (review).pdf",
	title = "{What determines our navigational abilities?}",
	x-color = "#ffff00",
	year = "2010"
}

@article{wolbers_2011_modality-independent_coding,
	abstract = "In many nonhuman species, neural computations of naviga- tional information such as position and orientation are not tied to a specific sensory modality [1, 2]. Rather, spatial signals are integrated from multiple input sources, likely leading to abstract representations of space. In contrast, the potential for abstract spatial representations in humans is not known, because most neuroscientific experiments on human navigation have focused exclusively on visual cues. Here, we tested the modality independence hypothesis with two functional magnetic resonance imaging (fMRI) experi- ments that characterized computations in regions impli- cated in processing spatial layout [3]. According to the hypothesis, such regions should be recruited for spatial computation of 3D geometric configuration, independent of a specific sensory modality. In support of this view, sighted participants showed strong activation of the para- hippocampal place area (PPA) and the retrosplenial cortex (RSC) for visual and haptic exploration of information- matched scenes but not objects. Functional connectivity analyses suggested that these effects were not related to visual recoding, which was further supported by a similar preference for haptic scenes found with blind participants. Taken together, these findings establish the PPA/RSC network as critical in modality-independent spatial computa- tions and provide important evidence for a theory of high- level abstract spatial information processing in the human brain.",
	author = "Thomas Wolbers and Roberta L Klatzky and Jack M Loomis and Magdalena G Wutte and Nicholas A Giudice",
	journal = "Current Biology",
	localfile = "/home/chris/studium/masterarbeit/paper/Wolbers (2011). Modality-Independent Coding of Spatial Layout in the Human Brain.pdf",
	number = "11",
	pages = "984--989",
	publisher = "Elsevier",
	title = "{Modality-independent coding of spatial layout in the human brain}",
	volume = "21",
	x-color = "#ffffa5",
	year = "2011"
}

@article{wolbers_2014_challenges_for_indetifying,
	abstract = "Spatial navigation is a fascinating behavior that is essential for our everyday lives. It involves nearly all sensory systems, it requires numerous parallel computations, and it engages multiple memory systems. One of the key problems in this field pertains to the question of reference frames: spatial information such as direction or distance can be coded egocentrically---relative to an observer---or allocentrically---in a reference frame independent of the observer. While many studies have associated striatal and parietal circuits with egocentric coding and entorhinal/hippocampal circuits with allocentric coding, this strict dissociation is not in line with a growing body of experimental data. In this review, we discuss some of the problems that can arise when studying the neural mechanisms that are presumed to support different spatial reference frames. We argue that the scale of space in which a navigation task takes place plays a crucial role in determining the processes that are being recruited. This has important implications, particularly for the inferences that can be made from animal studies in small scale space about the neural mechanisms supporting human spatial navigation in large (environmental) spaces. Furthermore, we argue that many of the commonly used tasks to study spatial navigation and the underlying neuronal mechanisms involve different types of reference frames, which can complicate the interpretation of neurophysiological data.",
	author = "Thomas Wolbers and Jan M Wiener",
	localfile = "/home/chris/studium/masterarbeit/paper/Wolbers (2014). Challenges for identifying the neural mechanisms that support spatial navigation (review).pdf",
	title = "{Challenges for identifying the neural mechanisms that support spatial navigation: The impact of spatial scale}",
	x-color = "#ffff00",
	year = "2014"
}

@article{smith_2002_fast_BET,
	author = "Stephen M Smith",
	journal = "Human Brain Mapping",
	localfile = "/home/chris/studium/masterarbeit/paper/Smith (2002). Fast Robust Automated Brain Extraction.pdf",
	number = "3",
	pages = "143--155",
	publisher = "Wiley Online Library",
	title = "{Fast robust automated brain extraction}",
	volume = "17",
	year = "2002"
}

@article{woolrich_2001_temporal_autocorr,
	author = "Mark W Woolrich and Brian D Ripley and Michael Brady and Stephen M Smith",
	journal = "NeuroImage",
	localfile = "/home/chris/studium/masterarbeit/paper/Woolrich (2001). Temporal Autocorrelation in Univariate Linear Modeling of FMRI Data.pdf",
	number = "6",
	pages = "1370--1386",
	title = "{Temporal Autocorrelation in Univariate Linear Modeling of FMRI Data}",
	volume = "14",
	year = "2001"
}

@article{beckmann_2003_multi-level_modelling,
	author = "Christian F Beckmann and Mark Jenkinson and Stephen M Smith",
	journal = "NeuroImage",
	localfile = "/home/chris/studium/masterarbeit/paper/Beckmann (2003). General multilevel linear modeling for group analysis in FMRI.pdf",
	number = "2",
	pages = "1052--1063",
	publisher = "Elsevier",
	title = "{General multi-level linear modelling for group analysis in FMRI}",
	volume = "20",
	year = "2003"
}

@article{woolrich_2004_multi-level_modelling_bayesian,
	author = "Mark W Woolrich and Timothy EJ Behrens and Christian F Beckmann and Mark Jenkinson and Stephen M Smith",
	journal = "NeuroImage",
	localfile = "/home/chris/studium/masterarbeit/paper/Woolrich (2004). Multilevel linear modelling for FMRI group analysis using Bayesian inference.pdf",
	number = "4",
	pages = "1732--1747",
	publisher = "Elsevier",
	title = "{Multilevel linear modelling for FMRI group analysis using Bayesian inference}",
	volume = "21",
	year = "2004"
}

@article{woolrich_2008_robust_group_analysis,
	author = "Mark Woolrich",
	journal = "NeuroImage",
	number = "2",
	pages = "286--301",
	publisher = "Elsevier",
	title = "{Robust group analysis using outlier inference}",
	volume = "41",
	year = "2008"
}

@incollection{worsley_2001_statistical_activation_images,
	author = "KJ Worsley",
	chapter = "14",
	editor = "P. Jezzard and P.M. Matthews and S.M. Smith",
	journal = "Functional MRI: An Introduction to Methods",
	localfile = "/home/chris/studium/masterarbeit/paper/Worsley (2001). Statistical Analysis of Activation.pdf",
	pages = "251--270",
	publisher = "Citeseer",
	title = "{Statistical analysis of activation images}",
	year = "2001"
}

@article{poldrack_2008_fMRI_guidelines,
	author = "Russell A Poldrack and Paul C Fletcher and Richard N Henson and Keith J Worsley and Matthew Brett and Thomas E Nichols",
	journal = "NeuroImage",
	localfile = "/home/chris/studium/masterarbeit/paper/Poldrack (2008). Guidelines for reporting an fmri study.pdf",
	number = "2",
	pages = "409--414",
	publisher = "Elsevier",
	title = "{Guidelines for reporting an fMRI study}",
	volume = "40",
	year = "2008"
}

@article{hasson_2012_future_trends_neuroimaging,
	author = "Uri Hasson and Christopher J Honey",
	journal = "NeuroImage",
	localfile = "/home/chris/studium/masterarbeit/paper/Hasson (2012). Future trends in neuroimaging: Neural processes as expressed within real-life contexts.pdf",
	number = "2",
	pages = "1272--1278",
	publisher = "Elsevier",
	title = "{Future trends in Neuroimaging: Neural processes as expressed within real-life contexts}",
	volume = "62",
	year = "2012"
}

@article{smith_2004_FSL,
	author = "Stephen M Smith and Mark Jenkinson and Mark W Woolrich and Christian F Beckmann and Timothy EJ Behrens and Heidi Johansen-Berg and Peter R Bannister and Marilena {De Luca} and Ivana Drobnjak and David E Flitney and others",
	journal = "NeuroImage",
	pages = "208--219",
	publisher = "Elsevier",
	title = "{Advances in functional and structural MR image analysis and implementation as FSL}",
	volume = "23",
	year = "2004"
}

@article{bartels_2008_natural_vision_regional_spec,
	author = "Andreas Bartels and Semir Zeki and Nikos K Logothetis",
	localfile = "/home/chris/studium/masterarbeit/paper/Bartels (2008). Natural Vision Reveals Regional Specializazion to Local Motion and to Contrast-Invariant, Global Flow in the Human Brain.pdf",
	note = {stimulus: "Tomorrow Never Dies" (James Bond Movie)},
	title = "{Natural vision reveals regional specialization to local motion and to contrast-invariant, global flow in the human brain}",
	x-color = "#ffff00",
	year = "2008"
}

@inproceedings{kauttonen_2014_model_narrative_nowness,
	author = "Janne Kauttonen and Mauri Kaipainen and Pia Tikka",
	booktitle = "{5th Workshop on Computational Models of Narrative, Quebec City, Canada, July 31-August 2, 2014.}",
	localfile = "/home/chris/studium/masterarbeit/paper/Kauttonen (2014). Model of Narrative Nowness for Neurocinematic Experiments.pdf",
	organization = "Dagstuhl Publishing",
	pages = "77--87",
	title = "{Model of narrative nowness for neurocinematic experiments}",
	volume = "41",
	year = "2014"
}

@article{taube_2013_navigation_in_VR,
	author = "J. S. Taube and S. Valerio and R. M Yoder",
	journal = "Journal of cognitive neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Taube (2013). Is Navigation in Virtual Reality with fMRI really Navigation.pdf",
	number = "7",
	pages = "1008--1019",
	publisher = "MIT Press",
	title = "{Is navigation in virtual reality with FMRI really navigation?}",
	volume = "25",
	year = "2013"
}

@article{grill_2001_lateral_occipital_object_recognition,
	author = "Kalanit Grill-Spector and Zoe Kourtzi and Nancy Kanwisher",
	journal = "Vision research",
	keywords = "review",
	localfile = "/home/chris/studium/masterarbeit/paper/Grill-Spector (2001). The lateral occipital complex and its role in object recognition.pdf",
	number = "10",
	pages = "1409--1422",
	publisher = "Elsevier",
	title = "{The lateral occipital complex and its role in object recognition}",
	volume = "41",
	x-color = "#ffffa5",
	year = "2001"
}

@article{ylipaavalniemi_2009_brain_correlates_natural_stim,
	author = "Jarkko Ylipaavalniemi and Eerika Savia and Sanna Malinen and Riitta Hari and Ricardo Vigário and Samuel Kaski",
	journal = "NeuroImage",
	localfile = "/home/chris/studium/masterarbeit/paper/Ylipaavalniemi (2009). Dependencies between stimuli and spatially independent fMRI sources.pdf",
	number = "1",
	pages = "176--185",
	publisher = "Elsevier",
	title = "{Dependencies between stimuli and spatially independent fMRI sources: Towards brain correlates of natural stimuli}",
	volume = "48",
	x-color = "#ffffa5",
	year = "2009"
}

@article{tikka_2014_modeling_radical_embodiment,
	author = "Pia Tikka and Mauri Ylermi Kaipainen",
	journal = "Frontiers in human neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Tikka (2014). From naturalistic neuroscience to modeling radical embodiment with narrative enactive systems.pdf",
	publisher = "Frontiers Media SA",
	title = "{From naturalistic neuroscience to modeling radical embodiment with narrative enactive systems}",
	volume = "8",
	x-color = "#ffffa5",
	year = "2014"
}

@book{mercado_2011_filmmakers_eye,
	author = "Gustavo Mercado",
	edition = "1",
	isbn = "9780240812175",
	keywords = "cinematography",
	localfile = "/home/chris/studium/masterarbeit/cinematography /Mercado - The Filmmakers Eye.pdf",
	month = "9",
	publisher = "Focal Press",
	title = "{The Filmmaker's Eye: Learning (and Breaking) the Rules of Cinematic Composition}",
	url = "http://amazon.com/o/ASIN/0240812174",
	year = "2011"
}

@book{rabiger_2008_directing,
	author = "Michael Rabiger",
	edition = "4",
	isbn = "9780240808826",
	localfile = "/home/chris/studium/masterarbeit/cinematography /Rabiger - Directing (4th Ed., 2007).pdf",
	month = "8",
	publisher = "Focal Press",
	title = "{Directing. Film Techniques and Aesthetics}",
	url = "http://amazon.com/o/ASIN/0240808827",
	year = "2008"
}

@book{murch_2001_blink_of_an_eye,
	author = "Walter Murch",
	edition = "2nd",
	isbn = "9781879505629",
	keywords = "cinematography",
	month = "8",
	publisher = "Silman-James Press",
	title = "{In the Blink of an Eye: A Perspective on Film Editing, 2nd Edition}",
	year = "2001"
}

@article{doeller_2010_human_grid_cells,
	author = "Christian F Doeller and Caswell Barry and Neil Burgess",
	journal = "Nature",
	localfile = "/home/chris/studium/masterarbeit/paper/Doeller, Burgess (2010). Evidence for grid cells in a human memory network.pdf",
	number = "7281",
	pages = "657--661",
	publisher = "Nature Publishing Group",
	title = "{Evidence for grid cells in a human memory network}",
	volume = "463",
	year = "2010"
}

@article{krupic_2015_grid_cell_env_geometry,
	author = "Julija Krupic and Marius Bauza and Stephen Burton and Caswell Barry and John O{\rq}Keefe",
	journal = "Nature",
	localfile = "/home/chris/studium/masterarbeit/paper/Grupic (2015). Grid cell symmetry is shaped by environmental geometry.pdf",
	number = "7538",
	pages = "232--235",
	publisher = "Nature Publishing Group",
	title = "{Grid cell symmetry is shaped by environmental geometry}",
	volume = "518",
	year = "2015"
}

@article{horner_2016_grid-like_imagined_navi,
	author = "Aidan J Horner and James A Bisby and Ewa Zotow and Daniel Bush and Neil Burgess",
	journal = "Current Biology",
	localfile = "/home/chris/studium/masterarbeit/paper/Horner (2016). Grid-like Processing of Imagined Navigation.pdf",
	number = "6",
	pages = "842--847",
	publisher = "Elsevier",
	title = "{Grid-like processing of imagined navigation}",
	volume = "26",
	year = "2016"
}

@article{jacobs_2013_direct_recording_grid-like,
	author = "Joshua Jacobs and Christoph T Weidemann and Jonathan F Miller and Alec Solway and John F Burke and Xue-Xin Wei and Nanthia Suthana and Michael R Sperling and Ashwini D Sharan and Itzhak Fried and others",
	journal = "Nature neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Jacobs (2013). Direct recordings of grid-like neuronal activity in human spatial navigation.pdf",
	number = "9",
	pages = "1188--1190",
	publisher = "Nature Publishing Group",
	title = "{Direct recordings of grid-like neuronal activity in human spatial navigation}",
	volume = "16",
	year = "2013"
}

@book{Dancyger_2011_technique_of_film,
	author = "Ken Dancyger",
	edition = "5th",
	isbn = "9780240813974",
	month = "11",
	publisher = "Focal Press",
	title = "{The Technique of Film and Video Editing: History, Theory, and Practice.}",
	year = "2011"
}

@article{smith_2006_attentional_theory_continuity_editing,
	author = "Tim J Smith",
	localfile = "/home/chris/studium/masterarbeit/paper/Smith (2005). An Attentional Theory of Continuity Editing.pdf",
	publisher = "University of Edinburgh. College of Science and Engineering. School of Informatics.",
	title = "{An attentional theory of continuity editing}",
	year = "2006"
}

@article{hafting_2005_microstructure_maps_enthorinal_c,
	abstract = "The ability to find one{\rq}s way depends on neural algorithms that integrate information about place, distance and direction, but the implementation of these operations in cortical microcircuits is poorly understood. Here we show that the dorsocaudal medial entorhinal cortex (dMEC) contains a directionally oriented, topographically organized neural map of the spatial environment. Its key unit is the {\lq}grid cell{\rq}, which is activated whenever the animal{\rq}s position coincides with any vertex of a regular grid of equilateral triangles spanning the surface of the environment. Grids of neighbouring cells share a common orientation and spacing, but their vertex locations (their phases) differ. The spacing and size of individual fields increase from dorsal to ventral dMEC. The map is anchored to external landmarks, but persists in their absence, suggesting that grid cells may be part of a generalized, path-integration-based map of the spatial environment.",
	author = "Torkel Hafting and Marianne Fyhn and Sturla Molden and May-Britt Moser and Edvard I Moser",
	journal = "Nature",
	keywords = "grid cells",
	localfile = "/home/chris/studium/masterarbeit/paper/Hafting (2005). Microstructure of a spatial map in the entorhinal cortex.pdf",
	number = "7052",
	pages = "801--806",
	publisher = "Nature Publishing Group",
	title = "{Microstructure of a spatial map in the entorhinal cortex}",
	volume = "436",
	year = "2005"
}

@article{cutting_2011_quicker_faster_darker,
	author = "James E Cutting and Kaitlin L Brunick and Jordan E DeLong and Catalina Iricinschi and Ayse Candan",
	journal = "i-Perception",
	localfile = "/home/chris/studium/masterarbeit/paper/Cutting (2011). Quicker, faster, darker: Changes in Hollywood film over 75 years.pdf",
	number = "6",
	pages = "569--576",
	publisher = "SAGE Publications",
	title = "{Quicker, faster, darker: Changes in Hollywood film over 75 years}",
	volume = "2",
	year = "2011"
}

@article{cutting_2011_changing_poetics_of_dissolve,
	author = "James E Cutting and Kaitlin L Brunick and Jordan E DeLong",
	journal = "Empirical Studies of the Arts",
	localfile = "/home/chris/studium/masterarbeit/paper/Cutting (2011). The Changing Poetics of the Dissolve in Hollywood Film.pdf",
	number = "2",
	pages = "149--169",
	title = "{The changing poetics of the dissolve in Hollywood film}",
	volume = "29",
	year = "2011"
}

@book{reisz_millar_2009_film_editing,
	author = "Karel Reisz and Gavin Millar",
	edition = "2",
	isbn = "9780240521855",
	localfile = "/home/chris/studium/masterarbeit/cinematography /Reisz & Millar - The Technique of Film Editing (2009).pdf",
	month = "9",
	publisher = "Focal Press",
	title = "{Technique of Film Editing.}",
	year = "2009"
}

@book{wadsworth_2016_editors_toolkit,
	author = "Chris Wadsworth",
	localfile = "/home/chris/studium/masterarbeit/cinematography /Wadsworth - The Editors Toolkit.pdf",
	publisher = "Focal Press",
	title = "{The Editor's Toolkit: A Hands-On Guide to the Craft of Film and TV Editing.}",
	year = "2016"
}

@article{kanwisher_2000_cognitive,
	author = "Nancy Kanwisher and Morris Moscovitch",
	journal = "Cognitive Neuropsychology",
	localfile = "/home/chris/studium/masterarbeit/paper/Kanwisher (2000). The Cognitive Neuroscience of Face Processing. Intro.pdf",
	number = "1-3",
	pages = "1--11",
	publisher = "Taylor \& Francis",
	title = "{The cognitive neuroscience of face processing: An introduction}",
	volume = "17",
	year = "2000"
}

@article{kanwisher_1997_fusiform_face_area,
	author = "Nancy Kanwisher and Josh McDermott and Marvin M Chun",
	journal = "The Journal of Neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Kanwisher (1997). The Fusiform Face Area.pdf",
	number = "11",
	pages = "4302--4311",
	publisher = "The Journal of Neuroscience",
	title = "{The fusiform face area: A module in human extrastriate cortex specialized for face perception}",
	volume = "17",
	year = "1997"
}

@article{levin_1997_detect_changes_motion_pic,
	abstract = {Our intuition that we richly represent the visual details of our environment is illusory. When viewing a scene, we seem to use detailed representations of object properties and interobject relations to achieve a sense of continuity across views. Yet, several recent studies show that human observers fail to detect changes to objects and object properties when localized retinal information signaling a change is masked or eliminated (e.g., by eye movements). However, these studies changed arbitrarily chosen objects which may have been outside the focus of attention. We draw on previous research showing the importance of spatiotemporal information for tracking objects by creating short motion pictures in which objects in both arbitrary locations and the very center of attention were changed. Adult observers failed to notice changes in both cases, even when the sole actor in a scene transformed into another person across an instantaneous change in camera angle (or "cut").},
	author = "Daniel T Levin and Daniel J Simons",
	journal = "Psychonomic Bulletin \& Review",
	localfile = "/home/chris/studium/masterarbeit/paper/Levin (1997). Failure to detect changes to attended objects in motion pictures.pdf",
	number = "4",
	pages = "501--506",
	publisher = "Springer",
	title = "{Failure to detect changes to attended objects in motion pictures}",
	volume = "4",
	year = "1997"
}

@article{levin_2010_spatial_representations_familiar_TV,
	abstract = "Three experiments explored representations of spaces depicted on long-running television shows. The first two experiments tested representations of the space depicted in the show ER, which is filmed on a multiple-view set that allows the action to be viewed from any vantage point. Participants who had not seen the show, as well as those who had seen it frequently, made judgments about relative directions on the ER set. The experienced viewers were unable to perform this task more accurately than novices. In the third experiment, representations of two multiple-view sets (ER and West Wing) were compared with representations of more traditional constrained-view sets in which camera positions are limited to the region behind a {\lq}{\lq}fourth wall.{\rq}{\rq} Results demonstrated that experience watching the constrained-view shows was much more strongly associated with accurate representations than was experience with the multiple-view shows. In addition, a novel view of a constrained set was tested, and experience again did not facil- itate correct responding. These results suggest that long-term spatial memories can result from short-term spatial coding of individual scenes, but only when views are generally consistent.",
	author = "Daniel T Levin",
	journal = "Media Psychology",
	localfile = "/home/chris/studium/masterarbeit/paper/Levin (2010). Spatial Representations of the Sets of Familiar and Unfamiliar television programs.pdf",
	number = "1",
	pages = "54--76",
	publisher = "Taylor \& Francis",
	title = "{Spatial representations of the sets of familiar and unfamiliar television programs}",
	volume = "13",
	x-color = "#ffffa5",
	year = "2010"
}

@article{sugiura_2005_un_familiar_objects_places,
	abstract = "The recognition of both personally familiar objects and places involves nonspatial memory retrieval processes, but only personally familiar places are represented as space. Although the posterior cingulate cortex (PCC) is considered to process both types of such memories, its functional organization is poorly understood. In this event-related fMRI study, normal subjects judged familiar/unfamiliar pictures in four categories: familiar places (FP), familiar objects (FO), unfamiliar places (UP), and unfamiliar objects (UO), thus constituting a two-factorial design. A significant main effect of stimuli with greater activation in the place (FP and UP) than object (FO and UO) trials was observed bilaterally in several medial temporo-occipito-parietal regions, including the caudal PCC (cPCC) and parahippocampal gyrus. The reverse compar- ison revealed greater activation in the lateral inferior occipito-temporal junctions and intraparietal sulci bilaterally. A significant main effect of familiarity with greater activation in the familiar (FP and FO) than unfamiliar (UP and UO) trials was observed in the mid-dorsal PCC (mPCC), retro- splenial cortex, posterior precuneus, and the left intraparietal sulcus. Activation specific to the FP trials (as assessed by the interaction) was observed in the right posterodorsal PCC (pPCC) only. Together with data from previous functional imaging studies, the results suggest a functional segregation of human PCC with differential involvement of pPCC in spatial representations of personally familiar places and of the mPCC and retrosplenial cortex in episodic retrieval of personally familiar places and objects. Activation of the left intraparietal sulcus may reflect retrieval of memories related to object manipulation.",
	author = "Motoaki Sugiura and Nadim J Shah and Karl Zilles and Gereon R Fink",
	localfile = "/home/chris/studium/masterarbeit/paper/Sugiura (2005). Cortical Representations of Personally Familiar Objects.pdf",
	title = "{Cortical Representations of Personally Familiar Objects and Places: Functional Organization of the Human Posterior Cingulate Cortex}",
	x-color = "#0033ff",
	year = "2005"
}

@article{baumgartner_2013_feature_binding_superior_parietal,
	abstract = "The neural substrates of feature binding are an old, yet still not completely resolved problem. While patient studies suggest that posterior parietal cortex is necessary for feature binding, imaging evidence has been in- conclusive in the past. These studies compared visual feature and conjunction search to investigate the neural substrate of feature conjunctions. However, a common problem of these comparisons was a confound with search difï¬culty. To circumvent this confound, we directly investigated the localized representation of fea- tures (color and spatial frequency) and feature conjunctions in a single search task by using multivariate pat- tern analysis at high ï¬eld strength (7 T). In right superior parietal lobule, we found evidence for the representation of feature conjunctions that could not be explained by the summation of individual feature representations and thus indicates conjoined processing of color and spatial frequency.",
	author = "Florian Baumgartner and Michael Hanke and Franziska Geringswald and Wolf Zinke and Oliver Speck and Stefan Pollmann",
	journal = "NeuroImage",
	keywords = "FSL; attention; visual search; Visual perception; spatial perception; right superior parietla lobule",
	localfile = "/home/chris/studium/masterarbeit/paper/Baumgartner, Hanke, Pollman (2013). Evidence for feature binding in the superior parietal lobule.pdf",
	pages = "173--180",
	publisher = "Elsevier",
	title = "{Evidence for feature binding in the superior parietal lobule}",
	volume = "68",
	x-color = "#0033ff",
	year = "2013"
}

@article{geyer_baumgartner_2012_medial_temporal_search_trials,
	abstract = "Using visual search, functional magnetic resonance imaging (fMRI) and patient studies have demonstrated that medial temporal lobe (MTL) structures differentiate repeated from novel displays---even when observers are unaware of display repetitions. This suggests a role for MTL in both explicit and, importantly, implicit learning of repeated sensory information (Greene et al., 2007). However, recent behavioral studies suggest, by examining visual search and recognition performance concurrently, that observers have explicit knowledge of at least some of the repeated displays (Geyer et al., 2010). The aim of the present fMRI study was thus to contribute new evidence regarding the contribution of MTL structures to explicit vs. implicit learning in visual search. It was found that MTL activation was increased for explicit and, respectively, decreased for implicit relative to baseline displays. These activation differences were most pronounced in left anterior parahippocampal cortex (aPHC), especially when observers were highly trained on the repeated displays. The data are taken to suggest that explicit and implicit memory processes are linked within MTL structures, but expressed via functionally separable mechanisms (repetition-enhancement vs. -suppression). They further show that repetition effects in visual search would have to be investigated at the display level.",
	author = "Thomas Geyer and Florian Johannes Baumgartner and Hermann Josef Mueller and Stefan Pollmann",
	journal = "Frontiers in human neuroscience",
	keywords = "FSL; visual search; contextual cueing; medial temporal lobe; awareness",
	localfile = "/home/chris/studium/masterarbeit/paper/Geyer, Baumgartner, Pollmann (2012). Medial temporal loobe-dependent repetition suppression and enhancement due to implicit vs. explicit processing.pdf",
	pages = "272",
	publisher = "Frontiers",
	title = "{Medial temporal lobe-dependent repetition suppression and enhancement due to implicit vs. explicit processing of individual repeated search displays}",
	volume = "6",
	x-color = "#0033ff",
	year = "2012"
}

@article{manginelli_2013_dorsal_ventral_working_memory_context_cue,
	abstract = "Behavioral evidence suggests that the use of implicitly learned spatial contexts for improved visual search may depend on visual working memory resources. Working memory may be involved in contextual cueing in different ways: (1) for keeping implicitly learned working memory contents available during search or (2) for the capture of attention by contexts retrieved from memory. We mapped brain areas that were mod- ulated by working memory capacity. Within these areas, activation was modulated by contextual cueing along the descending segment of the intraparietal sulcus, an area that has previously been related to mainte- nance of explicit memories. Increased activation for learned displays, but not modulated by the size of con- textual cueing, was observed in the temporo-parietal junction area, previously associated with the capture of attention by explicitly retrieved memory items, and in the ventral visual cortex. This pattern of activation extends previous research on dorsal versus ventral stream functions in memory guidance of attention to the realm of attentional guidance by implicit memory.",
	author = "Angela A Manginelli and Florian Baumgartner and Stefan Pollmann",
	journal = "NeuroImage",
	keywords = "BrainVoyager",
	localfile = "/home/chris/studium/masterarbeit/paper/Manginelli, Baumgartner, Pollmann (2013). Dorsal and ventral working memory-related brain areas support distinct processes in contextual cueing.pdf",
	pages = "363--374",
	publisher = "Elsevier",
	title = "{Dorsal and ventral working memory-related brain areas support distinct processes in contextual cueing}",
	volume = "67",
	x-color = "#0033ff",
	year = "2013"
}

@article{pollmann_2016_neural_visual_search_reward,
	abstract = "Spatial contextual cueing reï¬ects an incidental form of learning that occurs when spatial distractor conï¬gurations are repeated in visual search displays. Recently, it was reported that the efï¬ciency of contextual cueing can be modulated by reward. We replicated this behavioral ï¬nding and investigated its neural basis with fMRI. Reward value was associated with repeated displays in a learning session. The effect of reward value on context-guided visual search was assessed in a subsequent fMRI session without reward. Structures known to support explicit reward valuation, such as ventral frontomedial cortex and posterior cingulate cortex, were modulated by inci- dental reward learning. Contextual cueing, leading to more efï¬cient search, went along with decreased activation in the visual search network. Retrosplenial cortex played a special role in that it showed both a main effect of re- ward and a reward × conï¬guration interaction and may thereby be a central structure for the reward modulation of context-guided visual search.",
	author = "Stefan Pollmann and Jana Ešto\v{c}inová and Susanne Sommer and Leonardo Chelazzi and Wolf Zinke",
	journal = "NeuroImage",
	keywords = "FSL",
	localfile = "/home/chris/studium/masterarbeit/paper/Pollmann (2016). Neural structures involved in visual search guidance by reward-enhanced contextual cueing of the target location.pdf",
	pages = "887--897",
	publisher = "Elsevier",
	title = "{Neural structures involved in visual search guidance by reward-enhanced contextual cueing of the target location}",
	volume = "124",
	x-color = "#0033ff",
	year = "2016"
}

@article{pollmann_2014_right_TPJ_visual_feature_binding,
	author = "Stefan Pollmann and Wolf Zinke and Florian Baumgartner and Franziska Geringswald and Michael Hanke",
	journal = "NeuroImage",
	keywords = "FSL",
	localfile = "/home/chris/studium/masterarbeit/paper/Pollmann, Hanke (2014). The right temporo-parietal junction contributes to visual feature binding.pdf",
	pages = "289--297",
	publisher = "Elsevier",
	title = "{The right temporo-parietal junction contributes to visual feature binding}",
	volume = "101",
	year = "2014"
}

@article{pollmann_2009_early_contextual_change_prefrontal_cortex,
	author = "Stefan Pollmann and Angela A Manginelli",
	journal = "Brain research",
	keywords = "BrainVoyager",
	localfile = "/home/chris/studium/masterarbeit/paper/Pollmann, Manginelli (2009). Early implicit contextual change detection in anterior prefrontal cortex.pdf",
	pages = "87--92",
	publisher = "Elsevier",
	title = "{Early implicit contextual change detection in anterior prefrontal cortex}",
	volume = "1263",
	year = "2009"
}

@article{wegrzyn_2015_facial_expressions_MVPA,
	abstract = "Humans can readily decode emotion expressions from faces and perceive them in a cat- egorical manner. The model by Haxby and colleagues proposes a number of different brain regions with each taking over specific roles in face processing. One key question is how these regions directly compare to one another in successfully discriminating between various emotional facial expressions. To address this issue, we compared the predictive accuracy of all key regions from the Haxby model using multi-voxel pattern analysis (MVPA) of functional magnetic resonance imaging (fMRI) data. Regions of interest were extracted using independent meta-analytical data. Participants viewed four classes of facial expressions (happy, angry, fearful and neutral) in an event-related fMRI design, while performing an orthogonal gender recog- nition task. Activity in all regions allowed for robust above-chance predictions. When directly comparing the regions to one another, fusiform gyrus and superior temporal sulcus (STS) showed highest accuracies. These results underscore the role of the fusiform gyrus as a key region in perception of facial expressions, alongside STS. The study suggests the need for further specification of the relative role of the various brain areas involved in the perception of facial expression. Face processing appears to rely on more interactive and functionally overlapping neural mechanisms than previously conceptualised.",
	author = "Martin Wegrzyn and Marcel Riehle and Kirsten Labudda and Friedrich Woermann and Florian Baumgartner and Stefan Pollmann and Christian G Bien and Johanna Kissler",
	journal = "cortex",
	keywords = "SPM",
	localfile = "/home/chris/studium/masterarbeit/paper/Wegrzyn, Pollmann (2015). Investigating the brain basis of facial expression perception using multi-voxel pattern analysis.pdf",
	pages = "131--140",
	publisher = "Elsevier",
	title = "{Investigating the brain basis of facial expression perception using multi-voxel pattern analysis}",
	volume = "69",
	year = "2015"
}

@article{wei_2011_binding_features_conj_search,
	author = "Ping Wei and Hermann J Müller and Stefan Pollmann and Xiaolin Zhou",
	journal = "Neuroimage",
	keywords = "SPM",
	localfile = "/home/chris/studium/masterarbeit/paper/Wei, Pollmann (2011). Neural correlates of binding features within- or cross-dimensions in visual conjunction search.pdf",
	number = "1",
	pages = "235--241",
	publisher = "Elsevier",
	title = "{Neural correlates of binding features within-or cross-dimensions in visual conjunction search: An fMRI study}",
	volume = "57",
	year = "2011"
}

@article{halchenko_hanke_2012_open_not_enough,
	author = "Yaroslav O Halchenko and Michael Hanke",
	journal = "Frontiers in neuroinformatics",
	localfile = "/home/chris/studium/masterarbeit/paper/Halchenko, Hanke (2012). Open is not enough.pdf",
	pages = "22",
	publisher = "Frontiers",
	title = "{Open is not enough. Let's take the next step: an integrated, community-driven computing platform for neuroscience}",
	volume = "6",
	year = "2012"
}

@article{weniger_2010_parahippocampal_navi_virtual_maze,
	abstract = "Background: Present evidence suggests that the hippocampus (HC) and the parahippocampal cortex (PHC) are involved in allocentric (world-centered) spatial memory. However, the putative role of the PHC in egocentric (body-centered) spatial learning has received only limited systematic investigation. Methods: To examine the role of the PHC in egocentric learning, 19 healthy volunteers learned to ï¬nd their way in a virtual maze during functional magnetic resonance imaging (fMRI). The virtual maze pre- sented a ï¬rst-person view, lacked any topographical landmarks and could be learned only using egocentric navigation strategies. Results: During learning, increased medial temporal lobe activity was observed in the PHC bilaterally. Activity was also observed in cortical areas known to project to the PHC and proposed to contribute to egocentric spatial navigation and memory. Conclusions: Our results point to a role of the PHC for the representation and storage of egocentric infor- mation. It seems possible that the PHC contributes to egocentric memory by its feedback projections to the posterior parietal cortex. Moreover, access to allocentric and egocentric streams of spatial informa- tion may enable the PHC to construct a global and comprehensive representation of spatial environments and to promote the construction of stable cognitive maps by translating between egocentric and allocen- tric frames of memory.",
	author = "Godehard Weniger and Jakob Siemerkus and Carsten Schmidt-Samoa and Markus Mehlitz and Jürgen Baudewig and Peter Dechent and Eva Irle",
	localfile = "/home/chris/studium/masterarbeit/paper/Weniger (2010). The human parahippocampal cortex subserves egocentric spatial learning during navigation in a virtual maze.pdf",
	title = "{The human parahippocampal cortex subserves egocentric spatial learning during navigation in a virtual maze}",
	year = "2010"
}

@article{park_2010_refreshing_visual_scenes,
	author = "Soojin Park and Marvin M Chun and Marcia K Johnson",
	journal = "Journal of cognitive neuroscience",
	localfile = "/home/chris/studium/masterarbeit/paper/Park (2010). Refreshing and Integrating Visual Scenes in Scene-selective Cortex.pdf",
	number = "12",
	pages = "2813--2822",
	publisher = "MIT Press",
	title = "{Refreshing and integrating visual scenes in scene-selective cortex}",
	volume = "22",
	year = "2010"
}

@article{pitcher_2011_occipital_face_area,
	author = "David Pitcher and Vincent Walsh and Bradley Duchaine",
	journal = "Experimental Brain Research",
	localfile = "/home/chris/studium/masterarbeit/paper/Pitcher (2011). The role of the occipital face area.pdf",
	number = "4",
	pages = "481--493",
	publisher = "Springer",
	title = "{The role of the occipital face area in the cortical face perception network}",
	volume = "209",
	year = "2011"
}

@article{downing_2001_extrastriate_body_area,
	author = "Paul E Downing and Yuhong Jiang and Miles Shuman and Nancy Kanwisher",
	journal = "Science",
	localfile = "/home/chris/studium/masterarbeit/paper/Downing (2001). A cortical area selective for visual processing of the human body.pdf",
	number = "5539",
	pages = "2470--2473",
	publisher = "American Association for the Advancement of Science",
	title = "{A cortical area selective for visual processing of the human body}",
	volume = "293",
	year = "2001"
}

@article{malach_1995_lateral_occipital_complex,
	author = "Rafael Malach and JB Reppas and RR Benson and KK Kwong and H Jiang and WA Kennedy and PJ Ledden and TJ Brady and BR Rosen and RB Tootell",
	journal = "Proceedings of the National Academy of Sciences",
	localfile = "/home/chris/studium/masterarbeit/paper/Malach (1995). Object-related activity revealed by functional magnetic resonance imaging in human occipital cortex.pdf",
	number = "18",
	pages = "8135--8139",
	publisher = "National Acad Sciences",
	title = "{Object-related activity revealed by functional magnetic resonance imaging in human occipital cortex}",
	volume = "92",
	year = "1995"
}

