\documentclass[10pt,a4paper,twocolumn]{article}
\usepackage{endfloat}
\usepackage{f1000_styles}
\usepackage{listings}
\usepackage{units}
\usepackage[colorlinks]{hyperref}
\usepackage{url}
\usepackage{appendix}
\usepackage{soul}
\usepackage[sort,compress]{natbib}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\begin{document}

\input{results_def.tex}

\title{An annotation of changes in depicted location and time in the motion
picture ``Forrest Gump''}

\author[1]{Christian HÃ¤usler}
\author[1,2]{Michael Hanke}

\affil[1]{Psychoinformatics lab, Department of Psychology, University of Magdeburg, Universit\"{a}tsplatz 2, 39106 Magdeburg, Germany}
\affil[2]{Center for Behavioral Brain Sciences, Magdeburg, Germany}
\maketitle
\thispagestyle{fancy}

\begin{abstract}
% Abstracts should be up to 300 words and provide a succinct summary of the
% article. Although the abstract should explain why the article might be
% interesting, care should be taken not to inappropriately over-emphasise the
% importance of the work described in the article. Citations should not be used
% in the abstract, and the use of abbreviations should be minimized.

\todo[inline]{Write an abstract}

\end{abstract}

\listoftodos[ToDo notes]

\clearpage

%The format of the main body of the article is flexible: it should be concise
%and in the format most appropriate to displaying the content of the article.

\section*{Introduction}
% ~380 words
% Rationale for creating the dataset(s) and/or objectives for the experiment
% resulting in the dataset - why the data were gathered or produced.

Cognitive neuroimaging research is moving towards studying brain behavior under
conditions of real-life-like complexity, and, frequently, motion pictures are
utilized as stimuli in ``neurocinematics'' studies
\citep{hasson_2008_neurocinematics}. What sets motion pictures apart from other
dynamic naturalistic stimuli is that they are more likely to evoke time-locked
response patterns in a larger portion of the brain that are synchronous across
multiple individuals who are experiencing the same movie
\citep{hasson_2009_natural_stim_review,lankinen_2014_MEG_during_movie}. One
reason for this is likely the structure of movies. They are typically not a
prolonged contiguous capture of the environment in a first person view, but are
carefully assembled from hundreds of short sequences from various perspectives
that are practically always joined by cuts
\citep{cutting_2011_changing_poetics_of_dissolve}. These cuts are sharp
discontinuities in the sensory input that require all viewers to re-assess the
depicted environment in order to perform a cognitive re-orientation in
fictional space and time. This re-orientation can be complex and involve a
large bandwidth of cognitive processes: detection of familiar settings,
retrieval of prior knowledge from memory, discovery of change in locales and
depicted characters. Consequently, movies, and, in particular, their cuts offer
an instrument to study complex, concurrent, real-life cognition.

In this study, we focus on spatial and temporal viewer re-orientation, and, to
this end, describe change in depicted location and time for all cuts in the
motion picture ``Forrest Gump''. This movie is the core stimulus of the
\textit{studyforrest} project (\url{http://studyforrest}). Two fMRI datasets
are publicly available: 1) participants listening to an audio-movie version
\citep{HBI+14}, and 2) a subset of the original participants watching the
audio-visual movie with simultaneous eye tracking \citep{HAK+16}. Additional
imaging data and movie annotations are available \citep{HDH+2015,LRS+2015},
including an individual localization of the \textit{parahippocampal place area}
\citep{SKG+16} that has been implicated in spatial perception and scene
processing \citep{EK1998}.

This new annotation extends the available knowledge about the structure of this
complex natural stimulus, and enriches the joint studyforrest dataset. These
data can be used to investigate the formation of a representation of viewer
location, and the perception of (speeded or negative) temporal progression in
the movie stimulus. For any study focusing on other aspects of real-life
cognition these new data can serve as additional confound measures describing
key properties of major building blocks of this movie stimulus.


\section*{Materials and methods}
% Detailed account of the protocol used to generate the dataset

\subsection*{Stimulus}

% ~600 words
The annotated stimulus was a slightly shortened ($\approx$\unit[2]{h}) version
of the movie Forrest~Gump (R.~Zemeckis, Paramount Pictures, 1994) with dubbed
German soundtrack, and is identical to the audio-visual movie annotated in
\cite{LRS+2015}. Further details on this particular movie cut, and how to
reproduce it from commercially available sources are available in
\cite{HAK+16}.


\subsection*{Annotation procedure}

First the movie was explored by two persons, one of them with an academic
background in documentary filmmaking, in order to generate a consistent list of
labels for depicted and recurring locations.

Subsequently, the actual annotation was performed by the first author using a
multi-pass strategy. The movie was manually investigated frame-by-frame to
determine the location of cuts (using the video editor Shotcut v16.02.01). Cut
timing was later validated against the results of an automated detection
routine. For each new shot (sequence between two cuts) a number of properties,
described below, were determined and entered into a table. A total of four
passes were performed in order to validate the annotation.


\subsection*{Data legend}

The annotation table contains one line per shot and
seven columns: 1) a shot's \textit{start time}, 2) a label for the shot's
\textit{major location}, 3) a label for the \textit{setting} within the
location, 4) a label for the \textit{locale} within the setting, 5) a flag
indicating an \textit{interior or exterior} setting, 6) a label for the type of
\textit{temporal progression} with respect to the previous shot, and 7) a label
for the \textit{time of day}. Further details are provided in the following
sections.

\begin{table}[h]
\begin{tabular}{lllllll}
\multicolumn{7}{l}{Table 1. Example lines from the annotation early in the movie}\tabularnewline
\hline 
time & major location & setting & locale & int or ext & flow of time & time of day\tabularnewline
00:05:00:14  & Greenbow Alabama  & doctor's office  & doctor's office  & ext  & 0 & day\tabularnewline
00:05:11:24  & Greenbow Alabama  & main street  & in front of barbershop  & ext  & + & day\tabularnewline
00:05:18:07  & United States  & flashback countryside  & flashback countryside  & ext  & - & day\tabularnewline
00:05:43:01 & Greenbow Alabama  & main street  & in front of barbershop  & ext  & ++ & day\tabularnewline
\hline 
\end{tabular}
\end{table}



\subsubsection*{Shot start time}

A shot's start time is defined as the onset time of the first video frame of a
shot after a cut. Time stamps a provided in seconds of movie onset. 

\subsubsection*{Location}

Location was coded with three labels, describing the depicted scenary
in increasing level of detail.

\paragraph{Major location} provides a course identification at the level of a
town, county, or region where the respective story is taking place. Examples are:
``Greenbow'', or ``Vietnam''.

\paragraph{Setting} further details location by distinguishing places at the same
major location, which are not in direct sight of each other. For example
Forrest Gump's elementary school and the football field, both in Greenbow,
Alabama. A switch from one setting to another is typically synonymous with a
transition to a new scene in a cinematographic sense. If the camera switched 
settings within a scene, the annotation deviates from the screenplay to make that
switch to another setting explicit.

\paragraph{Locale} subdivides settings into distinguishable locales.  Indoors, a
locale is congruent with a particular room enclosed by walls. For example
Forrest Gump's bedroom, the corridor downstairs and the corridor upstairs are
three different rooms inside the Gumps' house (setting) on the Gumps' property
(major location). Outdoors, locales were distinguished when they were separated
by a logical boundary, substantial distance, or shared no landmarks.  For
example the glade at the river and the location of the wounded Bubba are two
different locales in the embattled jungle (setting) in Vietnam (major
location). A locale's label is identical to the respective setting label, when
only one locale is depicted for this setting.


\subsubsection*{Interior or exterior}

This flag indicates whether a particular location is an open
(``\texttt{ext}''), or enclosed space (``\texttt{int}''), such as a building,
or a vehicle.


\subsubsection*{Temporal progression}

This label indicates the depicted progression of time between the previous and
the current shot. Four categories were distinguished: ``\texttt{-}'' labels a
flashback, or jump into the past, independent of the temporal distance;
``\texttt{0}'' indicates no noticeable break in the ongoing stream of time, for
example a sole change of viewing perspective; ``\texttt{+}'' represents
noticeable jumps in time, ranging from several seconds to about one or two
hours; and lastly ``\texttt{++}'' marks major time jumps from several hours
(e.g.  night vs. day) to several years.


\subsubsection*{Time of day}

This flag indicates whether a scene is at least partially illuminated by sun
light. Consequently, day time and twilight (early sunrises and late sun
settings) are labeled ``\texttt{day}''. If sun light is entirely missing,
the time of day is coded as ``\texttt{night}''.



\subsection*{Dataset content}

\todo[inline]{What exactly is released, in what format?}

\paragraph{Source code}

The full source code for all descriptive statistics and figures included in
this paper is available in \texttt{descriptive\_stats.py} (Python script).


\section*{Dataset validation}
% Information about any validation carried out and/or any limitations of the
% datasets, including any allowances made for controlling bias or unwanted
% sources of variability.

\begin{table*}
  \centering
  \begin{tabular}{lllllllllllll}
    %& \multicolumn{3}{l}{\textbf{Event definition min. agreement}} \\
    % header
    &
    \multicolumn{4}{c}{\textbf{Major locations}} &
    \multicolumn{4}{c}{\textbf{Settings}} &
    \multicolumn{4}{c}{\textbf{Locales}} \\
    \\\hline\\
    Number of unique & \multicolumn{4}{c}{\NMajorLocations} & \multicolumn{4}{c}{\NSettings} & \multicolumn{4}{c}{\NLocales} \\
    \\\hline\\
    % subheader
    & min & med. & mean & max &
      min & med. & mean & max &
      min & med. & mean & max \\\\
    Number of shots
    & \ShotsPerMajorLocationMin & \ShotsPerMajorLocationMedian & \ShotsPerMajorLocationMean & \ShotsPerMajorLocationMax 
    & \ShotsPerSettingMin & \ShotsPerSettingMedian & \ShotsPerSettingMean & \ShotsPerSettingMax 
    & \ShotsPerLocaleMin & \ShotsPerLocaleMedian & \ShotsPerLocaleMean & \ShotsPerLocaleMax
    \\
    Number of consecutive shots
    & \ConsecShotsPerMajorLocationMin & \ConsecShotsPerMajorLocationMedian & \ConsecShotsPerMajorLocationMean & \ConsecShotsPerMajorLocationMax 
    & \ConsecShotsPerSettingMin & \ConsecShotsPerSettingMedian & \ConsecShotsPerSettingMean & \ConsecShotsPerSettingMax 
    & \ConsecShotsPerLocaleMin & \ConsecShotsPerLocaleMedian & \ConsecShotsPerLocaleMean & \ConsecShotsPerLocaleMax
    \\
    Times revisited
    & \NTimesMajorLocationsRevisitedMin & \NTimesMajorLocationsRevisitedMedian & \NTimesMajorLocationsRevisitedMean & \NTimesMajorLocationsRevisitedMax 
    & \NTimesSettingsRevisitedMin & \NTimesSettingsRevisitedMedian & \NTimesSettingsRevisitedMean & \NTimesSettingsRevisitedMax 
    & \NTimesLocalesRevisitedMin & \NTimesLocalesRevisitedMedian & \NTimesLocalesRevisitedMean & \NTimesLocalesRevisitedMax
    \\
    \\\hline
  \end{tabular}
  \caption{Descriptive statistics.}
  \label{tab:stats}
\end{table*}
 





% 870 shots if last "shot" which only contains black frames counts as a shot
To check for human errors and validate the timings, the manual annotation was
compared to an annotation created by an in-house developed, automated cut
detection algorithm.

In summary the shortened version of the movie comprises
\NShots\ shots (duration: min=\unit[\ShotLengthMin]{s},
max=\unit[\ShotLengthMax]{s}, median=\unit[\ShotLengthMedian]{s},
SD=\unit[\ShotLengthSD]{s}).

% jetzt haben wir uns den Entwurf der Visualisierung meiner Bedinungen nicht angeguckt,
% denke aber, dass es hier ein bisschen gewollt wirkt: "Haben das Bild gerade da,
% also fuegen wir es auch mit ein"

\todo[inline]{Place any information and illustrative figures here that help
people figure out whether these annotation are useful/trustworthy for them}


\subsection*{from raw annotation to experimental conditions}

\todo[inline]{this section could be stripped of all FSL/MRI references
  and converted into a ``validation'' that lists possible conditions
  and counts the respective events in each, so people get a sense of
  what is there.}

The total number of events for the conditions were: 96 events for
setting\_new (Mdn = 8.92; SD = 21.882 s), 90 events for setting\_old
(Mdn = 7.68; SD = 9.440 s), 89 events for locale\_change (Mdn = 6.96;
SD = 8855 s), 386 events for perspective\_new (occuring in shots with
median shot length of 3.96 s; SD = 7.484 s), and 208 events for perspective\_old
(Mdn = 3.5 s; SD = 7.470 s)\todo{stats in this paragraph need to be computed from
annotation}


\section*{Data availability}

\texttt{This section will be auto-generated.}


\section*{Author contributions}
%In order to give appropriate credit to each author of an article, the
%individual contributions of each author to the manuscript should be detailed
%in this section. We recommend using author initials and then stating briefly
%how they contributed.
CH design, performed, and validated the annotation, and wrote the manuscript.
MH provided critical feedback on the procedure and wrote the manuscript.

\section*{Competing Interests}
No competing interests were disclosed.

\section*{Grant Information}

Michael Hanke was supported by funds from the German federal state of
Saxony-Anhalt and the European Regional Development Fund (ERDF), Project: ,
Project: Center for Behavioral Brain Sciences.

\section*{Acknowledgements}
%This section should acknowledge anyone who contributed to the research or the
%article but who does not qualify as an author based on the criteria provided
%earlier (e.g. someone or an organisation that provided writing assistance).
%Please state how they contributed; authors should obtain permission to
%acknowledge from all those mentioned in the Acknowledgements section.  Please
%do not list grant funding in this section (this should be included in the
%Grant information section - See above).
We are grateful to Daniel Kottke for cross-checking the timing of the cuts in
the movie using an automated detection routine. We would also like to thank Gavin
Theren for sharing patiently his cinematographic knowledge 
during movie watching and for his high-level gastronomic skills.

%\nocite{*}
{\small\bibliographystyle{unsrt}
\bibliography{references,bibliography_forrest_gump}

\end{document}

% vim: textwidth=80 colorcolumn=81
